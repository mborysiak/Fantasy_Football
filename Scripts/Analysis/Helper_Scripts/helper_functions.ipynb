{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# Dictionary for position relevant metrics\n",
    "#==========\n",
    "\n",
    "# initialize full position dictionary\n",
    "pos = {}\n",
    "\n",
    "#---------\n",
    "# RB dictionary\n",
    "#---------\n",
    " \n",
    "# initilize RB dictionary\n",
    "pos['RB'] = {}\n",
    "\n",
    "# total touch filter name\n",
    "pos['RB']['touch_filter'] = 'total_touches'\n",
    "\n",
    "# metrics to be predicted for fantasy point generation\n",
    "pos['RB']['metrics'] = ['rush_yd_per_game', 'rec_yd_per_game', 'rec_per_game', 'td_per_game']\n",
    "\n",
    "# median feature categories\n",
    "pos['RB']['med_features'] = ['fp', 'tgt', 'receptions', 'total_touches', 'rush_yds', 'rec_yds', \n",
    "                           'rush_yd_per_game', 'rec_yd_per_game', 'rush_td', 'games_started', \n",
    "                           'qb_rating', 'qb_yds', 'pass_off', 'tm_rush_td', 'tm_rush_yds', \n",
    "                           'tm_rush_att', 'adjust_line_yds', 'ms_rush_yd', 'ms_rec_yd', 'ms_rush_td',\n",
    "                           'avg_pick', 'fp_per_touch', 'team_rush_avg_att']\n",
    "\n",
    "# sum feature categories\n",
    "pos['RB']['sum_features'] = ['total_touches', 'att', 'scrimmage_yds']\n",
    "\n",
    "# max feature categories\n",
    "pos['RB']['max_features'] = ['fp', 'rush_td', 'tgt', 'rush_yds', 'rec_yds', 'scrimmage_yds']\n",
    "\n",
    "# age feature categories\n",
    "pos['RB']['age_features'] = ['fp', 'rush_yd_per_game', 'rec_yd_per_game', 'total_touches', 'receptions', 'tgt',\n",
    "                             'ms_rush_yd', 'ms_rec_yd', 'available_rush_att', 'available_tgt', 'total_touches_sum',\n",
    "                             'scrimmage_yds_sum', 'avg_pick', 'fp_per_touch', 'ms_rush_yd_per_att', 'ms_tgts']\n",
    "\n",
    "# set the random search parameters for tree clustering\n",
    "pos['RB']['tree_params'] = {\n",
    "    'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'min_samples_split': [2, 3, 4, 5, 6],\n",
    "    'min_samples_leaf': [18, 20, 22, 25, 28, 30, 32, 35],\n",
    "    'splitter': ['best', 'random']\n",
    "}\n",
    "\n",
    "#---------\n",
    "# WR dictionary\n",
    "#---------\n",
    " \n",
    "# initilize RB dictionary\n",
    "pos['WR'] = {}\n",
    "\n",
    "# total touch filter name\n",
    "pos['WR']['touch_filter'] = 'tgt'\n",
    "\n",
    "# metrics to calculate stats for\n",
    "pos['WR']['metrics'] = ['yd_per_game', 'rec_per_game', 'td_per_game']\n",
    "\n",
    "# median feature categories\n",
    "pos['WR']['med_features'] = ['fp', 'tgt', 'receptions', 'yds', 'yd_per_game', 'td', 'games_started', \n",
    "                             'qb_rating', 'qb_yds', 'pass_off', 'ms_tgts', 'ms_rec_yd', \n",
    "                             'tm_net_pass_yds', 'avg_pick']\n",
    "# sum feature categories\n",
    "pos['WR']['sum_features'] = ['receptions', 'yds', 'tgt']\n",
    "\n",
    "# max feature categories\n",
    "pos['WR']['max_features'] = ['fp', 'td', 'tgt', 'ms_tgts', 'ms_rec_yd']\n",
    "\n",
    "# age feature categories\n",
    "pos['WR']['age_features'] = ['fp', 'yd_per_game', 'receptions', 'tgt', 'ms_tgts', 'ms_rec_yd', \n",
    "                             'avg_pick', 'ms_yds_per_tgts']\n",
    "\n",
    "# set the random search parameters for tree clustering\n",
    "pos['WR']['tree_params'] = {\n",
    "    'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'min_samples_split': [2, 3, 4, 5, 6],\n",
    "    'min_samples_leaf': [18, 20, 22, 25, 28, 30, 32, 35],\n",
    "    'splitter': ['best', 'random']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Fantasy Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fp(df, pts, pos):\n",
    "    \n",
    "    # calculate fantasy points for QB's associated with a given RB or WR\n",
    "    if pos == 'RB' or 'WR':\n",
    "        df['qb_fp'] = \\\n",
    "        pts['pass_yd_pts']*df['qb_yds'] + \\\n",
    "        pts['pass_td_pts']*df['qb_tds'] - \\\n",
    "        pts['int_pts']*df['int'] - \\\n",
    "        pts['sack_pts']*df['qb_sacks']\n",
    "    \n",
    "    # calculate fantasy points for RB's\n",
    "    if pos == 'RB':\n",
    "        \n",
    "        # create the points list corresponding to metrics calculated\n",
    "        pts_list = [pts['yd_pts'], pts['yd_pts'], pts['rec_pts'], pts['td_pts']]\n",
    "        \n",
    "        df['fp'] = \\\n",
    "        pts['yd_pts']*df['rush_yds'] + \\\n",
    "        pts['yd_pts']*df['rec_yds'] + \\\n",
    "        pts['td_pts']*df['rush_td'] + \\\n",
    "        pts['td_pts']*df['rec_td'] + \\\n",
    "        pts['rec_pts']*df['receptions'] + \\\n",
    "        pts['fmb_pts']*df['fmb']\n",
    "        \n",
    "        # calculate fantasy points per touch\n",
    "        df['fp_per_touch'] = df['fp'] / df['total_touches']\n",
    "        \n",
    "        # calculate fantasy points per target\n",
    "        df['fp_per_tgt'] = df['fp'] / df['tgt']\n",
    "    \n",
    "    if pos == 'WR':\n",
    "        \n",
    "        # create the points list corresponding to metrics calculated\n",
    "        pts_list = [pts['yd_pts'], pts['rec_pts'], pts['td_pts']]\n",
    "        \n",
    "        df['fp'] = \\\n",
    "        pts['yd_pts']*df['yds'] + \\\n",
    "        pts['td_pts']*df['td'] + \\\n",
    "        pts['rec_pts']*df['receptions']\n",
    "        \n",
    "        # calculate fantasy points per touch\n",
    "        df['fp_per_tgt'] = df['fp'] / df['tgt']\n",
    "        \n",
    "    # calculate fantasy points per game\n",
    "    df['fp_per_game'] = df['fp'] / df['games']\n",
    "    \n",
    "    return df, pts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_target(df, year_start, year_end, median_features, sum_features, max_features, \n",
    "                    age_features, target_feature):\n",
    "    \n",
    "    import pandas as pd\n",
    "\n",
    "    new_df = pd.DataFrame()\n",
    "    years = range(year_start+1, year_end+1)\n",
    "\n",
    "    for year in years:\n",
    "        \n",
    "        # adding the median features\n",
    "        past = df[df['year'] <= year]\n",
    "        for metric in median_features:\n",
    "            past = past.join(past.groupby('player')[metric].median(),on='player', rsuffix='_median')\n",
    "\n",
    "        for metric in max_features:\n",
    "            past = past.join(past.groupby('player')[metric].max(),on='player', rsuffix='_max')\n",
    "            \n",
    "        for metric in sum_features:\n",
    "            past = past.join(past.groupby('player')[metric].sum(),on='player', rsuffix='_sum')\n",
    "            \n",
    "        # adding the age features\n",
    "        suffix = '/ age'\n",
    "        for feature in age_features:\n",
    "            feature_label = ' '.join([feature, suffix])\n",
    "            past[feature_label] = past[feature] / past['age']\n",
    "        \n",
    "        # adding the values for target feature\n",
    "        year_n = past[past[\"year\"] == year]\n",
    "        year_n_plus_one = df[df['year'] == year+1][['player', target_feature]].rename(columns={target_feature: 'y_act'})\n",
    "        year_n = pd.merge(year_n, year_n_plus_one, how='left', left_on='player', right_on='player')\n",
    "        new_df = new_df.append(year_n)\n",
    "    \n",
    "    # creating dataframes to export\n",
    "    new_df = new_df.sort_values(by=['year', 'fp'], ascending=[False, False])\n",
    "    new_df = pd.concat([new_df, pd.get_dummies(new_df.year)], axis=1)\n",
    "    \n",
    "    df_train = new_df[new_df.year < year_end].reset_index(drop=True)\n",
    "    df_predict = new_df[new_df.year == year_end].drop('y_act', axis=1).reset_index(drop=True)\n",
    "    \n",
    "    df_train['year'] = df_train.year.astype('int')\n",
    "    df_train = df_train.sort_values(['year', 'fp_per_game'], ascending=True).reset_index(drop=True)\n",
    "\n",
    "    df_predict['year'] = df_predict.year.astype('int')\n",
    "    \n",
    "    return df_train, df_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_features(df_train):\n",
    "    \n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    from my_plot import PrettyPlot\n",
    "    \n",
    "    plt.figure(figsize=(17,12))\n",
    "    k = 25\n",
    "    corrmat = abs(df_train.corr())\n",
    "    cols_large = corrmat.nlargest(k, 'y_act').index\n",
    "    hm_large = corrmat.nlargest(k,'y_act')[cols_large]\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns_plot = sns.heatmap(hm_large, cmap=\"YlGnBu\", cbar=True, annot=True, square=False, fmt='.2f', \n",
    "                 annot_kws={'size': 12});\n",
    "\n",
    "    fig = sns_plot.get_figure();\n",
    "    PrettyPlot(plt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results, col_names, asc=True, barh=True, figsize=(6,16), fontsize=12):\n",
    "    '''\n",
    "    Input:  The feature importance or coefficient weights from a trained model.\n",
    "    Return: A plot of the ordered weights, demonstrating relative importance of each feature.\n",
    "    '''\n",
    "    \n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    #cols = df_predict.select_dtypes(include=['float', 'int', 'uint8']).columns\n",
    "    series = pd.Series(results, index=col_names).sort_values(ascending=asc)\n",
    "    \n",
    "    if barh == True:\n",
    "        ax = series.plot.barh(figsize=figsize, fontsize=fontsize)\n",
    "        #ax.set_xlabel(label, fontsize=fontsize+1)\n",
    "    else:\n",
    "        ax = series.plot.bar(figsize=figsize, fontsize=fontsize)\n",
    "        #ax.set_ylabel(label, fontsize=fontsize+1)\n",
    "        \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Model Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_removal(df_train, df_predict, corr_cutoff=0.025):\n",
    "\n",
    "    corr = df_train.corr()['y_act']\n",
    "    good_cols = list(corr[abs(corr) > corr_cutoff].index)\n",
    "\n",
    "    good_cols.extend(['player', 'year'])\n",
    "    df_train = df_train[good_cols]\n",
    "    df_train = df_train.loc[:,~df_train.columns.duplicated()]\n",
    "\n",
    "    good_cols.remove('y_act')\n",
    "    df_predict = df_predict[good_cols]\n",
    "    df_predict = df_predict.loc[:,~df_predict.columns.duplicated()]\n",
    "    \n",
    "    return df_train, df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "class ReduceVIF(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, thresh=5.0, scale=True, impute=True, impute_strategy='median', print_progress=False):\n",
    "       \n",
    "        # From looking at documentation, values between 5 and 10 are \"okay\".\n",
    "        # Above 10 is too high and so should be removed.\n",
    "        self.thresh = thresh\n",
    "        self.print_progress = print_progress\n",
    "       \n",
    "        # The statsmodel function will fail with NaN values, as such we have to impute them.\n",
    "        # By default we impute using the median value.\n",
    "        # This imputation could be taken out and added as part of an sklearn Pipeline.\n",
    "        if impute:\n",
    "            self.imputer = Imputer(strategy=impute_strategy)\n",
    "            \n",
    "        if scale:\n",
    "            self.scale = StandardScaler()\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        if hasattr(self, 'imputer'):\n",
    "            self.imputer.fit(X)\n",
    "            \n",
    "        if hasattr(self, 'scale'):\n",
    "            self.scale.fit(X)\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        columns = X.columns.tolist()\n",
    "        \n",
    "        if hasattr(self, 'imputer'):\n",
    "            X = pd.DataFrame(self.imputer.transform(X), columns=columns)\n",
    "            \n",
    "        if hasattr(self, 'scale'):\n",
    "            X = pd.DataFrame(self.scale.transform(X), columns=columns)\n",
    "        \n",
    "        return ReduceVIF.calculate_vif(self, X, self.thresh)\n",
    " \n",
    "    @staticmethod\n",
    "    def calculate_vif(self, X, thresh=5.0):\n",
    "        \n",
    "        print('Running VIF Feature Reduction')\n",
    "        \n",
    "        # filter out warnings during run\n",
    "        import warnings\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        \n",
    "        # Taken from https://stats.stackexchange.com/a/253620/53565 and modified\n",
    "        dropped=True\n",
    "        while dropped:\n",
    "            \n",
    "            variables = X.columns\n",
    "            \n",
    "            dropped = False\n",
    "            vif = [variance_inflation_factor(X[variables].values, X.columns.get_loc(var)) for var in X.columns]\n",
    "           \n",
    "            max_vif = max(vif)\n",
    "            if max_vif > thresh:\n",
    "                maxloc = vif.index(max_vif)\n",
    "                if self.print_progress:\n",
    "                    print(f'Dropping {X.columns[maxloc]} with vif={max_vif}')\n",
    "                X = X.drop([X.columns.tolist()[maxloc]], axis=1)\n",
    "                dropped=True\n",
    "                        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============\n",
    "# Create parameter dictionaries for each algorithm\n",
    "#=============\n",
    "\n",
    "lgbm_params = {\n",
    "    'n_estimators':[30, 40, 50, 60, 75],\n",
    "    'max_depth':[2, 3, 4, 5, 6, 7],\n",
    "    'freature_fraction':[0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "    'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "    'min_child_weight': [5, 10, 15, 20, 25],\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': [30, 40, 50, 60, 75], \n",
    "    'max_depth': [2, 3, 4, 5, 6, 7], \n",
    "    'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "    'min_child_weight': [10, 15, 20, 25, 30],\n",
    "    'freature_fraction':[0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [30, 40, 50, 60, 75, 100, 125, 150], \n",
    "    'max_depth': [3, 4, 5, 6, 7], \n",
    "    'min_samples_leaf': [1, 2, 3, 5, 7, 10],\n",
    "    'max_features':[0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "}\n",
    "\n",
    "catboost_params = {\n",
    "    'iterations': [10, 25, 50], \n",
    "    'depth': [1, 2, 3, 4, 5, 10]\n",
    "}\n",
    "\n",
    "ridge_params = {\n",
    "    'alpha': [50, 100, 150, 200, 250, 300, 400, 500]\n",
    "}\n",
    "\n",
    "lasso_params = {\n",
    "    'alpha': [0.5, 0.75, 0.8, .9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5]\n",
    "}\n",
    "\n",
    "lasso_pca_params = {\n",
    "    'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.75, 1, 1.5, 2]\n",
    "}\n",
    "\n",
    "lr_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estimator(name, params, rand=True, random_state=None):\n",
    "    \n",
    "    import random\n",
    "    from numpy import random\n",
    "    from xgboost import XGBRegressor\n",
    "    from lightgbm import LGBMRegressor\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from catboost import CatBoostRegressor\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    \n",
    "    state = random.RandomState(random_state)\n",
    "    \n",
    "    rnd_params = {}\n",
    "    tmp_params = params[name]\n",
    "    if rand == True:\n",
    "        for line in tmp_params.items():\n",
    "            rnd_params[line[0]] = state.choice(line[1])\n",
    "    else:\n",
    "        rnd_params = tmp_params\n",
    "    \n",
    "    if name == 'lgbm':\n",
    "        estimator = LGBMRegressor(random_state=1234, **rnd_params, min_data=1)\n",
    "        \n",
    "    if name == 'xgb':\n",
    "        estimator = XGBRegressor(random_state=1234, **rnd_params)\n",
    "        \n",
    "    if name == 'rf':\n",
    "        estimator = RandomForestRegressor(random_state=1234, **rnd_params)\n",
    "        \n",
    "    if name == 'ridge':\n",
    "        estimator = Ridge(random_state=1234, **rnd_params)\n",
    "        \n",
    "    if name == 'lasso':\n",
    "        estimator = Lasso(random_state=1234, **rnd_params)\n",
    "        \n",
    "    if name == 'catboost':\n",
    "        estimator = CatBoostRegressor(random_state=1234, logging_level='Silent', **rnd_params)\n",
    "        \n",
    "    if name == 'lasso_pca':\n",
    "        estimator = Lasso(random_state=1234, **rnd_params)\n",
    "        \n",
    "    if name == 'lr_pca':\n",
    "        estimator = LinearRegression()\n",
    "\n",
    "    return estimator, rnd_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_y_split(train, val, scale=True, pca=False):\n",
    "    '''\n",
    "    input: train and validation or test datasets\n",
    "    output: datasets split into X features and y response for train / validation or test\n",
    "    '''\n",
    "    \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    X_train = train.select_dtypes(include=['float', 'int', 'uint8']).drop('y_act', axis=1)\n",
    "    y_train = train.y_act\n",
    "    \n",
    "    try:    \n",
    "        X_val = val.select_dtypes(include=['float', 'int', 'uint8']).drop('y_act', axis=1)\n",
    "        y_val = val.y_act\n",
    "    except:\n",
    "        X_val = val.select_dtypes(include=['float', 'int', 'uint8'])\n",
    "        y_val = None\n",
    "    \n",
    "    if scale == True:\n",
    "        X_train = StandardScaler().fit_transform(X_train)\n",
    "        X_val = StandardScaler().fit_transform(X_val)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    if pca == True:\n",
    "        pca = PCA(n_components=10)\n",
    "        pca.fit(X_train)\n",
    "        \n",
    "        X_train = pca.transform(X_train)\n",
    "        X_val = pca.transform(X_val)\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_residuals(estimator, X_train, y_train, X_val, y_val, train_error, val_error):\n",
    "    '''\n",
    "    input: estimator, feature set to be predicted, ground truth\n",
    "    output: sum of residuals for train and validation predictions\n",
    "    '''\n",
    "    predict_train = estimator.predict(X_train)\n",
    "    train_error.append(np.sum((predict_train-y_train)**2))\n",
    "    \n",
    "    predict_val = estimator.predict(X_val)\n",
    "    val_error.append(np.sum(abs(predict_val-y_val)**2))\n",
    "    \n",
    "    return train_error, val_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_compare(df, skip_years):\n",
    "    \n",
    "    from scipy.stats import pearsonr\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    df = df[df.year > df.year.min() + skip_years+1].dropna().reset_index(drop=True)\n",
    "\n",
    "    lr = LinearRegression().fit(df.pred.values.reshape(-1,1), df.y_act)\n",
    "    r_sq_pred = round(lr.score(df.pred.values.reshape(-1,1), df.y_act), 3)\n",
    "    corr_pred = round(pearsonr(df.pred, df.y_act)[0], 3)\n",
    "    \n",
    "    lr = LinearRegression().fit(df.avg_pick.values.reshape(-1,1), df.y_act)\n",
    "    r_sq_avg_pick = round(lr.score(df.avg_pick.values.reshape(-1,1), df.y_act), 3)\n",
    "    corr_avg_pick = abs(round(pearsonr(df.avg_pick, df.y_act)[0], 3))\n",
    "\n",
    "    return [r_sq_pred, corr_pred, r_sq_avg_pick, corr_avg_pick]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(estimators, params, df_train, iterations=50, random_state=None, scale=False, pca=False, skip_years=2):\n",
    "    '''\n",
    "    input: training dataset, estimator\n",
    "    output: out-of-sample errors and predictions for 5 timeframes\n",
    "    '''\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "    \n",
    "    # initialize a parameter tracker dictionary and summary output dataframe\n",
    "    param_tracker = {}\n",
    "    summary = pd.DataFrame()\n",
    "    \n",
    "    #==========\n",
    "    # Complete a Random Hyperparameter search for the given models and parameters\n",
    "    #==========\n",
    "    \n",
    "    for i in range(0, iterations):\n",
    "        \n",
    "        # update random state to pull new params, but keep consistency based on starting state\n",
    "        random_state = random_state + 1\n",
    "        \n",
    "        # print update on progress\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(str(datetime.datetime.now())[:-7])\n",
    "            print('Completed ' + str(i+1) + '/' + str(iterations) + ' iterations')\n",
    "            \n",
    "        # create empty sub-dictionary for current iteration storage\n",
    "        param_tracker[i] = {}\n",
    "        \n",
    "        # create empty lists to store predictions and errors for each estimator\n",
    "        est_predictions=pd.DataFrame()\n",
    "        est_errors=pd.DataFrame()\n",
    "        \n",
    "        #==========\n",
    "        # Loop through estimators with a running time series based training and validation method\n",
    "        #==========\n",
    "        \n",
    "        for est in estimators:\n",
    "\n",
    "            # grab estimator and random parameters for estimator type\n",
    "            estimator, param_tracker[i][est] = get_estimator(est, params, rand=True, random_state=random_state)\n",
    "        \n",
    "            # run through all years for given estimator and save errors and predictions\n",
    "            val_error = []    \n",
    "            train_error = [] \n",
    "            val_predictions = np.array([]) \n",
    "            years = df_train.year.unique()[1:]\n",
    "\n",
    "            #==========\n",
    "            # Loop through years and complete a time-series validation of the given model\n",
    "            #==========\n",
    "            \n",
    "            for m in years:\n",
    "                \n",
    "                # create training set for all previous years and validation set for current year\n",
    "                train_split = df_train[df_train.year < m]\n",
    "                val_split = df_train[df_train.year == m]\n",
    "        \n",
    "                # setting the scale parameter based on the given model\n",
    "                if est == 'ridge' or est == 'lasso' or est == 'knn' or pca == True:\n",
    "                    scale = True\n",
    "    \n",
    "                # splitting the train and validation sets into X_train, y_train, X_val and y_val\n",
    "                X_train, X_val, y_train, y_val = X_y_split(train_split, val_split, scale, pca)\n",
    "        \n",
    "                # fit training data and creating prediction based on validation data\n",
    "                estimator.fit(X_train, y_train)\n",
    "                val_predict = estimator.predict(X_val)\n",
    "                \n",
    "                # skip over the first two year of predictions due to high error for xgb / lgbm\n",
    "                if m > years.min() + skip_years:\n",
    "                    val_predictions = np.append(val_predictions, val_predict, axis=0)\n",
    "                    \n",
    "                    # calculate and append training and validation errors\n",
    "                    train_error, val_error = calc_residuals(estimator, X_train, y_train, X_val, y_val, train_error, val_error)\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "            # append predictions for all validation samples / models (n_samples x m_models)\n",
    "            # and all errors (n_years x m_models) to dataframes \n",
    "            est_predictions = pd.concat([est_predictions, pd.Series(val_predictions, name=est)], axis=1)\n",
    "            est_errors = pd.concat([est_errors, pd.Series(val_error, name=est)], axis=1)\n",
    "        \n",
    "        #==========\n",
    "        # Create an ensemble model based on residual errors from each individual model\n",
    "        #==========\n",
    "        \n",
    "        # create weights based on the mean errors across all years for each model\n",
    "        est_errors = est_errors.iloc[1:, :]\n",
    "        frac = 1 - (est_errors.mean() / (est_errors.mean().sum()))\n",
    "        weights = round(frac / frac.sum(), 3)          \n",
    "        \n",
    "        # multiply the outputs from each model by their weights and sum to get final prediction\n",
    "        wt_results = pd.concat([df_train[df_train.year > years.min() + skip_years].reset_index(drop=True),\n",
    "                                pd.Series((est_predictions*weights).sum(axis=1), name='pred')],\n",
    "                                axis=1)\n",
    "        \n",
    "        #==========\n",
    "        # Calculate Error Metrics and Prepare Export\n",
    "        #==========\n",
    "        \n",
    "        # calculate r_squared and correlation for n+1 results using predictions and avg_pick\n",
    "        compare_metrics = error_compare(wt_results, skip_years)\n",
    "\n",
    "        # calculate the RMSE and MAE of the ensemble predictions\n",
    "        wt_rmse = round(np.sqrt(mean_squared_error(wt_results.pred, df_train[df_train.year > years.min() + skip_years].reset_index(drop=True).y_act)), 2)\n",
    "        wt_mae = round(mean_absolute_error(wt_results.pred, df_train[df_train.year > years.min() + skip_years].reset_index(drop=True).y_act), 2)\n",
    "        \n",
    "        #--------\n",
    "        # create a list of model weights based on residuals, as well s the average RMSE & MAE \n",
    "        # for the ensemble predictions to append to the output dataframe for export\n",
    "        #--------\n",
    "        \n",
    "        # generate a list of weights used for models\n",
    "        wt_list = list(weights.values)\n",
    "        \n",
    "        # append rmse and mae metrics for a given ensemble\n",
    "        wt_list.append(wt_rmse)\n",
    "        wt_list.append(wt_mae)\n",
    "        \n",
    "        # extend the results with the r2 and correlation metrics for the ensemble and adp\n",
    "        wt_list.extend(compare_metrics)\n",
    "        summary = summary.append([(wt_list)])\n",
    "    \n",
    "    #==========\n",
    "    # Update Summary Table of Weights and Error Metric Results\n",
    "    #==========\n",
    "        \n",
    "    summary = summary.reset_index(drop=True)\n",
    "    estimators.extend(['rmse', 'mae', 'r2_pred', 'c_pred', 'r2_adp', 'c_adp'])\n",
    "    summary.columns = estimators\n",
    "    summary = summary.sort_values(by=['rmse', 'r2_pred'], ascending=[True, False])\n",
    "    \n",
    "    return param_tracker, summary, wt_results, est_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(best_result, param_list, summary, df_train, df_predict, figsize=(6,15)):\n",
    "    \n",
    "    param_list = param_list[best_result]\n",
    "    weights = summary.iloc[best_result, :len(param_list)]\n",
    "    est_names = summary.columns[:len(param_list)]\n",
    "    \n",
    "    X_train, X_val, y_train, _ = X_y_split(df_train, df_predict)\n",
    "    \n",
    "    predictions = pd.DataFrame()\n",
    "    \n",
    "    models = []\n",
    "    for est in est_names[0:len(param_list)]:\n",
    "        estimator, _ = get_estimator(est, param_list, rand=False)\n",
    "        \n",
    "        estimator.fit(X_train, y_train)\n",
    "        test_predictions = pd.Series(estimator.predict(X_val), name=est)\n",
    "        \n",
    "        predictions = pd.concat([predictions, test_predictions], axis=1)\n",
    "        models.append(estimator)\n",
    "        \n",
    "    wt_predictions = pd.Series((predictions*weights).sum(axis=1), name='pred')\n",
    "    wt_predictions = pd.concat([df_predict.reset_index(drop=True), wt_predictions], axis=1)\n",
    "    \n",
    "    to_plot = wt_predictions.pred\n",
    "    to_plot.index = wt_predictions.player\n",
    "    to_plot.sort_values().plot.barh(figsize=figsize);\n",
    "    plt.show()\n",
    "    \n",
    "    return wt_predictions, models, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Model and Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# Calculate fantasy points based on predictions and point values\n",
    "#==========\n",
    "\n",
    "def format_results(df_train_results, df_test_results, df_train, df_predict, pts_list):\n",
    "\n",
    "    # calculate fantasy points for the train set\n",
    "    df_train_results.iloc[:, 2:] = df_train_results.iloc[:, 2:] * pts_list\n",
    "    df_train_results.loc[:, 'pred'] = df_train_results.iloc[:, 2:].sum(axis=1)\n",
    "\n",
    "    # calculate fantasy points for the test set\n",
    "    df_test_results.iloc[:, 1:] = df_test_results.iloc[:, 1:] * pts_list\n",
    "    df_test_results.loc[:, 'pred'] = df_test_results.iloc[:, 1:].sum(axis=1)\n",
    "\n",
    "    # add actual results and adp to the train df\n",
    "    df_train_results = pd.merge(df_train_results, df_train[['player', 'year', 'avg_pick', 'y_act']],\n",
    "                               how='inner', left_on=['player', 'year'], right_on=['player', 'year'])\n",
    "\n",
    "    # add adp to the test df\n",
    "    df_test_results = pd.merge(df_test_results, df_predict[['player', 'avg_pick']],\n",
    "                               how='inner', left_on='player', right_on='player')\n",
    "\n",
    "    # calculate the residual between the predictions and results\n",
    "    df_train_results['error'] = df_train_results.pred - df_train_results.y_act\n",
    "    \n",
    "    return df_train_results, df_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searching(est, params, X_grid, y_grid, n_jobs=3):\n",
    "    '''\n",
    "    Function to perform GridSearchCV and return the test RMSE, as well as the \n",
    "    optimized and fitted model\n",
    "    '''\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    \n",
    "    Search = GridSearchCV(estimator=est,\n",
    "                          param_grid=params,\n",
    "                          scoring='neg_mean_squared_error',\n",
    "                          n_jobs=n_jobs,\n",
    "                          return_train_score=True)\n",
    "   \n",
    "    search_results = Search.fit(X_grid, y_grid)\n",
    "   \n",
    "    best_params = search_results.cv_results_['params'][search_results.best_index_]\n",
    "   \n",
    "    est.set_params(**best_params)\n",
    "    \n",
    "    test_rmse = cross_val_score(est, X_grid, y_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "    test_rmse = np.mean(np.sqrt(np.abs(test_rmse)))\n",
    "    \n",
    "    print('Best RMSE: ', round(test_rmse, 3))\n",
    "   \n",
    "    est.fit(X_grid, y_grid)\n",
    "       \n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class clustering():\n",
    "\n",
    "    def __init__(self, df_train, df_test):\n",
    "    \n",
    "        import pandas as pd\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        # create self versions of train and test\n",
    "        self.df_train = df_train\n",
    "        self.df_test = df_test\n",
    "    \n",
    "        # create df for clustering by selecting numeric values and dropping y_act\n",
    "        self.X_train = df_train.select_dtypes(include=['float', 'int', 'uint8']).drop(['y_act', 'error'], axis=1)\n",
    "        self.X_test = df_test.select_dtypes(include=['float', 'int', 'uint8']).drop([], axis=1)\n",
    "        self.y = df_train.y_act\n",
    "        \n",
    "    def explore_k(self, k=15):\n",
    "        \n",
    "        from scipy.spatial.distance import cdist\n",
    "        from sklearn.cluster import KMeans\n",
    "        from sklearn import metrics\n",
    "\n",
    "        # k means determine k\n",
    "        X_train = self.X_train\n",
    "        distortions = []\n",
    "        silhouettes = []\n",
    "        K = range(2,k)\n",
    "        for k in K:\n",
    "            kmeanModel = KMeans(n_clusters=k, random_state=1).fit(X_train)\n",
    "            kmeanModel.fit(X_train);\n",
    "            distortions.append(sum(np.min(cdist(X_train, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / X_train.shape[0]);\n",
    "            \n",
    "            silhouettes.append(metrics.silhouette_score(X_train, kmeanModel.labels_))\n",
    "                               \n",
    "        # create elbow plot\n",
    "        fig = plt.figure()\n",
    "        ax1 = fig.add_subplot(121)\n",
    "        ax1.plot(K, distortions, 'bx-')\n",
    "        ax1.set_title(\"Distortion\");\n",
    "        \n",
    "        ax2 = fig.add_subplot(122)\n",
    "        ax2.plot(K, silhouettes, 'x-')\n",
    "        ax2.set_title(\"Silhouette Score\");\n",
    "        \n",
    "        \n",
    "    def fit_and_predict(self, k=10):\n",
    "        \n",
    "        from sklearn.cluster import KMeans\n",
    "\n",
    "        # retrain with optimal cluster \n",
    "        self.k = k\n",
    "        self.kmeans = KMeans(n_clusters=k, random_state=1).fit(self.X_train)\n",
    "        self.train_results = self.kmeans.predict(self.X_train)\n",
    "        self.test_results = self.kmeans.predict(self.X_test) \n",
    "    \n",
    "        # add cluster results to the df_train and df_test\n",
    "        self.df_train['cluster'] = self.train_results\n",
    "        self.df_test['cluster'] = self.test_results\n",
    "\n",
    "        \n",
    "    def fit_and_predict_tree(self):\n",
    "        \n",
    "        from sklearn.tree import DecisionTreeRegressor\n",
    "        \n",
    "        self.tree = searching(DecisionTreeRegressor(random_state=1), pos['RB']['tree_params'], self.X_train, self.y)\n",
    "        \n",
    "        self.df_train = pd.merge(self.df_train, pd.DataFrame(self.tree.apply(self.X_train), columns=['cluster']), \n",
    "                                    how='inner', left_index=True, right_index=True)\n",
    "\n",
    "        self.df_test = pd.merge(self.df_test, pd.DataFrame(self.tree.apply(self.X_test), columns=['cluster']),\n",
    "                                how='inner', left_index=True, right_index=True)\n",
    "        \n",
    "        \n",
    "        print('Cluster List: ', list(self.df_test.cluster.unique()))\n",
    "        \n",
    "        \n",
    "    def tree_plot(self):\n",
    " \n",
    "        from sklearn.externals.six import StringIO \n",
    "        from IPython.display import Image \n",
    "        from sklearn.tree import export_graphviz\n",
    "        import pydotplus\n",
    "\n",
    "        dot_data = StringIO()\n",
    "\n",
    "        export_graphviz(self.tree, out_file=dot_data, \n",
    "                        filled=True, rounded=True,\n",
    "                        special_characters=True,\n",
    "                        feature_names=self.X_train.columns)\n",
    "\n",
    "        graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) \n",
    "        nodes = graph.get_node_list()\n",
    "\n",
    "        for node in nodes:\n",
    "            if node.get_name() not in ('node', 'edge'):\n",
    "                values = self.tree.tree_.value[int(node.get_name())][0]\n",
    "                #color only nodes where only one class is present\n",
    "                if values > 20 :   \n",
    "                    node.set_fillcolor('#d74401')\n",
    "                elif values > 16:   \n",
    "                    node.set_fillcolor('#f06511')\n",
    "                elif values > 12:   \n",
    "                    node.set_fillcolor('#fdab67')\n",
    "                elif values > 8:   \n",
    "                    node.set_fillcolor('#b7cde2')\n",
    "                else:\n",
    "                    node.set_fillcolor('#3679a8')\n",
    "\n",
    "        return Image(graph.create_png())\n",
    "        \n",
    "    \n",
    "    def add_fit_metrics(self):\n",
    "        \n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        \n",
    "        final_train = pd.DataFrame()\n",
    "        final_test = pd.DataFrame()\n",
    "        \n",
    "        for j in list(self.df_train.cluster.unique()):\n",
    "        \n",
    "            test = self.df_test[self.df_test.cluster == j]\n",
    "            train = self.df_train[self.df_train.cluster==j]\n",
    "            \n",
    "            try:\n",
    "                # create a linear regression instance\n",
    "                lr = LinearRegression()\n",
    "                X=train.pred.values.reshape(-1,1)\n",
    "                y=train.y_act\n",
    "\n",
    "                # calculate rmse of predicted values vs. actual score\n",
    "                scores = cross_val_score(lr, X, y, scoring='neg_mean_absolute_error', cv=X.shape[0])\n",
    "                mae = np.mean(abs(scores))\n",
    "\n",
    "                # update predictions based on actual score\n",
    "                lr.fit(X, y)\n",
    "                X_test = test.pred.values.reshape(-1,1)\n",
    "                predictions = lr.predict(X_test)\n",
    "                predictions_train = lr.predict(X)\n",
    "\n",
    "                # output accuracy metrics and predictions\n",
    "                rsq = round(lr.score(X,y), 3)\n",
    "                test['cluster_pred'] = predictions\n",
    "                test['rsq'] = rsq\n",
    "                test['mae'] = mae\n",
    "\n",
    "                rsq = round(lr.score(X,y), 3)\n",
    "                train['cluster_pred'] = predictions_train\n",
    "                train['rsq'] = rsq\n",
    "                train['mae'] = mae\n",
    "\n",
    "                final_test = pd.concat([final_test, test], axis=0)\n",
    "                final_train = pd.concat([final_train, train], axis=0)\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        self.df_test = final_test\n",
    "        self.df_train = final_train\n",
    "        \n",
    "        return self.df_train, self.df_test\n",
    "            \n",
    "    \n",
    "    def show_results(self, j):\n",
    "        from scipy.stats import pearsonr\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        \n",
    "        test = self.df_test[self.df_test.cluster == j]\n",
    "        train = self.df_train[self.df_train.cluster==j]\n",
    "        \n",
    "        # calculate and print all percentiles for players in group\n",
    "        percentile = np.percentile(self.df_train[self.df_train.cluster == j].y_act, q=[5, 25, 50, 75, 95])\n",
    "        print('Fantasy PPG for Various Percentiles')\n",
    "        print('-----------------------------------')\n",
    "        print('5th percentile: ', round(percentile[0], 2))\n",
    "        print('25th percentile:', round(percentile[1], 2))\n",
    "        print('50th percentile:', round(percentile[2], 2))\n",
    "        print('75th percentile:', round(percentile[3], 2))\n",
    "        print('95th percentile:', round(percentile[4], 2))\n",
    "    \n",
    "        # show plot of historical actual results for cluster\n",
    "        ax = train.y_act.plot.hist()\n",
    "        ax.set_xlabel('Fantasy PPG Actual')\n",
    "    \n",
    "        # show plot of predicted vs actual points for cluster\n",
    "        ax = train.plot.scatter('pred', 'y_act')\n",
    "        ax.set_xlabel('Predicted Fantasy PPG')\n",
    "        ax.set_ylabel('Actual Fantasy PPG')\n",
    "        \n",
    "        # show correlation coefficient between actual and predicted points for cluster\n",
    "        print('')\n",
    "        print('Pred to Actual Correlation')\n",
    "        print(round(train.rsq.mean(), 3))\n",
    "        \n",
    "        # show examples of past players in cluster\n",
    "        current = test.sort_values(by='pred', ascending=False)[['player', 'pred', 'cluster_pred']]\n",
    "        \n",
    "        return current\n",
    "    \n",
    "    \n",
    "    def create_distributions(self, prior_repeats=5, show_plots=True):\n",
    "        \n",
    "        # historical standard deviation and mean for actual results\n",
    "        hist_std = self.df_train.groupby('player').agg('std').dropna()\n",
    "        hist_mean = self.df_train.groupby('player').agg('mean').dropna()\n",
    "        \n",
    "        # merge historicaly mean and standard deviations\n",
    "        hist_mean_std = pd.merge(hist_std, hist_mean, how='inner', left_index=True, right_index=True)\n",
    "        \n",
    "        # calculate global coefficient of variance for players that don't have enough historical results\n",
    "        global_cv = (hist_mean_std.y_act_x / hist_mean_std.y_act_y).mean()\n",
    "        \n",
    "        #==========\n",
    "        # Loop to Create Prior and Posterior Distributions\n",
    "        #==========\n",
    "\n",
    "        self.df_test = self.df_test.sort_values(by='pred', ascending=False)\n",
    "\n",
    "        results = pd.DataFrame()\n",
    "\n",
    "        for player in self.df_test.player[0:]:\n",
    "\n",
    "            # set seed\n",
    "            np.random.seed(1234)\n",
    "\n",
    "            # create list for results\n",
    "            results_list = [player]\n",
    "\n",
    "            #==========\n",
    "            # Pull Out Predictions and Actual Results for Given Player to Create Prior\n",
    "            #==========\n",
    "\n",
    "            #--------\n",
    "            # Extract this year's results and multiply by prior_repeats\n",
    "            #--------\n",
    "\n",
    "            # extract predictions from ensemble and updated predictions based on cluster fit\n",
    "            ty = self.df_test.loc[self.df_test.player == player, ['player', 'pred']]\n",
    "            ty_c = self.df_test.loc[self.df_test.player == player, ['player', 'cluster_pred']]\n",
    "\n",
    "            # replicate the predictions to increase n_0 for the prior\n",
    "            ty = pd.concat([ty]*prior_repeats, ignore_index=True)\n",
    "            ty_c = pd.concat([ty_c]*prior_repeats, ignore_index=True)\n",
    "\n",
    "            # rename the prediction columns to 'points'\n",
    "            ty = ty.rename(columns={'pred': 'points'})\n",
    "            ty_c = ty_c.rename(columns={'cluster_pred': 'points'})\n",
    "\n",
    "            #--------\n",
    "            # Extract previous year's results, if available\n",
    "            #--------\n",
    "\n",
    "            # pull out the most recent 5 years worth of performance, if available\n",
    "            py = self.df_train.loc[self.df_train.player == player, ['player', 'y_act']].reset_index(drop=True)[0:5]\n",
    "\n",
    "            # convert y_act to points name\n",
    "            py = py.rename(columns={'y_act': 'points'})\n",
    "\n",
    "            #--------\n",
    "            # Create Prior Distribution and Conjugant Hyperparameters\n",
    "            #--------\n",
    "\n",
    "            # combine this year's prediction, the cluster prediction, and previous year actual, if available\n",
    "            priors = pd.concat([ty, ty_c, py], axis=0)\n",
    "\n",
    "            # set m_0 to the priors mean\n",
    "            m_0 = priors.points.mean()\n",
    "\n",
    "            # Create the prior variance through a weighted average of the actual previous year\n",
    "            # performance and a global coefficient of variance multiple by the prior mean.\n",
    "            # If there is not at least 3 years of previous data, simply use the global cv.\n",
    "            if py.shape[0] >= 3:\n",
    "                s2_0 = ((py.shape[0]*py.points.std()**2) + (2*prior_repeats*(m_0 * global_cv)**2)) / (py.shape[0] + 2*prior_repeats)\n",
    "            else:\n",
    "                s2_0 = (m_0 * global_cv)**2\n",
    "\n",
    "            # set the prior sample size and degrees of freedom\n",
    "            n_0 = priors.shape[0]\n",
    "            v_0 = n_0 - 1\n",
    "\n",
    "            # calculate the prior distribution\n",
    "            prior_y = np.random.normal(loc=m_0, scale=np.sqrt(s2_0), size=10000)\n",
    "\n",
    "            #--------\n",
    "            # Create the Data and Data Hyperparameters\n",
    "            #--------\n",
    "\n",
    "            # pull out the cluster for the current player\n",
    "            ty_cluster = self.df_test[self.df_test.player == player].cluster.values[0]\n",
    "\n",
    "            # create a list of the actual points scored to be used as updating data\n",
    "            update_data = self.df_train[self.df_train.cluster == ty_cluster].y_act\n",
    "\n",
    "            # set ybar to the mean of the update data\n",
    "            ybar = update_data.mean()\n",
    "\n",
    "            # calculate the standard deviation based on the 5th and 95th percentiles\n",
    "            s2 = ((np.percentile(update_data, q=95)-np.percentile(update_data, q=5)) / 4.0)**2\n",
    "\n",
    "            # determine the n as the number of data points\n",
    "            n = len(update_data)\n",
    "\n",
    "            #--------\n",
    "            # Create the Posterior Distribution \n",
    "            #--------\n",
    "\n",
    "            # set the poster n samples\n",
    "            n_n = n_0 + n \n",
    "\n",
    "            # update the poster mean\n",
    "            m_n = (n*ybar + n_0*m_0) / n_n \n",
    "\n",
    "            # update the posterior degrees of freedom\n",
    "            v_n = v_0 + n \n",
    "\n",
    "            # update the posterior variance\n",
    "            s2_n = ((n-1)*s2 + v_0*s2_0 + (n_0*n*(m_0 - ybar)**2)/n_n)/v_n\n",
    "\n",
    "            # calculate the gamma distribution and convert to sigma\n",
    "            phi = np.random.gamma(shape=v_n/2, scale=2/(s2_n*v_n), size=10000)\n",
    "            sigma = 1/np.sqrt(phi)\n",
    "\n",
    "            # calculate the posterior mean\n",
    "            post_mu = np.random.normal(loc=m_n, scale=sigma/(np.sqrt(n_n)), size=10000)\n",
    "\n",
    "            # create the posterior distribution\n",
    "            pred_y =  np.random.normal(loc=post_mu, scale=sigma, size=10000)\n",
    "\n",
    "            results_list.extend(pred_y*16)\n",
    "            results = pd.concat([results, pd.DataFrame(results_list).T], axis=0)\n",
    "\n",
    "            if show_plots == True:\n",
    "\n",
    "                # set plot bins based on the width of the distribution\n",
    "                bins = int((np.percentile(pred_y, 97.5)*16 - np.percentile(pred_y, 2.55)*16) / 10)\n",
    "\n",
    "                # print the player name\n",
    "                print(player)\n",
    "\n",
    "                # create a plot of the prior distribution and a line for the mean\n",
    "                pd.Series(prior_y*16, name='Prior').plot.hist(alpha=0.4, color='grey', bins=bins, legend=True, \n",
    "                                                              xlim=[0, self.df_test.pred.max()*16*1.75])\n",
    "                plt.axvline(x=prior_y.mean()*16, alpha=0.8, linestyle='--', color='grey')\n",
    "\n",
    "                # create a plot of the posterior distribution and a line for the mean\n",
    "                pd.Series(pred_y*16, name='Posterior').plot.hist(alpha=0.4, color='teal', bins=bins, legend=True,\n",
    "                                                             edgecolor='black', linewidth=1)\n",
    "                plt.axvline(x=pred_y.mean()*16, alpha=1, linestyle='--', color='black')\n",
    "\n",
    "                # show the plots\n",
    "                plt.show();\n",
    "\n",
    "        return results.reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
