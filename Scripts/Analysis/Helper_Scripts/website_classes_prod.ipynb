{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============\n",
    "# Load Packages\n",
    "#==============\n",
    "\n",
    "# set core path\n",
    "path = '/Users/Mark/Documents/Github/Fantasy_Football/'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import os\n",
    "\n",
    "# change directory temporarily to helper scripts\n",
    "os.chdir(path + 'Scripts/Analysis/Helper_Scripts')\n",
    "\n",
    "# load custom helper functions\n",
    "from helper_functions import *;\n",
    "\n",
    "\n",
    "#===============\n",
    "# Settings and User Inputs\n",
    "#===============\n",
    "\n",
    "# postgres login information\n",
    "pg_log = {\n",
    "    'USER': 'postgres',\n",
    "    'PASSWORD': 'Ctdim#1bf!!!!!',\n",
    "    'HOST': 'localhost',\n",
    "    'PORT': '5432', \n",
    "    'DATABASE_NAME': 'fantasyfootball'\n",
    "}\n",
    "\n",
    "# create engine for connecting to database\n",
    "engine = create_engine('postgres+psycopg2://{}:{}@{}:{}/{}'.format(pg_log['USER'], pg_log['PASSWORD'], pg_log['HOST'],\n",
    "                                                                   pg_log['PORT'], pg_log['DATABASE_NAME']))\n",
    "\n",
    "# define dictionary that contains all relevant point values\n",
    "pts_dict = {}\n",
    "pts_dict['QB'] = [0.04, 5, 0.1, 7, -2, -1]\n",
    "pts_dict['RB'] = [0.1, 0.1, 0.5, 7]\n",
    "pts_dict['WR'] = [0.1, 0.5, 7]\n",
    "pts_dict['TE'] = [0.1, 0.5, 7]\n",
    "\n",
    "# set random user id\n",
    "user_id=20\n",
    "\n",
    "# specify schema and table to write out intermediate results\n",
    "table_info = {\n",
    "    'schema': 'website',\n",
    "}\n",
    "\n",
    "# set year\n",
    "year = 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulling in Player Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_train_data(pts_dict, pos, engine, table_info, set_year=2018):\n",
    "    \n",
    "    '''\n",
    "    This function reads in all raw statistical predictions from the ensemble model for a given\n",
    "    position group and then converts it into predicted points scored based on a given scoring system.\n",
    "\n",
    "    Input: Database connection to pull stored raw statistical data, a dictionary containing points\n",
    "           per statistical category, and a position to pull.\n",
    "    Return: A dataframe with a player, their raw statistical projections and the predicted points\n",
    "            scored for a given scoring system.\n",
    "    '''\n",
    "\n",
    "    # create empty dataframe to store all player predicted points\n",
    "    data = pd.DataFrame()\n",
    "\n",
    "    #--------\n",
    "    # Connect to Database and Pull Player Data\n",
    "    #--------\n",
    "\n",
    "    df_train_results = pd.read_sql_query('SELECT * FROM {}.\"{}_Train_Results_{}\"' \\\n",
    "                                         .format(table_info['schema'], pos[1:], str(set_year)), engine)\n",
    "    df_test_results = pd.read_sql_query('SELECT * FROM {}.\"{}_Test_Results_{}\"' \\\n",
    "                                        .format(table_info['schema'], pos[1:], str(set_year)), engine)\n",
    "    df_train = pd.read_sql_query('SELECT * FROM {}.\"{}_Train_{}\"' \\\n",
    "                                 .format(table_info['schema'], pos[1:], str(set_year)), engine)\n",
    "    df_predict = pd.read_sql_query('SELECT * FROM {}.\"{}_Predict_{}\"' \\\n",
    "                                   .format(table_info['schema'], pos[1:], str(set_year)), engine)\n",
    "\n",
    "    #--------\n",
    "    # Calculate Fantasy Points for Given Scoring System\n",
    "    #--------\n",
    "\n",
    "    # pass in raw statistical results and convert to fantasy points scored\n",
    "    df_train_results, df_test_results = format_results(df_train_results, df_test_results, \n",
    "                                                       df_train, df_predict, \n",
    "                                                       pts_dict[pos[1:]])\n",
    "    # drop the year from the dataset\n",
    "    df_train_results = df_train_results.drop('year', axis=1)\n",
    "\n",
    "    return df_train_results, df_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGeneration():\n",
    "    \n",
    "    def __init__(self, df_train, df_test):\n",
    "    \n",
    "        import pandas as pd\n",
    "        \n",
    "        # create self versions of train and test\n",
    "        self.df_train = df_train\n",
    "        self.df_test = df_test\n",
    "    \n",
    "        # create df for clustering by selecting numeric values and dropping y_act\n",
    "        self.X_train = df_train.select_dtypes(include=['float', 'int', 'uint8']).drop(['y_act', 'error'], axis=1)\n",
    "        self.X_test = df_test.select_dtypes(include=['float', 'int', 'uint8']).drop([], axis=1)\n",
    "        self.y = df_train.y_act\n",
    "    \n",
    "        #=========\n",
    "        # Set the RF search params for each position\n",
    "        #=========\n",
    "\n",
    "        self.pos = {'QB': {}, 'RB': {}, 'WR': {}, 'TE': {}}\n",
    "\n",
    "        self.pos['QB']['tree_params'] = {\n",
    "            'max_depth': [4, 5],\n",
    "            'min_samples_split': [2],\n",
    "            'min_samples_leaf': [15, 20, 25],\n",
    "            'splitter': ['random']\n",
    "        }\n",
    "\n",
    "        self.pos['RB']['tree_params'] = {\n",
    "            'max_depth': [5, 6, 7],\n",
    "            'min_samples_split': [2],\n",
    "            'min_samples_leaf': [15, 20, 25],\n",
    "            'splitter': ['random']\n",
    "        }\n",
    "\n",
    "        self.pos['WR']['tree_params'] = {\n",
    "            'max_depth': [4, 5, 6],\n",
    "            'min_samples_split': [2],\n",
    "            'min_samples_leaf': [20, 25, 30],\n",
    "            'splitter': ['random']\n",
    "        }\n",
    "\n",
    "\n",
    "        self.pos['TE']['tree_params'] = {\n",
    "            'max_depth': [4, 5],\n",
    "            'min_samples_split': [2],\n",
    "            'min_samples_leaf': [15, 20, 25],\n",
    "            'splitter': ['random']\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _searching(est, params, X_grid, y_grid, n_jobs=1):\n",
    "        '''\n",
    "        Function to perform GridSearchCV and return the test RMSE, as well as the \n",
    "        optimized and fitted model\n",
    "        '''\n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "\n",
    "        # set up GridSearch object\n",
    "        Search = GridSearchCV(estimator=est,\n",
    "                              param_grid=params,\n",
    "                              scoring='neg_mean_squared_error',\n",
    "                              n_jobs=n_jobs,\n",
    "                              cv=3,\n",
    "                              return_train_score=False,\n",
    "                              iid=False)\n",
    "\n",
    "        # try all combination of parameters with the fit\n",
    "        search_results = Search.fit(X_grid, y_grid)\n",
    "\n",
    "        # extract best estimator parameters and create model object with them\n",
    "        best_params = search_results.cv_results_['params'][search_results.best_index_]\n",
    "        est.set_params(**best_params)\n",
    "\n",
    "        # fit the optimal estimator with the data\n",
    "        est.fit(X_grid, y_grid)\n",
    "\n",
    "        return est\n",
    "\n",
    "\n",
    "        \n",
    "    def fit_and_predict_tree(self, pos, print_results=False):\n",
    "        \n",
    "        #----------\n",
    "        # Train the Decision Tree with GridSearch optimization\n",
    "        #----------\n",
    "        \n",
    "        from sklearn.tree import DecisionTreeRegressor\n",
    "        \n",
    "        # train decision tree with _searching method\n",
    "        dtree = self._searching(DecisionTreeRegressor(random_state=1), self.pos[pos]['tree_params'], \n",
    "                               self.X_train, self.y)\n",
    "        \n",
    "        #----------\n",
    "        # Calculate each cluster's mean and standard deviation\n",
    "        #----------\n",
    "\n",
    "        # pull out the training clusters and cbind with the actual points scored\n",
    "        train_results = pd.concat([pd.Series(dtree.apply(self.X_train), name='Cluster'), self.y], axis=1)\n",
    "\n",
    "        # calculate the average and standard deviation of points scored by cluster\n",
    "        train_results = train_results.groupby('Cluster', as_index=False).agg({'y_act': ['mean', 'std']})\n",
    "        train_results.columns = ['Cluster', 'ClusterMean', 'ClusterStd']\n",
    "\n",
    "        #----------\n",
    "        # Add the cluster to test results and resulting group mean / std: Player | Pred | StdDev\n",
    "        #----------\n",
    "\n",
    "        # grab the player, prediction, and add cluster to dataset\n",
    "        test_results = pd.concat([self.df_test[['player', 'pred']], \n",
    "                                  pd.Series(dtree.apply(self.X_test), name='Cluster')], axis=1)\n",
    "\n",
    "        # merge the test results with the train result on cluster to add mean cluster and std\n",
    "        test_results = pd.merge(test_results, train_results, how='inner', left_on='Cluster', right_on='Cluster')\n",
    "\n",
    "        # calculate an overall prediction mean\n",
    "        test_results['PredMean'] = (0.5*test_results.pred + 0.5*test_results.ClusterMean)\n",
    "        \n",
    "        # pull out relevant results for creating distributions\n",
    "        test_results = test_results[['player', 'PredMean', 'ClusterStd']]\n",
    "        \n",
    "        return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start =time.time()\n",
    "\n",
    "distributions = pd.DataFrame()\n",
    "for pos in ['aQB', 'bRB', 'cWR', 'dTE']:\n",
    "\n",
    "    train_results, test_results = rf_train_data(pts_dict, pos, engine, table_info)\n",
    "    \n",
    "    cluster_dev = DataGeneration(train_results, test_results)\n",
    "    dist_input = cluster_dev.fit_and_predict_tree(pos[1:])\n",
    "    dist_input['pos'] = pos[1:]\n",
    "    distributions = pd.concat([distributions, dist_input])\n",
    "\n",
    "distributions = distributions.reset_index(drop=True)\n",
    "data = []\n",
    "for row in distributions.iterrows():\n",
    "    dist = list(np.random.normal(loc=row[1]['PredMean'], scale=row[1]['ClusterStd'], size=1500)*16)\n",
    "    data.append(dist)\n",
    "    \n",
    "data = pd.concat([distributions.player, distributions.pos, pd.DataFrame(data)], axis=1)\n",
    "time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
