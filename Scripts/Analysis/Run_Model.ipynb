{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mark/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# core packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sqlite3\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sqlalchemy import create_engine\n",
    "from imblearn.over_sampling import SMOTE\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# jupyter specifications\n",
    "pd.options.mode.chained_assignment = None\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# plotting functions\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set core path\n",
    "path = '/Users/Mark/Documents/Github/Fantasy_Football/'\n",
    "\n",
    "# change directory temporarily to helper scripts\n",
    "os.chdir(path + 'Scripts/Analysis/Helper_Scripts')\n",
    "\n",
    "# load custom plot functions\n",
    "from my_plot import PrettyPlot\n",
    "PrettyPlot(plt)\n",
    "\n",
    "# load custom helper functions and ensure lightgbm runs\n",
    "from helper_functions import *\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# General Setting\n",
    "#==========\n",
    "\n",
    "db_name = 'Model_Inputs.sqlite3'\n",
    "\n",
    "# set to position to analyze: 'RB', 'WR', 'QB', or 'TE'\n",
    "set_pos = 'RB'\n",
    "\n",
    "\n",
    "#==========\n",
    "# Postgres Database\n",
    "#==========\n",
    "\n",
    "# postgres login information\n",
    "pg_log = {\n",
    "    'USER': 'postgres',\n",
    "    'PASSWORD': 'Ctdim#1bf!!!!!',\n",
    "    'HOST': 'localhost',\n",
    "    'PORT': '5432', \n",
    "    'DATABASE_NAME': 'fantasyfootball'\n",
    "}\n",
    "\n",
    "# create engine for connecting to database\n",
    "engine = create_engine('postgres+psycopg2://{}:{}@{}:{}/{}'.format(pg_log['USER'], pg_log['PASSWORD'], pg_log['HOST'],\n",
    "                                                                   pg_log['PORT'], pg_log['DATABASE_NAME']))\n",
    "\n",
    "# specify schema and table to write out intermediate results\n",
    "table_info = {\n",
    "    'engine': engine,\n",
    "    'schema': 'websitedev',\n",
    "}\n",
    "\n",
    "#==========\n",
    "# Data Filtering\n",
    "#==========\n",
    "\n",
    "# set year to analyze\n",
    "set_year = 2019\n",
    "\n",
    "# set required touches (or pass thrown) and games for consideration\n",
    "req_games = 8\n",
    "\n",
    "\n",
    "#==========\n",
    "# Fantasy Point Values\n",
    "#==========\n",
    "\n",
    "# define point values for all statistical categories\n",
    "pass_yd_per_pt = 0.04 \n",
    "pass_td_pt = 4\n",
    "int_pts = -2\n",
    "sacks = -1\n",
    "rush_yd_per_pt = 0.1 \n",
    "rec_yd_per_pt = 0.1\n",
    "rush_rec_td = 7\n",
    "ppr = 0.5\n",
    "fumble = -2\n",
    "\n",
    "# creating dictionary containing point values for each position\n",
    "pts_dict = {}\n",
    "pts_dict['QB'] = [pass_yd_per_pt, pass_td_pt, rush_yd_per_pt, rush_rec_td, int_pts, sacks]\n",
    "pts_dict['RB'] = [rush_yd_per_pt, rec_yd_per_pt, ppr, rush_rec_td]\n",
    "pts_dict['WR'] = [rec_yd_per_pt, ppr, rush_rec_td]\n",
    "pts_dict['TE'] = [rec_yd_per_pt, ppr, rush_rec_td]\n",
    "\n",
    "\n",
    "#==========\n",
    "# Model Settings\n",
    "#==========\n",
    "\n",
    "pos['QB']['req_touch'] = 50\n",
    "pos['RB']['req_touch'] = 50\n",
    "pos['WR']['req_touch'] = 30\n",
    "pos['TE']['req_touch'] = 30\n",
    "\n",
    "pos['QB']['earliest_year'] = 2010\n",
    "pos['RB']['earliest_year'] = 2001\n",
    "pos['WR']['earliest_year'] = 1999\n",
    "pos['TE']['earliest_year'] = 1999\n",
    "\n",
    "pos['QB']['skip_years'] = 1\n",
    "pos['RB']['skip_years'] = 3\n",
    "pos['WR']['skip_years'] = 3\n",
    "pos['TE']['skip_years'] = 3\n",
    "\n",
    "pos['QB']['iter_rounds'] = 50\n",
    "pos['RB']['iter_rounds'] = 100\n",
    "pos['WR']['iter_rounds'] = 100\n",
    "pos['TE']['iter_rounds'] = 100\n",
    "\n",
    "pos['QB']['use_ay'] = False\n",
    "pos['RB']['use_ay'] = False\n",
    "pos['WR']['use_ay'] = True\n",
    "pos['TE']['use_ay'] = True\n",
    "\n",
    "# whether or not to plot feature importances following modeling\n",
    "plot_importance = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# Pull and clean compiled data\n",
    "#==========\n",
    "\n",
    "# connect to database and pull in positional data\n",
    "conn = sqlite3.connect(path + 'Data/' + db_name)\n",
    "df = pd.read_sql_query('SELECT * FROM ' + set_pos + '_' + str(set_year), con=conn)\n",
    "\n",
    "if pos[set_pos]['use_ay']:\n",
    "    ay = pd.read_sql_query('SELECT * FROM AirYards', con=sqlite3.connect(path + 'Data/Season_Stats.sqlite3'))\n",
    "    df = pd.merge(df, ay, how='inner', left_on=['player', 'year'], right_on=['player', 'year'])\n",
    "\n",
    "# pff_rec = pd.read_sql_query('SELECT * FROM PFF_Receiving', con=sqlite3.connect(path + 'Data/Season_Stats.sqlite3'))\n",
    "# pff_rec = pff_rec.drop_duplicates(subset=['player', 'year']).reset_index(drop=True)\n",
    "# df = pd.merge(df, pff_rec, how='inner', left_on=['player', 'year'], right_on=['player', 'year'])\n",
    "\n",
    "# split old and new to filter past years based on touches.\n",
    "# leave all new players in to ensure everyone gets a prediction\n",
    "old = df[(df[pos[set_pos]['touch_filter']] > pos[set_pos]['req_touch']) & \\\n",
    "         (df.games > req_games) & (df.year < set_year-1)].reset_index(drop=True)\n",
    "this_year = df[df.year==set_year-1]\n",
    "\n",
    "# merge old and new back together after filtering\n",
    "df = pd.concat([old, this_year], axis=0)\n",
    "\n",
    "# create dataframes to store results\n",
    "df_train_results = pd.DataFrame([old.player, old.year]).T\n",
    "df_test_results = pd.DataFrame([this_year.player, this_year.year]).T\n",
    "\n",
    "# calculate FP and generate list of relevant metrics\n",
    "df = calculate_fp(df, pts_dict, pos=set_pos).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pos[set_pos]['use_ay']:\n",
    "    cols = ['rec_yd_per_game', 'rec_per_game', 'td_per_game', 'wosp', 'air_yards', \n",
    "            'rz_20_tgt', 'rz_20_receptions', 'avg_pick', 'min_teammate']\n",
    "    \n",
    "elif set_pos == 'QB':\n",
    "    cols = ['fp', 'qb_tds','qb_rating', 'qb_yds', 'pass_off', 'qb_complete_pct', 'qb_td_pct', \n",
    "             'sack_pct', 'avg_pick', 'sacks_allowed', 'qbr', 'adj_yd_per_att', 'adj_net_yd_per_att',\n",
    "             'int', 'int_pct', 'rush_att', 'rush_yds', 'rush_yd_per_game', 'rush_td', 'rush_yd_per_att']\n",
    "else:\n",
    "    cols = ['rec_yd_per_game', 'rec_per_game', 'td_per_game', 'rz_20_rush_att', 'rz_5_rush_att', \n",
    "            'rz_20_rush_pct', 'rz_5_rush_pct','ms_rush_att',\n",
    "            'ms_rush_yd', 'ms_rush_td', 'ms_rec_yd', 'ms_tgts', 'rush_rec_ratio',\n",
    "            'rz_20_tgt', 'rz_20_receptions', 'avg_pick', 'teammate_diff_min', 'teammate_diff_avg']\n",
    "\n",
    "def add_exp_metrics(df, cols):\n",
    "    for lab in cols:\n",
    "        d = df.groupby('year_exp').agg('mean')[lab].reset_index()\n",
    "        d = d.rename(columns={lab: lab + '_exp'})\n",
    "        df = pd.merge(df, d, how='inner', left_on='year_exp', right_on='year_exp')\n",
    "        df[lab + '_exp_diff'] = df[lab] - df[lab + '_exp']\n",
    "        df[lab + '_exp_div'] = df[lab] / df[lab + '_exp']\n",
    "        \n",
    "    return df\n",
    "        \n",
    "df = add_exp_metrics(df, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge and Clean Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------\n",
    "# QB Dictionary\n",
    "#---------\n",
    "\n",
    "pos['QB']['med_features'] = ['fp', 'qb_tds','qb_rating', 'qb_yds', 'pass_off', 'qb_complete_pct', 'qb_td_pct', \n",
    "                             'sack_pct', 'avg_pick', 'sacks_allowed', 'qbr', 'adj_yd_per_att', 'adj_net_yd_per_att',\n",
    "                             'int', 'int_pct', 'rush_att', 'rush_yds', 'rush_td', 'rush_yd_per_game', 'rush_yd_per_att',\n",
    "                             'rz_20_pass_complete', 'rz_20_pass_att',\n",
    "                               'rz_20_complete_pct', 'rz_20_pass_yds', 'rz_20_pass_td', 'rz_20_int',\n",
    "                               'rz_10_pass_complete', 'rz_10_pass_att', 'rz_10_complete_pct',\n",
    "                               'rz_10_pass_yds', 'rz_10_pass_td', 'rz_10_int', 'rz_20_rush_att',\n",
    "                               'rz_20_rush_yds', 'rz_20_rush_td', 'rz_20_rush_pct', 'rz_10_rush_att',\n",
    "                               'rz_10_rush_yds', 'rz_10_rush_td', 'rz_10_rush_pct', 'rz_5_rush_att',\n",
    "                               'rz_5_rush_yds', 'rz_5_rush_td', 'rz_5_rush_pct']\n",
    "pos['QB']['max_features'] = ['fp', 'qb_rating', 'qb_yds', 'qb_tds', 'int', 'int_pct', 'sack_pct', 'rush_yd_per_att']\n",
    "pos['QB']['age_features'] = ['fp', 'qb_rating', 'qb_yds', 'qb_complete_pct', 'qb_td_pct', 'sack_pct', 'rush_yd_per_game', \n",
    "                             'avg_pick', 'qbr', 'int', 'int_pct', 'rush_att', 'rush_yds', 'rush_td', 'rush_yd_per_att']\n",
    "pos['QB']['sum_features'] = ['qb_tds', 'qb_yds', 'fourth_qt_comeback', 'game_winning_drives', 'fp']\n",
    "\n",
    "\n",
    "#---------\n",
    "# RB Dictionary\n",
    "#---------\n",
    "\n",
    "# median feature categories\n",
    "pos['RB']['med_features'] = ['fp', 'tgt', 'receptions', 'total_touches', 'rush_yds', 'rec_yds', \n",
    "                           'rush_yd_per_game', 'rec_yd_per_game', 'rush_td', 'games_started', \n",
    "                           'qb_rating', 'qb_yds', 'pass_off', 'tm_rush_td', 'tm_rush_yds', \n",
    "                           'tm_rush_att', 'adjust_line_yds', 'ms_rush_yd', 'ms_rec_yd', 'ms_rush_td',\n",
    "                           'avg_pick', 'fp_per_touch', 'team_rush_avg_att',\n",
    "                            'rz_20_rush_att', 'rz_20_rush_yds', 'rz_20_rush_td', 'rz_20_tgt', 'rz_20_receptions', \n",
    "                            'rz_20_catch_pct', 'rz_20_rec_yds', 'rz_20_rec_tds',\n",
    "                            'rz_10_rush_att', 'rz_10_rush_yds', 'rz_10_rush_td', 'rz_10_tgt', 'rz_10_receptions', \n",
    "                            'rz_10_catch_pct', 'rz_10_rec_yds', 'rz_10_rec_tds',\n",
    "                            'rz_5_rush_att', 'rz_5_rush_yds', 'rz_5_rush_td',\n",
    "                            'rec_yd_per_game_exp', 'rec_yd_per_game_exp_diff',\n",
    "       'rec_yd_per_game_exp_div', 'rec_per_game_exp', 'rec_per_game_exp_diff',\n",
    "       'rec_per_game_exp_div', 'td_per_game_exp', 'td_per_game_exp_diff',\n",
    "       'td_per_game_exp_div', 'rz_20_rush_att_exp', 'rz_20_rush_att_exp_diff',\n",
    "       'rz_20_rush_att_exp_div', 'rz_5_rush_att_exp', 'rz_5_rush_att_exp_diff',\n",
    "       'rz_5_rush_att_exp_div', 'rz_20_rush_pct_exp',\n",
    "       'rz_20_rush_pct_exp_diff', 'rz_20_rush_pct_exp_div',\n",
    "       'rz_5_rush_pct_exp', 'rz_5_rush_pct_exp_diff', 'rz_5_rush_pct_exp_div',\n",
    "       'ms_rush_att_exp', 'ms_rush_att_exp_diff', 'ms_rush_att_exp_div',\n",
    "       'ms_rush_yd_exp', 'ms_rush_yd_exp_diff', 'ms_rush_yd_exp_div',\n",
    "       'ms_rush_td_exp', 'ms_rush_td_exp_diff', 'ms_rush_td_exp_div',\n",
    "       'ms_rec_yd_exp', 'ms_rec_yd_exp_diff', 'ms_rec_yd_exp_div',\n",
    "       'ms_tgts_exp', 'ms_tgts_exp_diff', 'ms_tgts_exp_div',\n",
    "       'rush_rec_ratio_exp', 'rush_rec_ratio_exp_diff',\n",
    "       'rush_rec_ratio_exp_div', 'rz_20_tgt_exp', 'rz_20_tgt_exp_diff',\n",
    "       'rz_20_tgt_exp_div', 'rz_20_receptions_exp',\n",
    "       'rz_20_receptions_exp_diff', 'rz_20_receptions_exp_div', 'avg_pick_exp',\n",
    "       'avg_pick_exp_diff', 'avg_pick_exp_div', 'teammate_diff_min_exp',\n",
    "       'teammate_diff_min_exp_diff', 'teammate_diff_min_exp_div',\n",
    "       'teammate_diff_avg_exp', 'teammate_diff_avg_exp_diff',\n",
    "       'teammate_diff_avg_exp_div']\n",
    "\n",
    "# sum feature categories\n",
    "pos['RB']['sum_features'] = ['total_touches', 'att', 'total_yds', 'rush_td', 'fp', 'rec_yds', \n",
    "                             'rush_yds', 'qb_yds']\n",
    "\n",
    "# max feature categories\n",
    "pos['RB']['max_features'] = ['fp', 'rush_td', 'tgt', 'rush_yds', 'rec_yds', 'total_yds', \n",
    "                             'rush_yd_per_game', 'rec_yd_per_game', 'ms_rush_yd']\n",
    "\n",
    "# age feature categories\n",
    "pos['RB']['age_features'] = ['fp', 'rush_yd_per_game', 'rec_yd_per_game', 'total_touches', 'receptions', 'tgt',\n",
    "                             'ms_rush_yd', 'ms_rec_yd', 'available_rush_att', 'available_tgt', 'total_touches_sum',\n",
    "                             'total_yds_sum', 'avg_pick', 'fp_per_touch', 'ms_rush_yd_per_att', 'ms_tgts',\n",
    "                            'rz_20_rush_att', 'rz_20_rush_yds', 'rz_20_rush_td', 'rz_20_tgt', 'rz_20_receptions', \n",
    "                            'rz_20_catch_pct', 'rz_20_rec_yds', 'rz_20_rec_tds',\n",
    "                            'rz_10_rush_att', 'rz_10_rush_yds', 'rz_10_rush_td', 'rz_10_tgt', 'rz_10_receptions', \n",
    "                            'rz_10_catch_pct', 'rz_10_rec_yds', 'rz_10_rec_tds',\n",
    "                            'rz_5_rush_att', 'rz_5_rush_yds', 'rz_5_rush_td',\n",
    "                            'rec_yd_per_game_exp', 'rec_yd_per_game_exp_diff',\n",
    "       'rec_yd_per_game_exp_div', 'rec_per_game_exp', 'rec_per_game_exp_diff',\n",
    "       'rec_per_game_exp_div', 'td_per_game_exp', 'td_per_game_exp_diff',\n",
    "       'td_per_game_exp_div', 'rz_20_rush_att_exp', 'rz_20_rush_att_exp_diff',\n",
    "       'rz_20_rush_att_exp_div', 'rz_5_rush_att_exp', 'rz_5_rush_att_exp_diff',\n",
    "       'rz_5_rush_att_exp_div', 'rz_20_rush_pct_exp',\n",
    "       'rz_20_rush_pct_exp_diff', 'rz_20_rush_pct_exp_div',\n",
    "       'rz_5_rush_pct_exp', 'rz_5_rush_pct_exp_diff', 'rz_5_rush_pct_exp_div',\n",
    "       'ms_rush_att_exp', 'ms_rush_att_exp_diff', 'ms_rush_att_exp_div',\n",
    "       'ms_rush_yd_exp', 'ms_rush_yd_exp_diff', 'ms_rush_yd_exp_div',\n",
    "       'ms_rush_td_exp', 'ms_rush_td_exp_diff', 'ms_rush_td_exp_div',\n",
    "       'ms_rec_yd_exp', 'ms_rec_yd_exp_diff', 'ms_rec_yd_exp_div',\n",
    "       'ms_tgts_exp', 'ms_tgts_exp_diff', 'ms_tgts_exp_div',\n",
    "       'rush_rec_ratio_exp', 'rush_rec_ratio_exp_diff',\n",
    "       'rush_rec_ratio_exp_div', 'rz_20_tgt_exp', 'rz_20_tgt_exp_diff',\n",
    "       'rz_20_tgt_exp_div', 'rz_20_receptions_exp',\n",
    "       'rz_20_receptions_exp_diff', 'rz_20_receptions_exp_div', 'avg_pick_exp',\n",
    "       'avg_pick_exp_diff', 'avg_pick_exp_div', 'teammate_diff_min_exp',\n",
    "       'teammate_diff_min_exp_diff', 'teammate_diff_min_exp_div',\n",
    "       'teammate_diff_avg_exp', 'teammate_diff_avg_exp_diff',\n",
    "       'teammate_diff_avg_exp_div']\n",
    "\n",
    "\n",
    "#---------\n",
    "# WR Dictionary\n",
    "#---------\n",
    "\n",
    "# median feature categories\n",
    "pos['WR']['med_features'] = ['fp', 'tgt', 'receptions', 'rec_yds', 'rec_yd_per_game', 'rec_td', 'games_started', \n",
    "                             'qb_rating', 'qb_yds', 'pass_off', 'ms_tgts', 'ms_rec_yd', \n",
    "                             'tm_net_pass_yds', 'avg_pick',  'rz_20_tgt', 'rz_20_receptions', \n",
    "                            'rz_20_catch_pct', 'rz_20_rec_yds', 'rz_20_rec_tds',\n",
    "                             'rz_10_tgt', 'rz_10_receptions', \n",
    "                            'rz_10_catch_pct', 'rz_10_rec_yds', 'rz_10_rec_tds',\n",
    "                            'rec_yd_per_game_exp_diff', 'rec_per_game_exp_diff', 'td_per_game_exp_diff', \n",
    "                            'wosp', 'wosp_exp_diff', 'wosp_exp_div', 'air_yards_exp_diff',\n",
    "                             'rz_20_tgt_exp_diff', 'rz_20_receptions_exp_diff'\n",
    "                            ]\n",
    "\n",
    "# sum feature categories\n",
    "pos['WR']['sum_features'] = ['receptions', 'rec_yds', 'tgt']\n",
    "\n",
    "# max feature categories\n",
    "pos['WR']['max_features'] = ['fp', 'rec_td', 'tgt', 'ms_tgts', 'ms_rec_yd', 'rec_yd_per_game',\n",
    "                             'rz_20_tgt', 'rz_20_receptions', \n",
    "                             'rz_20_catch_pct', 'rz_20_rec_yds', 'rz_20_rec_tds',]\n",
    "\n",
    "# age feature categories\n",
    "pos['WR']['age_features'] = ['fp', 'rec_yd_per_game', 'receptions', 'tgt', 'ms_tgts', 'ms_rec_yd', \n",
    "                             'avg_pick', 'ms_yds_per_tgts', 'rz_20_tgt', 'rz_20_receptions', \n",
    "                            'rz_20_catch_pct', 'rz_20_rec_yds', 'rz_20_rec_tds',\n",
    "                             'rz_10_tgt', 'rz_10_receptions', \n",
    "                            'rz_10_catch_pct', 'rz_10_rec_yds', 'rz_10_rec_tds',\n",
    "                            'rec_yd_per_game_exp_diff', 'rec_per_game_exp_diff', 'td_per_game_exp_diff',\n",
    "                            'rec_yd_per_game_exp_div', 'rec_per_game_exp_div', 'td_per_game_exp_div',\n",
    "                            'wosp', 'wosp_exp_diff', 'wosp_exp_div', 'air_yards_exp_diff',\n",
    "                             'rz_20_tgt_exp_diff', 'rz_20_receptions_exp_diff'\n",
    "                            ]\n",
    "\n",
    "#---------\n",
    "# TE Dictionary\n",
    "#---------\n",
    "\n",
    "# median feature categories\n",
    "pos['TE']['med_features'] = ['fp', 'tgt', 'receptions', 'rec_yds', 'rec_yd_per_game', 'rec_td', 'games_started', \n",
    "                             'qb_rating', 'qb_yds', 'pass_off', 'ms_tgts', 'ms_rec_yd', \n",
    "                             'tm_net_pass_yds', 'avg_pick','rz_20_tgt', 'rz_20_receptions', \n",
    "                            'rz_20_catch_pct', 'rz_20_rec_yds', 'rz_20_rec_tds',\n",
    "                             'rz_10_tgt', 'rz_10_receptions', \n",
    "                            'rz_10_catch_pct', 'rz_10_rec_yds', 'rz_10_rec_tds',\n",
    "                            'rec_yd_per_game_exp_diff', 'rec_per_game_exp_diff', 'td_per_game_exp_diff', \n",
    "                            'wosp', 'wosp_exp_diff', 'wosp_exp_div', 'air_yards_exp_diff',\n",
    "                             'rz_20_tgt_exp_diff', 'rz_20_receptions_exp_diff']\n",
    "# sum feature categories\n",
    "pos['TE']['sum_features'] = ['receptions', 'rec_yds', 'tgt', 'rec_td', 'qb_yds']\n",
    "\n",
    "# max feature categories\n",
    "pos['TE']['max_features'] = ['fp', 'rec_td', 'tgt', 'ms_tgts', 'rec_yds', 'ms_rec_yd', 'rec_yd_per_game',\n",
    "                             'rz_20_tgt', 'rz_20_receptions', \n",
    "                            'rz_20_catch_pct', 'rz_20_rec_yds', 'rz_20_rec_tds',\n",
    "                             'rz_10_tgt', 'rz_10_receptions', \n",
    "                            'rz_10_catch_pct', 'rz_10_rec_yds', 'rz_10_rec_tds',]\n",
    "\n",
    "# age feature categories\n",
    "pos['TE']['age_features'] = ['fp', 'rec_yd_per_game', 'receptions', 'tgt', 'ms_tgts', 'ms_rec_yd', \n",
    "                             'avg_pick', 'ms_yds_per_tgts','rz_20_tgt', 'rz_20_receptions', \n",
    "                            'rz_20_catch_pct', 'rz_20_rec_yds', 'rz_20_rec_tds',\n",
    "                             'rz_10_tgt', 'rz_10_receptions', \n",
    "                            'rz_10_catch_pct', 'rz_10_rec_yds', 'rz_10_rec_tds',\n",
    "                            'rec_yd_per_game_exp_diff', 'rec_per_game_exp_diff', 'td_per_game_exp_diff', \n",
    "                            'wosp', 'wosp_exp_diff', 'wosp_exp_div', 'air_yards_exp_diff',\n",
    "                             'rz_20_tgt_exp_diff', 'rz_20_receptions_exp_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# Loop to create statistical predictions\n",
    "#==========\n",
    "\n",
    "output = {}\n",
    "\n",
    "\n",
    "for metric in pos[set_pos]['metrics']:\n",
    "    \n",
    "    # print which metric is being calculated\n",
    "    print('Running Models for ' + metric)\n",
    "    print('----------------------------------')\n",
    "\n",
    "    #--------\n",
    "    # Create train and predict dataframes\n",
    "    #--------\n",
    "    \n",
    "    # create training and prediction dataframes\n",
    "    df_train, df_predict = features_target(df,\n",
    "                                           pos[set_pos]['earliest_year'], set_year-1,\n",
    "                                           pos[set_pos]['med_features'],\n",
    "                                           pos[set_pos]['sum_features'],\n",
    "                                           pos[set_pos]['max_features'],\n",
    "                                           pos[set_pos]['age_features'],\n",
    "                                           target_feature=metric)\n",
    "    \n",
    "    df_train = convert_to_float(df_train)\n",
    "    df_predict = convert_to_float(df_predict)\n",
    "    \n",
    "    # drop any rows that have a null target value (likely due to injuries or other missed season)\n",
    "    df_train = df_train.dropna(subset=['y_act']).reset_index(drop=True)\n",
    "    df_train = df_train.fillna(df_train.mean())\n",
    "    df_predict = df_predict.dropna().reset_index(drop=True)\n",
    "\n",
    "    print('Number of Training Samples:', df_train.shape[0])\n",
    "\n",
    "    #--------\n",
    "    # Run ensemble model with parameter optimization\n",
    "    #--------\n",
    "\n",
    "    # generate a master dictionary of parameters\n",
    "    param_list = [lgbm_params, xgb_params, lasso_params, ridge_params]\n",
    "    est_names = ['lgbm', 'xgb', 'lasso', 'ridge']\n",
    "\n",
    "    params = {}\n",
    "    for i, param in enumerate(param_list):\n",
    "        params[est_names[i]] = param\n",
    "\n",
    "    print('Training Ensemble Model')\n",
    "    param_results, summary, results_tracker, errors = validation(est_names, params, df_train, \n",
    "                                                                           iterations=pos[set_pos]['iter_rounds'], \n",
    "                                                                           random_state=1234, \n",
    "                                                                           skip_years=pos[set_pos]['skip_years'])\n",
    "\n",
    "    #--------\n",
    "    # Print best results\n",
    "    #--------\n",
    "\n",
    "    # print a summary of error metrics, weightings of various models, and a comparison to \n",
    "    # using straight adp as as a prediction for next year's stats\n",
    "    print(summary.head(10))\n",
    "\n",
    "    # pull out the best result for the random hyperparameter search of models\n",
    "    best_result = summary.index[0]\n",
    "    df_train = corr_collinear_removal(df_train, param_results[best_result]['corr_cutoff'],\n",
    "                                       param_results[best_result]['collinear_cutoff'])\n",
    "    train_cols = list(df_train.columns)\n",
    "    train_cols.remove('y_act')\n",
    "    df_predict = df_predict[train_cols]\n",
    "\n",
    "    # pass the best hyperparameters into the generation_prediction function, which\n",
    "    # will return the test results for the current year and the trained best models\n",
    "    df_test_results_, models = generate_predictions(best_result, param_results, summary, df_train, df_predict)\n",
    "\n",
    "    #--------\n",
    "    # Save all relevant metrics to output dictionary\n",
    "    #--------\n",
    "\n",
    "    # add models to output dictionary\n",
    "    output[metric] = {}\n",
    "    output[metric] = {}\n",
    "    output[metric]['models'] = models\n",
    "\n",
    "    # add params to output dictionary\n",
    "    output[metric]['params'] = param_results\n",
    "\n",
    "    # add columns to output dictionary\n",
    "    cols = list(df_train.columns)\n",
    "    cols.remove('y_act')\n",
    "    cols.remove('player')\n",
    "    output[metric]['cols'] = cols\n",
    "    \n",
    "    #--------\n",
    "    # Aggregate all results through merging\n",
    "    #--------\n",
    "    \n",
    "    df_train_results_ = results_tracker[best_result]\n",
    "\n",
    "    # rename and select only relevant columns for appending\n",
    "    df_train_results_ = df_train_results_.rename(columns={'pred': 'pred_' + metric,\n",
    "                                                          'y_act': 'act_' + metric})\n",
    "    df_train_results_ = df_train_results_[['player', 'year', 'pred_' + metric, 'act_' + metric]]\n",
    "\n",
    "    # concat the chunk for each metric together into one dataframe\n",
    "    df_test_results_ = df_test_results_.rename(columns={'pred': 'pred_' + metric})\n",
    "    df_test_results_ = df_test_results_[['player', 'year', 'pred_' + metric]]\n",
    "\n",
    "    # merge the train results for the given metric with all other metric outputs\n",
    "    df_train_results = pd.merge(df_train_results, df_train_results_, \n",
    "                                how='inner', left_on=['player', 'year'], right_on=['player', 'year'])\n",
    "    # merge the test results for the given metric with all other metric outputs\n",
    "    df_test_results = pd.merge(df_test_results, df_test_results_, \n",
    "                               how='inner', left_on=['player', 'year'], right_on=['player', 'year'])\n",
    "\n",
    "# reorder the results of the output to have predicted before actual\n",
    "col_order = ['player', 'year']\n",
    "col_order.extend([c for c in df_train_results.columns if 'pred' in c])\n",
    "col_order.extend([c for c in df_train_results.columns if 'act' in c])\n",
    "df_train_results = df_train_results[col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------\n",
    "# Calculate Fantasy Points for Given Scoring System\n",
    "#-------- \n",
    "\n",
    "# extract points list and get the idx of point attributes based on length of list\n",
    "pts_list = pts_dict[set_pos]\n",
    "c_idx = len(pts_list) + 2\n",
    "\n",
    "train_plot = df_train_results.copy()\n",
    "test_plot = df_test_results.copy()\n",
    "\n",
    "# multiply stat categories by corresponding point values\n",
    "train_plot.iloc[:, 2:c_idx] = train_plot.iloc[:, 2:c_idx] * pts_list\n",
    "test_plot.iloc[:, 2:c_idx] = test_plot.iloc[:, 2:c_idx] * pts_list\n",
    "\n",
    "# add a total predicted points stat category\n",
    "train_plot.loc[:, 'pred'] = train_plot.iloc[:, 2:c_idx].sum(axis=1)\n",
    "test_plot.loc[:, 'pred'] = test_plot.iloc[:, 2:c_idx].sum(axis=1)\n",
    "\n",
    "#==========\n",
    "# Plot Predictions for Each Player\n",
    "#==========\n",
    "\n",
    "# set length of plot based on number of results\n",
    "plot_length = int(test_plot.shape[0] / 3.5)\n",
    "\n",
    "# plot results from highest predicted FP to lowest predicted FP\n",
    "test_plot.sort_values('pred').plot.barh(x='player', y='pred', figsize=(5, plot_length));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# If desired, plot feature importances for a given metric / model\n",
    "#==========\n",
    "plot_importance=True\n",
    "if plot_importance == True:\n",
    "    \n",
    "    metric = 'rec_per_game'\n",
    "    j = 3\n",
    "    try:\n",
    "        plot_results(output[metric]['models'][j].feature_importances_, col_names=output[metric]['cols']);\n",
    "    except:\n",
    "        plot_results(output[metric]['models'][j].coef_, col_names=output[metric]['cols']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Fantasy Pros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and prediction dataframes\n",
    "fantasy_points = []\n",
    "\n",
    "for m in pos[set_pos]['metrics']:\n",
    "    df_train_full, df_predict_full = features_target(df,\n",
    "                                                     pos[set_pos]['earliest_year'], set_year-1,\n",
    "                                                     pos[set_pos]['med_features'],\n",
    "                                                     pos[set_pos]['sum_features'],\n",
    "                                                     pos[set_pos]['max_features'],\n",
    "                                                     pos[set_pos]['age_features'],\n",
    "                                                     target_feature=m)\n",
    "    fantasy_points.append(list(df_train_full.y_act.values))\n",
    "    \n",
    "fantasy_pts = pd.DataFrame(fantasy_points).T.reset_index(drop=True)\n",
    "fantasy_pts = (fantasy_pts * pts_dict[set_pos]).sum(axis=1)\n",
    "fantasy_pts.name = 'fantasy_pts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stats_fp = []\n",
    "stats_all = []\n",
    "min_year = int(max(df_train_results.year.min(), 2012))\n",
    "    \n",
    "for metric in pos[set_pos]['metrics']:\n",
    "\n",
    "    df_train_full, df_predict_full = features_target(df,\n",
    "                                                     pos[set_pos]['earliest_year'], set_year-1,\n",
    "                                                     pos[set_pos]['med_features'],\n",
    "                                                     pos[set_pos]['sum_features'],\n",
    "                                                     pos[set_pos]['max_features'],\n",
    "                                                     pos[set_pos]['age_features'],\n",
    "                                                     target_feature=metric)\n",
    "\n",
    "    df_train_full = pd.concat([df_train_full, fantasy_pts], axis=1)\n",
    "\n",
    "    fp = pd.read_sql_query('SELECT * FROM FantasyPros', con=sqlite3.connect('/Users/Mark/Documents/Github/Fantasy_Football/Data/Season_Stats.sqlite3'))\n",
    "    fp.year = fp.year-1\n",
    "    df_train_full = pd.merge(df_train_full, fp, how='inner', left_on=['player', 'year'], right_on=['player', 'year'])\n",
    "    df_train_full = df_train_full[df_train_full.fp > 5]\n",
    "\n",
    "\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "    df_train_full = df_train_full.dropna()\n",
    "    lass = Lasso(alpha=250)\n",
    "#     y = 'fantasy_pts'\n",
    "#     y_other = 'y_act'\n",
    "    \n",
    "    y_other = 'fantasy_pts'\n",
    "    y = 'y_act'\n",
    "\n",
    "\n",
    "    stat_all = []\n",
    "    stat_fp = []\n",
    "    results_all = []\n",
    "    results_fp = []\n",
    "    for i in range(min_year, (set_year-1)):\n",
    "\n",
    "        print(i)\n",
    "        X_train = df_train_full.loc[df_train_full.year < i].drop([y_other, y], axis=1)\n",
    "        y_train = df_train_full.loc[df_train_full.year < i, y]\n",
    "\n",
    "        X_fp = X_train[['year', 'rank', 'adp', 'best', 'worst', 'avg', 'std_dev']]\n",
    "        X_all = X_train.drop(['player', 'team', 'pos','rank', 'adp', 'best', 'worst', 'avg', 'std_dev' ], axis=1)\n",
    "\n",
    "        X_predict = df_train_full.loc[df_train_full.year== i].drop([y_other, y], axis=1)\n",
    "        X_pred_fp = X_predict[['year', 'rank', 'adp', 'best', 'worst', 'avg', 'std_dev']]\n",
    "        X_pred_all = X_predict.drop(['player', 'team', 'pos', 'rank', 'adp', 'best', 'worst', 'avg', 'std_dev'], axis=1)\n",
    "\n",
    "        y_pred = df_train_full.loc[df_train_full.year == i, y]\n",
    "\n",
    "        lass.fit(X_fp, y_train)\n",
    "        fp_pred = lass.predict(X_pred_fp)\n",
    "        stat_fp.extend(list(fp_pred))\n",
    "        print('FP error:', round(np.mean(np.sqrt(abs(mean_squared_error(fp_pred, y_pred)))), 3))\n",
    "        results_fp.append(round(np.mean(np.sqrt(abs(mean_squared_error(fp_pred, y_pred)))), 3))\n",
    "\n",
    "        lass.fit(X_all.replace([np.inf, -np.inf], np.nan).fillna(0), y_train)\n",
    "        all_pred = lass.predict(X_pred_all.replace([np.inf, -np.inf], np.nan).fillna(0))\n",
    "        stat_all.extend(list(all_pred))\n",
    "        print('All error:', round(np.mean(np.sqrt(abs(mean_squared_error(all_pred, y_pred)))), 3))\n",
    "        results_all.append(round(np.mean(np.sqrt(abs(mean_squared_error(all_pred, y_pred)))), 3))\n",
    "    \n",
    "    stats_fp.append(stat_fp)\n",
    "    stats_all.append(stat_all)\n",
    "    \n",
    "    if y == 'fantasy_pts':\n",
    "        print('--------------')\n",
    "        print('Fantasy Pros straight FP Error:', round(np.mean(results_fp), 3))\n",
    "        print('All straight FP Error:', round(np.mean(results_all), 3))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------\n",
    "# Convert Fantasy Pros and Lasso Stat Results to Points\n",
    "#----------------\n",
    "\n",
    "df_all = pd.DataFrame(stats_all).T\n",
    "df_fp = pd.DataFrame(stats_fp).T\n",
    "    \n",
    "df_all = (df_all * pts_dict[set_pos]).sum(axis=1)\n",
    "df_fp = (df_fp * pts_dict[set_pos]).sum(axis=1)\n",
    "\n",
    "y_test = df_train_full.loc[(df_train_full.year <= i) & (df_train_full.year >= min_year), y_other]\n",
    "\n",
    "print('Lasso error:', round(np.mean(np.sqrt(abs(mean_squared_error(df_all, y_test)))), 2))\n",
    "print('FantasyPros error:', round(np.mean(np.sqrt(abs(mean_squared_error(df_fp, y_test)))), 2))\n",
    "\n",
    "#----------------\n",
    "# Merge Fantasy Pros Data with Full Model Results to get Matching Player Sets\n",
    "#----------------\n",
    "\n",
    "full_models = pd.merge(\n",
    "              df_train_full.loc[(df_train_full.year <= i) & (df_train_full.year >= min_year), ['player', 'year']],\n",
    "              df_train_results, \n",
    "              how='inner', left_on=['player', 'year'], right_on=['player', 'year']).reset_index(drop=True)\n",
    "\n",
    "y_test = df_train_full.loc[(df_train_full.year <= i) & (df_train_full.year >= min_year), y_other].reset_index(drop=True)\n",
    "\n",
    "if set_pos == 'RB':\n",
    "    pts = pts_dict[set_pos]\n",
    "    full_models['fantasy_pts'] = (full_models.iloc[:,2:(len(pts)+2)]* pts).sum(axis=1)\n",
    "\n",
    "elif set_pos == 'WR' or set_pos =='TE':\n",
    "    pts = pts_dict[set_pos]\n",
    "    full_models['fantasy_pts'] = (full_models.iloc[:,2:(len(pts)+2)]*pts).sum(axis=1)\n",
    "    \n",
    "elif set_pos == 'QB':\n",
    "    pts = pts_dict[set_pos]\n",
    "    full_models['fantasy_pts'] = (full_models.iloc[:,2:(len(pts)+2)]* pts).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All Models:', round(np.mean(np.sqrt(abs(mean_squared_error(full_models.fantasy_pts, y_test)))), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RB Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(4.34-3.67) / (np.mean([4.34, 3.67]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WR Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3.37 - 2.85) / (np.mean([3.37, 2.85]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TE Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(2.61-2.33) / (np.mean([2.61, 2.33]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QB Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(2.68 - 2.43) / (np.mean([2.68, 2.43]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out results to Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------\n",
    "# Append additional stat categories to the results\n",
    "#--------\n",
    "\n",
    "# add actual results and adp to the train df\n",
    "train_results = pd.merge(df_train_results, df[['player', 'year', 'age', 'year_exp', 'avg_pick']],\n",
    "                           how='inner', left_on=['player', 'year'], right_on=['player', 'year'])\n",
    "\n",
    "# add adp to the test df\n",
    "test_results = pd.merge(df_test_results, df[['player', 'year', 'age', 'year_exp', 'avg_pick']],\n",
    "                           how='inner', left_on=['player', 'year'], right_on=['player', 'year'])\n",
    "\n",
    "#--------\n",
    "# Set up proper database connections to save out single dataset\n",
    "#--------\n",
    "\n",
    "train_results.to_sql(set_pos + '_Train_' + str(set_year), engine, schema='websitedev', index=False, if_exists='replace')\n",
    "test_results.to_sql(set_pos + '_Test_' + str(set_year), engine, schema='websitedev', index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break Out Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params_class = {\n",
    "    'n_estimators':[10, 15, 20, 25, 30, 40],\n",
    "    'max_depth':[2, 3, 4, 5],\n",
    "    'feature_fraction':[0.4, 0.5, 0.6, 0.65, 0.7, 0.8],\n",
    "    'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "    'min_child_weight': [1, 5, 10, 12, 15, 20],\n",
    "}\n",
    "\n",
    "xgb_params_class = {\n",
    "    'n_estimators': [10, 15, 20, 25, 30, 40, 50], \n",
    "    'max_depth': [2, 3, 4, 5], \n",
    "    'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "    'min_child_weight': [5, 10, 15, 20, 25, 30, 35],\n",
    "    'feature_fraction':[0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "rf_params_class = {\n",
    "    'n_estimators': [30, 40, 50, 60, 75, 100, 125, 150], \n",
    "    'max_depth': [3, 4, 5, 6, 7, 8], \n",
    "    'min_samples_leaf': [1, 2, 3, 5],\n",
    "    'max_features':[0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "}\n",
    "\n",
    "logit_params = {\n",
    "    'C': [0.1, 1, 5, 10, 25, 50, 100, 150, 200, 250, 500]\n",
    "}\n",
    "\n",
    "svm_params = {\n",
    "    \"C\": [0.1, 1, 5, 10, 25, 50, 100],\n",
    "    'degree': [1, 2, 3]\n",
    "}\n",
    "\n",
    "def get_estimator_class(name, params, rand=True, random_state=None):\n",
    "    \n",
    "    import random\n",
    "    from numpy import random\n",
    "    from xgboost import XGBClassifier\n",
    "    from lightgbm import LGBMClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    \n",
    "    state = random.RandomState(random_state)\n",
    "    \n",
    "    rnd_params = {}\n",
    "    tmp_params = params[name]\n",
    "    if rand == True:\n",
    "        for line in tmp_params.items():\n",
    "            rnd_params[line[0]] = state.choice(line[1])\n",
    "    else:\n",
    "        rnd_params = tmp_params\n",
    "    \n",
    "    if name == 'lgbm':\n",
    "        estimator = LGBMClassifier(random_state=1234, **rnd_params, min_data=1)\n",
    "        \n",
    "    if name == 'xgb':\n",
    "        estimator = XGBClassifier(random_state=1234, **rnd_params)\n",
    "        \n",
    "    if name == 'rf':\n",
    "        estimator = RandomForestClassifier(random_state=1234, **rnd_params)\n",
    "        \n",
    "    if name == 'lr':\n",
    "        estimator = LogisticRegression(random_state=1234, **rnd_params, solver='liblinear', tol=.001)\n",
    "        \n",
    "    if name == 'svm':\n",
    "        estimator = SVC(probability=True, gamma='scale', **rnd_params)\n",
    "        \n",
    "    return estimator, rnd_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and prediction dataframes\n",
    "df_train, df_predict = features_target(df,\n",
    "                                       pos[set_pos]['earliest_year'], set_year-1,\n",
    "                                       pos[set_pos]['med_features'],\n",
    "                                       pos[set_pos]['sum_features'],\n",
    "                                       pos[set_pos]['max_features'],\n",
    "                                       pos[set_pos]['age_features'],\n",
    "                                       target_feature='fp_per_game')\n",
    "\n",
    "df_train = convert_to_float(df_train)\n",
    "df_predict = convert_to_float(df_predict)\n",
    "\n",
    "# drop any rows that have a null target value (likely due to injuries or other missed season)\n",
    "df_train = df_train.dropna(subset=['y_act']).reset_index(drop=True)\n",
    "df_train = df_train.fillna(df_train.mean())\n",
    "df_predict = df_predict.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictions based on ADP and filter to outlier cases\n",
    "outlier, lr = get_adp_predictions(df_train, year_min_int=2, pct_off=0.1, act_ppg=12)\n",
    "outlier = pd.merge(df_train, outlier.drop(['y_act', 'avg_pick'], axis=1), how='inner',\n",
    "                   left_on=['player', 'year'], right_on=['player', 'year'])\n",
    "\n",
    "# maintain the actual points scored to join back later\n",
    "y_act = outlier[['player', 'year', 'y_act', 'pct_off']]\n",
    "outlier = outlier.drop(['y_act', 'pct_off', 'avg_pick_pred'], axis=1)\n",
    "\n",
    "# remove collinear variables based on difference of means between the 0 and 1 labeled groups\n",
    "keep_cols = ['player', 'pos', 'team', 'year', 'label']\n",
    "outlier = remove_classification_collinear(outlier, collinear_cutoff=0.5, keep_cols=keep_cols)\n",
    "outlier = outlier.rename(columns={'label': 'y_act'})\n",
    "\n",
    "try:\n",
    "    outlier.loc[outlier.rz_td_ratio == np.inf, 'rz_td_ratio'] = 0\n",
    "except:\n",
    "    pass\n",
    "\n",
    "outlier_predict = df_predict[[c for c in outlier.columns if c != 'y_act']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    282\n",
       "1     94\n",
       "Name: y_act, dtype: int64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier.y_act.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rookie_rb  = pd.read_sql_query('SELECT * FROM Rookie_RB_Stats', \n",
    "                               con=sqlite3.connect('/Users/Mark/Documents/Github/Fantasy_Football/Data/Season_Stats.sqlite3'))\n",
    "rookie_rb = rookie_rb.drop(['pp_age', 'draft_year', 'rush_yd_per_game', 'rec_yd_per_game', \n",
    "                            'rec_per_game', 'td_per_game',\n",
    "                            'team', 'avg_pick', 'log_avg_pick'], axis=1)\n",
    "outlier = pd.merge(outlier, rookie_rb, how='inner', left_on='player', right_on='player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a master dictionary of parameters\n",
    "param_list = [lgbm_params_class, xgb_params_class, logit_params, rf_params_class, svm_params]\n",
    "est_names = ['lgbm', 'xgb', 'lr', 'rf', 'svm']\n",
    "\n",
    "# param_list = [logit_params]\n",
    "# est_names = ['lr']\n",
    "\n",
    "params = {}\n",
    "for i, param in enumerate(param_list):\n",
    "    params[est_names[i]] = param\n",
    "\n",
    "iterations = 100\n",
    "scale = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-01 21:35:45\n",
      "Completed 10/100 iterations\n",
      "2019-12-01 21:36:46\n",
      "Completed 20/100 iterations\n",
      "2019-12-01 21:37:37\n",
      "Completed 30/100 iterations\n",
      "2019-12-01 21:38:27\n",
      "Completed 40/100 iterations\n",
      "2019-12-01 21:39:22\n",
      "Completed 50/100 iterations\n",
      "2019-12-01 21:40:19\n",
      "Completed 60/100 iterations\n",
      "2019-12-01 21:41:15\n",
      "Completed 70/100 iterations\n",
      "2019-12-01 21:42:05\n",
      "Completed 80/100 iterations\n",
      "2019-12-01 21:42:56\n",
      "Completed 90/100 iterations\n",
      "2019-12-01 21:43:54\n",
      "Completed 100/100 iterations\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)\n",
    "import datetime\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "param_tracker = {}\n",
    "results_tracker = {}\n",
    "use_smote = True\n",
    "\n",
    "for est_name in est_names:\n",
    "    param_tracker[est_name] = {}\n",
    "    results_tracker[est_name] = {}\n",
    "\n",
    "for i in range(0, iterations):\n",
    "        \n",
    "    # update random state to pull new params, but keep consistency based on starting state\n",
    "    random_state = 100 + i*20 + i*3\n",
    "\n",
    "    # print update on progress\n",
    "    if (i+1) % 10 == 0:\n",
    "        print(str(datetime.datetime.now())[:-7])\n",
    "        print('Completed ' + str(i+1) + '/' + str(iterations) + ' iterations')\n",
    "    \n",
    "    for est_name in est_names:\n",
    "        \n",
    "        est, _ = get_estimator_class(est_name, params, rand=True, random_state=random_state)\n",
    "        \n",
    "        # if using smote, set the zero class weight to something close to 1\n",
    "        if use_smote:\n",
    "            zero_weight = np.random.uniform(1, 1.5)\n",
    "        else:\n",
    "            label_cts = outlier.y_act.value_counts()\n",
    "            zero_weight = np.random.uniform(1, 1.5) * label_cts[1] / label_cts[0]\n",
    "        \n",
    "        est.class_weight = {0: zero_weight, 1: 1}\n",
    "        \n",
    "        # run through all years for given estimator and save errors and predictions\n",
    "        val_error = []    \n",
    "        train_error = [] \n",
    "        val_predictions = np.array([]) \n",
    "        years = outlier.year.unique()[1:]\n",
    "        \n",
    "        # create empty sub-dictionary for current iteration storage\n",
    "        results_tracker[est_name][i] = {}\n",
    "        param_tracker[est_name][i] = est\n",
    "\n",
    "        for acc_metric in ['f1_score', 'precision', 'recall']:\n",
    "            results_tracker[est_name][i][acc_metric] = []\n",
    "        \n",
    "        for m in years[:-1]:\n",
    "                \n",
    "            # create training set for all previous years and validation set for current year\n",
    "            train_split = outlier[outlier.year < m]\n",
    "            val_split = outlier[outlier.year == m]\n",
    "\n",
    "            # splitting the train and validation sets into X_train, y_train, X_val and y_val\n",
    "            X_train, X_val, y_train, y_val = X_y_split(train_split, val_split, scale=scale)\n",
    "            \n",
    "            if use_smote:\n",
    "                knn = int(len(y_train[y_train==1])*0.5)\n",
    "                smt = SMOTE(k_neighbors=knn)\n",
    "                X_train, y_train = smt.fit_resample(X_train, y_train)\n",
    "                \n",
    "                X_val = X_val.values\n",
    "            \n",
    "            est.fit(X_train, y_train)\n",
    "            val_predict = est.predict(X_val)\n",
    "            \n",
    "            # calculate accuracy metrics\n",
    "            results_tracker[est_name][i]['f1_score'].append(f1_score(y_val, val_predict))\n",
    "            results_tracker[est_name][i]['precision'].append(precision_score(y_val, val_predict))\n",
    "            results_tracker[est_name][i]['recall'].append(recall_score(y_val, val_predict))\n",
    "            \n",
    "        for acc_metric in ['f1_score', 'precision', 'recall']:\n",
    "            results_tracker[est_name][i][acc_metric] = np.mean(results_tracker[est_name][i][acc_metric])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr     f1_score  precision    recall\n",
      "97  0.365191   0.340253  0.424143\n",
      "lgbm     f1_score  precision    recall\n",
      "58  0.274565   0.350758  0.259975\n",
      "rf     f1_score  precision    recall\n",
      "82  0.265185    0.32338  0.278202\n",
      "xgb     f1_score  precision    recall\n",
      "10  0.346884   0.287301  0.619345\n",
      "svm     f1_score  precision    recall\n",
      "86  0.372626   0.275908  0.647962\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "for model in ['lr', 'lgbm', 'rf', 'xgb', 'svm']:\n",
    "    df = pd.DataFrame(results_tracker[model]).T\n",
    "    idx = df[df.f1_score == df.f1_score.max()].index[0]\n",
    "    print(model, df[df.index==idx])\n",
    "    best_models[model] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the train and validation sets into X_train, y_train, X_val and y_val\n",
    "year_pred = 2018\n",
    "\n",
    "if year_pred == df_predict.year.max():\n",
    "    df_val = outlier_predict.copy()\n",
    "    df_val['y_act'] = None\n",
    "else:\n",
    "    df_val = outlier[outlier.year==year_pred].reset_index(drop=True).copy()\n",
    "\n",
    "X_train, X_val, y_train, y_val = X_y_split(outlier[outlier.year != year_pred], df_val, scale=scale)\n",
    "\n",
    "param_tracker['lr'][best_models['lr']].fit(X_train, y_train)\n",
    "lr_pred = param_tracker['lr'][best_models['lr']].predict_proba(X_val)[:,1]\n",
    "\n",
    "param_tracker['rf'][best_models['rf']].fit(X_train, y_train)\n",
    "rf_pred = param_tracker['rf'][best_models['rf']].predict_proba(X_val)[:,1]\n",
    "\n",
    "param_tracker['xgb'][best_models['xgb']].fit(X_train, y_train)\n",
    "xgb_pred = param_tracker['xgb'][best_models['xgb']].predict_proba(X_val)[:,1]\n",
    "\n",
    "param_tracker['lgbm'][best_models['lgbm']].fit(X_train, y_train)\n",
    "lgbm_pred = param_tracker['lgbm'][best_models['lgbm']].predict_proba(X_val)[:,1]\n",
    "\n",
    "param_tracker['svm'][best_models['svm']].fit(X_train, y_train)\n",
    "svm_pred = param_tracker['svm'][best_models['svm']].predict_proba(X_val)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>year</th>\n",
       "      <th>y_act</th>\n",
       "      <th>lr_pred</th>\n",
       "      <th>rf_pred</th>\n",
       "      <th>xgb_pred</th>\n",
       "      <th>lgbm_pred</th>\n",
       "      <th>svm_pred</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saquon Barkley</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.650281</td>\n",
       "      <td>0.452139</td>\n",
       "      <td>0.359333</td>\n",
       "      <td>0.320746</td>\n",
       "      <td>0.247547</td>\n",
       "      <td>2.030045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kenyan Drake</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.636190</td>\n",
       "      <td>0.360842</td>\n",
       "      <td>0.432660</td>\n",
       "      <td>0.296729</td>\n",
       "      <td>0.249615</td>\n",
       "      <td>1.976036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Dalvin Cook</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.353811</td>\n",
       "      <td>0.414568</td>\n",
       "      <td>0.316271</td>\n",
       "      <td>0.586288</td>\n",
       "      <td>0.250294</td>\n",
       "      <td>1.921232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Leonard Fournette</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.381699</td>\n",
       "      <td>0.427079</td>\n",
       "      <td>0.345936</td>\n",
       "      <td>0.495758</td>\n",
       "      <td>0.247966</td>\n",
       "      <td>1.898439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christian McCaffrey</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.344191</td>\n",
       "      <td>0.544749</td>\n",
       "      <td>0.387123</td>\n",
       "      <td>0.365526</td>\n",
       "      <td>0.248023</td>\n",
       "      <td>1.889613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alvin Kamara</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.506578</td>\n",
       "      <td>0.493777</td>\n",
       "      <td>0.285745</td>\n",
       "      <td>0.315147</td>\n",
       "      <td>0.247184</td>\n",
       "      <td>1.848430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tevin Coleman</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.407710</td>\n",
       "      <td>0.261987</td>\n",
       "      <td>0.418213</td>\n",
       "      <td>0.442556</td>\n",
       "      <td>0.247932</td>\n",
       "      <td>1.778399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Kalen Ballage</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.407925</td>\n",
       "      <td>0.392513</td>\n",
       "      <td>0.321427</td>\n",
       "      <td>0.339611</td>\n",
       "      <td>0.250019</td>\n",
       "      <td>1.711496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Derrius Guice</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.299695</td>\n",
       "      <td>0.316584</td>\n",
       "      <td>0.397258</td>\n",
       "      <td>0.407187</td>\n",
       "      <td>0.249143</td>\n",
       "      <td>1.669867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Joe Mixon</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.290091</td>\n",
       "      <td>0.377977</td>\n",
       "      <td>0.325894</td>\n",
       "      <td>0.411915</td>\n",
       "      <td>0.249491</td>\n",
       "      <td>1.655368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Ronald Jones</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.192614</td>\n",
       "      <td>0.460032</td>\n",
       "      <td>0.341812</td>\n",
       "      <td>0.405369</td>\n",
       "      <td>0.249536</td>\n",
       "      <td>1.649363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Kerryon Johnson</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.335356</td>\n",
       "      <td>0.283445</td>\n",
       "      <td>0.374033</td>\n",
       "      <td>0.392271</td>\n",
       "      <td>0.250494</td>\n",
       "      <td>1.635599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Melvin Gordon</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.167898</td>\n",
       "      <td>0.318369</td>\n",
       "      <td>0.398449</td>\n",
       "      <td>0.484140</td>\n",
       "      <td>0.248796</td>\n",
       "      <td>1.617653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Duke Johnson</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.392399</td>\n",
       "      <td>0.307991</td>\n",
       "      <td>0.313398</td>\n",
       "      <td>0.347954</td>\n",
       "      <td>0.248739</td>\n",
       "      <td>1.610481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Aaron Jones</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.365976</td>\n",
       "      <td>0.408169</td>\n",
       "      <td>0.249348</td>\n",
       "      <td>0.332751</td>\n",
       "      <td>0.249609</td>\n",
       "      <td>1.605854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Peyton Barber</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.113673</td>\n",
       "      <td>0.464327</td>\n",
       "      <td>0.296751</td>\n",
       "      <td>0.391796</td>\n",
       "      <td>0.250741</td>\n",
       "      <td>1.517289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Austin Ekeler</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.277357</td>\n",
       "      <td>0.227707</td>\n",
       "      <td>0.347030</td>\n",
       "      <td>0.413407</td>\n",
       "      <td>0.249472</td>\n",
       "      <td>1.514973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Matt Breida</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.309545</td>\n",
       "      <td>0.260199</td>\n",
       "      <td>0.333180</td>\n",
       "      <td>0.339799</td>\n",
       "      <td>0.248786</td>\n",
       "      <td>1.491509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Chris Thompson</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.273471</td>\n",
       "      <td>0.325116</td>\n",
       "      <td>0.256946</td>\n",
       "      <td>0.359597</td>\n",
       "      <td>0.249672</td>\n",
       "      <td>1.464802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Devonta Freeman</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.246936</td>\n",
       "      <td>0.300951</td>\n",
       "      <td>0.291906</td>\n",
       "      <td>0.374983</td>\n",
       "      <td>0.246230</td>\n",
       "      <td>1.461006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Chris Carson</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.399688</td>\n",
       "      <td>0.297708</td>\n",
       "      <td>0.291652</td>\n",
       "      <td>0.219771</td>\n",
       "      <td>0.248104</td>\n",
       "      <td>1.456923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Phillip Lindsay</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.252712</td>\n",
       "      <td>0.237667</td>\n",
       "      <td>0.376780</td>\n",
       "      <td>0.334840</td>\n",
       "      <td>0.249166</td>\n",
       "      <td>1.451166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Rashaad Penny</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.315336</td>\n",
       "      <td>0.326962</td>\n",
       "      <td>0.238553</td>\n",
       "      <td>0.318279</td>\n",
       "      <td>0.248792</td>\n",
       "      <td>1.447922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tarik Cohen</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.344692</td>\n",
       "      <td>0.325708</td>\n",
       "      <td>0.289504</td>\n",
       "      <td>0.212413</td>\n",
       "      <td>0.248853</td>\n",
       "      <td>1.421169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Todd Gurley</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.341389</td>\n",
       "      <td>0.313905</td>\n",
       "      <td>0.298270</td>\n",
       "      <td>0.214894</td>\n",
       "      <td>0.249037</td>\n",
       "      <td>1.417496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kareem Hunt</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.347446</td>\n",
       "      <td>0.238906</td>\n",
       "      <td>0.303081</td>\n",
       "      <td>0.262060</td>\n",
       "      <td>0.249407</td>\n",
       "      <td>1.400900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Jerick McKinnon</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.391620</td>\n",
       "      <td>0.213767</td>\n",
       "      <td>0.267741</td>\n",
       "      <td>0.278544</td>\n",
       "      <td>0.247697</td>\n",
       "      <td>1.399370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>James Conner</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.238706</td>\n",
       "      <td>0.325891</td>\n",
       "      <td>0.210864</td>\n",
       "      <td>0.241541</td>\n",
       "      <td>0.248758</td>\n",
       "      <td>1.265760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Nick Chubb</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.194408</td>\n",
       "      <td>0.263608</td>\n",
       "      <td>0.297631</td>\n",
       "      <td>0.247176</td>\n",
       "      <td>0.250156</td>\n",
       "      <td>1.252979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Jordan Howard</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.160215</td>\n",
       "      <td>0.265693</td>\n",
       "      <td>0.255811</td>\n",
       "      <td>0.306307</td>\n",
       "      <td>0.251187</td>\n",
       "      <td>1.239213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Malcolm Brown</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.181601</td>\n",
       "      <td>0.404751</td>\n",
       "      <td>0.232414</td>\n",
       "      <td>0.157294</td>\n",
       "      <td>0.248455</td>\n",
       "      <td>1.224515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ezekiel Elliott</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.163667</td>\n",
       "      <td>0.290392</td>\n",
       "      <td>0.312992</td>\n",
       "      <td>0.195149</td>\n",
       "      <td>0.250968</td>\n",
       "      <td>1.213167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lamar Miller</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.127772</td>\n",
       "      <td>0.329655</td>\n",
       "      <td>0.265176</td>\n",
       "      <td>0.241376</td>\n",
       "      <td>0.248509</td>\n",
       "      <td>1.212488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Ito Smith</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.254087</td>\n",
       "      <td>0.161507</td>\n",
       "      <td>0.313212</td>\n",
       "      <td>0.230007</td>\n",
       "      <td>0.249469</td>\n",
       "      <td>1.208282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Jalen Richard</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.284493</td>\n",
       "      <td>0.238459</td>\n",
       "      <td>0.241421</td>\n",
       "      <td>0.193699</td>\n",
       "      <td>0.248129</td>\n",
       "      <td>1.206201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Nyheim Hines</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.293740</td>\n",
       "      <td>0.279757</td>\n",
       "      <td>0.220660</td>\n",
       "      <td>0.156951</td>\n",
       "      <td>0.249074</td>\n",
       "      <td>1.200182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Marlon Mack</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.135178</td>\n",
       "      <td>0.244093</td>\n",
       "      <td>0.213545</td>\n",
       "      <td>0.352699</td>\n",
       "      <td>0.249474</td>\n",
       "      <td>1.194988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>T.J. Yeldon</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.084329</td>\n",
       "      <td>0.250611</td>\n",
       "      <td>0.292810</td>\n",
       "      <td>0.309495</td>\n",
       "      <td>0.250248</td>\n",
       "      <td>1.187492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Sony Michel</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.058001</td>\n",
       "      <td>0.360325</td>\n",
       "      <td>0.223420</td>\n",
       "      <td>0.251619</td>\n",
       "      <td>0.249450</td>\n",
       "      <td>1.142816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Jamaal Williams</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.259362</td>\n",
       "      <td>0.240394</td>\n",
       "      <td>0.230119</td>\n",
       "      <td>0.142978</td>\n",
       "      <td>0.249262</td>\n",
       "      <td>1.122115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>James White</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.189340</td>\n",
       "      <td>0.156135</td>\n",
       "      <td>0.259847</td>\n",
       "      <td>0.257132</td>\n",
       "      <td>0.248892</td>\n",
       "      <td>1.111346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Le'Veon Bell</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.157271</td>\n",
       "      <td>0.167234</td>\n",
       "      <td>0.280653</td>\n",
       "      <td>0.251980</td>\n",
       "      <td>0.249152</td>\n",
       "      <td>1.106290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Giovani Bernard</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.302869</td>\n",
       "      <td>0.166855</td>\n",
       "      <td>0.190242</td>\n",
       "      <td>0.158206</td>\n",
       "      <td>0.249192</td>\n",
       "      <td>1.067365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Damien Williams</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.067778</td>\n",
       "      <td>0.384969</td>\n",
       "      <td>0.203302</td>\n",
       "      <td>0.146815</td>\n",
       "      <td>0.251803</td>\n",
       "      <td>1.054666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Alfred Blue</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.315560</td>\n",
       "      <td>0.143156</td>\n",
       "      <td>0.166466</td>\n",
       "      <td>0.167571</td>\n",
       "      <td>0.248504</td>\n",
       "      <td>1.041257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Derrick Henry</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.154885</td>\n",
       "      <td>0.206694</td>\n",
       "      <td>0.252495</td>\n",
       "      <td>0.167842</td>\n",
       "      <td>0.251069</td>\n",
       "      <td>1.032985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Ty Montgomery</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.183076</td>\n",
       "      <td>0.196666</td>\n",
       "      <td>0.214584</td>\n",
       "      <td>0.179203</td>\n",
       "      <td>0.249531</td>\n",
       "      <td>1.023061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Justin Jackson</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.118379</td>\n",
       "      <td>0.122811</td>\n",
       "      <td>0.303130</td>\n",
       "      <td>0.227648</td>\n",
       "      <td>0.250819</td>\n",
       "      <td>1.022786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>LeSean McCoy</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.066312</td>\n",
       "      <td>0.370952</td>\n",
       "      <td>0.147196</td>\n",
       "      <td>0.131378</td>\n",
       "      <td>0.277218</td>\n",
       "      <td>0.993056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Adrian Peterson</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.099672</td>\n",
       "      <td>0.218857</td>\n",
       "      <td>0.309862</td>\n",
       "      <td>0.189463</td>\n",
       "      <td>0.162571</td>\n",
       "      <td>0.980426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>C.J. Anderson</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.251744</td>\n",
       "      <td>0.139382</td>\n",
       "      <td>0.202465</td>\n",
       "      <td>0.133707</td>\n",
       "      <td>0.248671</td>\n",
       "      <td>0.975969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Wayne Gallman</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.236939</td>\n",
       "      <td>0.116387</td>\n",
       "      <td>0.200635</td>\n",
       "      <td>0.163284</td>\n",
       "      <td>0.248864</td>\n",
       "      <td>0.966109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Carlos Hyde</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.094721</td>\n",
       "      <td>0.158008</td>\n",
       "      <td>0.193319</td>\n",
       "      <td>0.204056</td>\n",
       "      <td>0.250492</td>\n",
       "      <td>0.900595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Dion Lewis</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.146155</td>\n",
       "      <td>0.069012</td>\n",
       "      <td>0.329977</td>\n",
       "      <td>0.086221</td>\n",
       "      <td>0.249359</td>\n",
       "      <td>0.880724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Mark Ingram</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.021610</td>\n",
       "      <td>0.399413</td>\n",
       "      <td>0.177083</td>\n",
       "      <td>0.138394</td>\n",
       "      <td>0.137582</td>\n",
       "      <td>0.874083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Rex Burkhead</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.066152</td>\n",
       "      <td>0.132829</td>\n",
       "      <td>0.195719</td>\n",
       "      <td>0.155421</td>\n",
       "      <td>0.250812</td>\n",
       "      <td>0.800933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Jaylen Samuels</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.132993</td>\n",
       "      <td>0.148471</td>\n",
       "      <td>0.161254</td>\n",
       "      <td>0.093592</td>\n",
       "      <td>0.250152</td>\n",
       "      <td>0.786462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Mike Davis</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.083436</td>\n",
       "      <td>0.140394</td>\n",
       "      <td>0.212263</td>\n",
       "      <td>0.071567</td>\n",
       "      <td>0.251123</td>\n",
       "      <td>0.758783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Latavius Murray</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.049544</td>\n",
       "      <td>0.185747</td>\n",
       "      <td>0.144888</td>\n",
       "      <td>0.096810</td>\n",
       "      <td>0.249522</td>\n",
       "      <td>0.726511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 player    year y_act   lr_pred   rf_pred  xgb_pred  \\\n",
       "1        Saquon Barkley  2018.0  None  0.650281  0.452139  0.359333   \n",
       "17         Kenyan Drake  2018.0  None  0.636190  0.360842  0.432660   \n",
       "29          Dalvin Cook  2018.0  None  0.353811  0.414568  0.316271   \n",
       "38    Leonard Fournette  2018.0  None  0.381699  0.427079  0.345936   \n",
       "2   Christian McCaffrey  2018.0  None  0.344191  0.544749  0.387123   \n",
       "3          Alvin Kamara  2018.0  None  0.506578  0.493777  0.285745   \n",
       "18        Tevin Coleman  2018.0  None  0.407710  0.261987  0.418213   \n",
       "55        Kalen Ballage  2018.0  None  0.407925  0.392513  0.321427   \n",
       "30        Derrius Guice  2018.0  None  0.299695  0.316584  0.397258   \n",
       "9             Joe Mixon  2018.0  None  0.290091  0.377977  0.325894   \n",
       "57         Ronald Jones  2018.0  None  0.192614  0.460032  0.341812   \n",
       "33      Kerryon Johnson  2018.0  None  0.335356  0.283445  0.374033   \n",
       "6         Melvin Gordon  2018.0  None  0.167898  0.318369  0.398449   \n",
       "40         Duke Johnson  2018.0  None  0.392399  0.307991  0.313398   \n",
       "21          Aaron Jones  2018.0  None  0.365976  0.408169  0.249348   \n",
       "26        Peyton Barber  2018.0  None  0.113673  0.464327  0.296751   \n",
       "23        Austin Ekeler  2018.0  None  0.277357  0.227707  0.347030   \n",
       "24          Matt Breida  2018.0  None  0.309545  0.260199  0.333180   \n",
       "48       Chris Thompson  2018.0  None  0.273471  0.325116  0.256946   \n",
       "58      Devonta Freeman  2018.0  None  0.246936  0.300951  0.291906   \n",
       "14         Chris Carson  2018.0  None  0.399688  0.297708  0.291652   \n",
       "11      Phillip Lindsay  2018.0  None  0.252712  0.237667  0.376780   \n",
       "50        Rashaad Penny  2018.0  None  0.315336  0.326962  0.238553   \n",
       "12          Tarik Cohen  2018.0  None  0.344692  0.325708  0.289504   \n",
       "0           Todd Gurley  2018.0  None  0.341389  0.313905  0.298270   \n",
       "8           Kareem Hunt  2018.0  None  0.347446  0.238906  0.303081   \n",
       "37      Jerick McKinnon  2018.0  None  0.391620  0.213767  0.267741   \n",
       "5          James Conner  2018.0  None  0.238706  0.325891  0.210864   \n",
       "15           Nick Chubb  2018.0  None  0.194408  0.263608  0.297631   \n",
       "19        Jordan Howard  2018.0  None  0.160215  0.265693  0.255811   \n",
       "56        Malcolm Brown  2018.0  None  0.181601  0.404751  0.232414   \n",
       "4       Ezekiel Elliott  2018.0  None  0.163667  0.290392  0.312992   \n",
       "22         Lamar Miller  2018.0  None  0.127772  0.329655  0.265176   \n",
       "45            Ito Smith  2018.0  None  0.254087  0.161507  0.313212   \n",
       "34        Jalen Richard  2018.0  None  0.284493  0.238459  0.241421   \n",
       "32         Nyheim Hines  2018.0  None  0.293740  0.279757  0.220660   \n",
       "20          Marlon Mack  2018.0  None  0.135178  0.244093  0.213545   \n",
       "25          T.J. Yeldon  2018.0  None  0.084329  0.250611  0.292810   \n",
       "27          Sony Michel  2018.0  None  0.058001  0.360325  0.223420   \n",
       "41      Jamaal Williams  2018.0  None  0.259362  0.240394  0.230119   \n",
       "7           James White  2018.0  None  0.189340  0.156135  0.259847   \n",
       "10         Le'Veon Bell  2018.0  None  0.157271  0.167234  0.280653   \n",
       "46      Giovani Bernard  2018.0  None  0.302869  0.166855  0.190242   \n",
       "43      Damien Williams  2018.0  None  0.067778  0.384969  0.203302   \n",
       "44          Alfred Blue  2018.0  None  0.315560  0.143156  0.166466   \n",
       "13        Derrick Henry  2018.0  None  0.154885  0.206694  0.252495   \n",
       "51        Ty Montgomery  2018.0  None  0.183076  0.196666  0.214584   \n",
       "52       Justin Jackson  2018.0  None  0.118379  0.122811  0.303130   \n",
       "39         LeSean McCoy  2018.0  None  0.066312  0.370952  0.147196   \n",
       "16      Adrian Peterson  2018.0  None  0.099672  0.218857  0.309862   \n",
       "49        C.J. Anderson  2018.0  None  0.251744  0.139382  0.202465   \n",
       "54        Wayne Gallman  2018.0  None  0.236939  0.116387  0.200635   \n",
       "42          Carlos Hyde  2018.0  None  0.094721  0.158008  0.193319   \n",
       "31           Dion Lewis  2018.0  None  0.146155  0.069012  0.329977   \n",
       "28          Mark Ingram  2018.0  None  0.021610  0.399413  0.177083   \n",
       "53         Rex Burkhead  2018.0  None  0.066152  0.132829  0.195719   \n",
       "47       Jaylen Samuels  2018.0  None  0.132993  0.148471  0.161254   \n",
       "36           Mike Davis  2018.0  None  0.083436  0.140394  0.212263   \n",
       "35      Latavius Murray  2018.0  None  0.049544  0.185747  0.144888   \n",
       "\n",
       "    lgbm_pred  svm_pred     total  \n",
       "1    0.320746  0.247547  2.030045  \n",
       "17   0.296729  0.249615  1.976036  \n",
       "29   0.586288  0.250294  1.921232  \n",
       "38   0.495758  0.247966  1.898439  \n",
       "2    0.365526  0.248023  1.889613  \n",
       "3    0.315147  0.247184  1.848430  \n",
       "18   0.442556  0.247932  1.778399  \n",
       "55   0.339611  0.250019  1.711496  \n",
       "30   0.407187  0.249143  1.669867  \n",
       "9    0.411915  0.249491  1.655368  \n",
       "57   0.405369  0.249536  1.649363  \n",
       "33   0.392271  0.250494  1.635599  \n",
       "6    0.484140  0.248796  1.617653  \n",
       "40   0.347954  0.248739  1.610481  \n",
       "21   0.332751  0.249609  1.605854  \n",
       "26   0.391796  0.250741  1.517289  \n",
       "23   0.413407  0.249472  1.514973  \n",
       "24   0.339799  0.248786  1.491509  \n",
       "48   0.359597  0.249672  1.464802  \n",
       "58   0.374983  0.246230  1.461006  \n",
       "14   0.219771  0.248104  1.456923  \n",
       "11   0.334840  0.249166  1.451166  \n",
       "50   0.318279  0.248792  1.447922  \n",
       "12   0.212413  0.248853  1.421169  \n",
       "0    0.214894  0.249037  1.417496  \n",
       "8    0.262060  0.249407  1.400900  \n",
       "37   0.278544  0.247697  1.399370  \n",
       "5    0.241541  0.248758  1.265760  \n",
       "15   0.247176  0.250156  1.252979  \n",
       "19   0.306307  0.251187  1.239213  \n",
       "56   0.157294  0.248455  1.224515  \n",
       "4    0.195149  0.250968  1.213167  \n",
       "22   0.241376  0.248509  1.212488  \n",
       "45   0.230007  0.249469  1.208282  \n",
       "34   0.193699  0.248129  1.206201  \n",
       "32   0.156951  0.249074  1.200182  \n",
       "20   0.352699  0.249474  1.194988  \n",
       "25   0.309495  0.250248  1.187492  \n",
       "27   0.251619  0.249450  1.142816  \n",
       "41   0.142978  0.249262  1.122115  \n",
       "7    0.257132  0.248892  1.111346  \n",
       "10   0.251980  0.249152  1.106290  \n",
       "46   0.158206  0.249192  1.067365  \n",
       "43   0.146815  0.251803  1.054666  \n",
       "44   0.167571  0.248504  1.041257  \n",
       "13   0.167842  0.251069  1.032985  \n",
       "51   0.179203  0.249531  1.023061  \n",
       "52   0.227648  0.250819  1.022786  \n",
       "39   0.131378  0.277218  0.993056  \n",
       "16   0.189463  0.162571  0.980426  \n",
       "49   0.133707  0.248671  0.975969  \n",
       "54   0.163284  0.248864  0.966109  \n",
       "42   0.204056  0.250492  0.900595  \n",
       "31   0.086221  0.249359  0.880724  \n",
       "28   0.138394  0.137582  0.874083  \n",
       "53   0.155421  0.250812  0.800933  \n",
       "47   0.093592  0.250152  0.786462  \n",
       "36   0.071567  0.251123  0.758783  \n",
       "35   0.096810  0.249522  0.726511  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.concat([df_val[['player', 'year', 'y_act'\n",
    "                            ]], \n",
    "                     pd.Series(lr_pred, name='lr_pred'), \n",
    "                     pd.Series(rf_pred, name='rf_pred'),\n",
    "                     pd.Series(xgb_pred, name='xgb_pred'),\n",
    "                     pd.Series(lgbm_pred, name='lgbm_pred'),\n",
    "                     pd.Series(svm_pred, name='svm_pred'),\n",
    "                     pd.Series(None, name='total')\n",
    "                    ], axis=1)\n",
    "\n",
    "results['total'] = results.iloc[:, 3:].drop('total', axis=1).sum(axis=1)\n",
    "\n",
    "results.sort_values(by='total', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Salary, Injury Tables and SQLite Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push Salary to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal = pd.read_csv('/Users/Mark/Documents/GitHub/Fantasy_Football/Data/OtherData/Salaries/salaries_2019_nv.csv')\n",
    "sal.to_sql('salaries_' + str(set_year), engine, schema='websitedev', index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push Injuries to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "inj = pd.read_csv('/Users/Mark/Documents/GitHub/Fantasy_Football/Data/OtherData/InjuryPredictor/injury_predictor_2019_v2.csv',  \n",
    "                  encoding='latin-1', header=None)\n",
    "inj.columns = ['player', 'pct_miss_one', 'proj_games_missed', 'inj_pct_per_game', 'inj_risk', 'points']\n",
    "inj.player = inj.player.apply(lambda x: x.split(',')[0])\n",
    "inj.pct_miss_one = inj.pct_miss_one.apply(lambda x: float(x.strip('%')))\n",
    "inj.inj_pct_per_game = inj.inj_pct_per_game.apply(lambda x: float(x.strip('%')))\n",
    "inj = inj.drop(['points', 'inj_risk'], axis=1)\n",
    "\n",
    "X = StandardScaler().fit_transform(inj.iloc[:, 1:])\n",
    "inj = pd.concat([pd.DataFrame(inj.player), \n",
    "                 pd.DataFrame(X, columns=['pct_miss_one', 'proj_games_missed', 'pct_per_game'])], \n",
    "                axis=1)\n",
    "for col in ['pct_miss_one', 'proj_games_missed', 'pct_per_game']:\n",
    "    inj[col] = inj[col] + abs(inj[col].min())\n",
    "\n",
    "inj['mean_risk'] = inj.iloc[:, 1:].mean(axis=1)\n",
    "inj = inj[['player', 'mean_risk']].sort_values(by='mean_risk').reset_index(drop=True)\n",
    "inj.loc[inj.player=='Kareem Hunt', 'mean_risk'] = 8\n",
    "inj.loc[inj.player=='Melvin Gordon', 'mean_risk'] = inj.loc[inj.player=='Melvin Gordon', 'mean_risk'] + 4\n",
    "inj.loc[inj.player=='Ezekiel Elliott', 'mean_risk'] = inj.loc[inj.player=='Ezekiel Elliott', 'mean_risk'] + 2\n",
    "inj.loc[inj.player=='Todd Gurley', 'mean_risk'] = inj.loc[inj.player=='Todd Gurley', 'mean_risk'] + 1\n",
    "inj.loc[inj.player=='Antonio Brown', 'mean_risk'] = inj.loc[inj.player=='Antonio Brown', 'mean_risk'] + 1\n",
    "inj.loc[inj.player=='Derrius Guice', 'mean_risk'] = inj.loc[inj.player=='Derrius Guice', 'mean_risk'] + 1\n",
    "inj.loc[inj.player=='A.J. Green', 'mean_risk'] = inj.loc[inj.player=='A.J. Green', 'mean_risk'] + 2\n",
    "\n",
    "\n",
    "inj = inj[['player', 'mean_risk']]\n",
    "inj.to_sql('injuries_' + str(set_year), engine, schema='websitedev', index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop All Data into SQLite Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('/Users/Mark/Desktop/FF_Sim/SimInput_v2.sqlite3')\n",
    "\n",
    "for set_pos in ['QB', 'RB', 'WR', 'TE']:\n",
    "    \n",
    "    train = pd.read_sql_query('SELECT * FROM {}.\"{}_Train_{}\"' \\\n",
    "                                     .format(table_info['schema'], set_pos, str(set_year)), table_info['engine'])\n",
    "    test = pd.read_sql_query('SELECT * FROM {}.\"{}_Test_{}\"' \\\n",
    "                                    .format(table_info['schema'], set_pos, str(set_year)), table_info['engine'])\n",
    "    \n",
    "    train.to_sql(name='{}_Train_{}'.format(set_pos, str(set_year)), con=db, if_exists='replace', index=False)\n",
    "    test.to_sql(name='{}_Test_{}'.format(set_pos, str(set_year)), con=db, if_exists='replace', index=False)\n",
    "    \n",
    "\n",
    "sal = pd.read_sql_query('SELECT * FROM {}.\"salaries_2019\"' \\\n",
    "                                    .format(table_info['schema'], set_pos, str(set_year)), table_info['engine'])\n",
    "sal.to_sql(name='salaries_2019', con=db, if_exists='replace', index=False)\n",
    "\n",
    "inj = pd.read_sql_query('SELECT * FROM {}.\"injuries_2019\"' \\\n",
    "                                    .format(table_info['schema'], set_pos, str(set_year)), table_info['engine'])\n",
    "inj.to_sql(name='injuries_2019', con=db, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
