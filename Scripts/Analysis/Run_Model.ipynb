{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set core path\n",
    "path = '/Users/Mark/Documents/Github/Fantasy_Football/'\n",
    "\n",
    "# set to position to analyze: 'RB', 'WR', 'QB', or 'TE'\n",
    "set_position = 'RB'\n",
    "\n",
    "# set year to analyze\n",
    "set_year = 2018\n",
    "earliest_year = 2002\n",
    "\n",
    "# set required touches (or pass thrown) and games for consideration\n",
    "req_games = 8\n",
    "req_touch = 50\n",
    "\n",
    "# settings for fantasy points\n",
    "pts = {}\n",
    "pts['yd_pts'] = 0.1\n",
    "pts['pass_yd_pts'] = 0.04\n",
    "pts['td_pts'] = 7\n",
    "pts['pass_td_pts'] = 5\n",
    "pts['rec_pts'] = .5\n",
    "pts['fmb_pts'] = -2.0\n",
    "pts['int_pts'] = -2\n",
    "pts['sack_pts'] = -1\n",
    "\n",
    "# VIF threshold to include a feature\n",
    "vif_thresh = 1000\n",
    "\n",
    "# number of hypersearch rounds for training ensemble\n",
    "iter_rounds = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# jupyter specifications\n",
    "pd.options.mode.chained_assignment = None\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "#InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# plotting functions\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change directory temporarily to helper scripts\n",
    "os.chdir(path + 'Scripts/Analysis/Helper_Scripts')\n",
    "\n",
    "# load custom plot functions\n",
    "from my_plot import PrettyPlot\n",
    "PrettyPlot(plt)\n",
    "\n",
    "# load custom helper functions\n",
    "from helper_functions import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge and Clean Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prepared data\n",
    "df = pd.read_csv(path + 'Data/' + str(set_year) + '/' + set_position + '_Input.csv').iloc[:, 1:]\n",
    "\n",
    "######\n",
    "### tmp--need to add td per game to data generation ###\n",
    "df['td_per_game'] = (df.rush_td + df.rec_td) / df.games\n",
    "jeff_fisher = df[(df.player == 'Todd Gurley') & (df.year == 2016.0)].index\n",
    "df = df.drop(jeff_fisher, axis=0).reset_index(drop=True)\n",
    "\n",
    "df.loc[:, 'avg_pick'] = np.log(df.avg_pick)\n",
    "df.loc[:, 'age'] = np.log(df.age)\n",
    "######\n",
    "\n",
    "\n",
    "# split old and new to filter past years based on touches.\n",
    "# leave all new players in to ensure everyone gets a prediction\n",
    "old = df[(df[pos['RB']['touch_filter']] > req_touch) & (df.games > req_games) & (df.year < set_year-1)].reset_index(drop=True)\n",
    "this_year = df[df.year==set_year-1]\n",
    "\n",
    "# merge old and new back together after filtering\n",
    "df = pd.concat([old, this_year], axis=0)\n",
    "\n",
    "# create dataframes to store results\n",
    "df_train_results = pd.DataFrame([old.player, old.year]).T\n",
    "df_test_results = pd.DataFrame([this_year.player]).T\n",
    "\n",
    "# calculate FP\n",
    "df = calculate_fp(df, pts, pos='RB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#==========\n",
    "# Loop to create statistical predictions\n",
    "#==========\n",
    "\n",
    "metrics = ['rush_yd_per_game', 'rec_yd_per_game', 'rec_per_game', 'td_per_game']\n",
    "output = {}\n",
    "\n",
    "for metric in metrics:\n",
    "    \n",
    "    print('Running Models for ' + metric)\n",
    "    print('----------------------------------')\n",
    "    \n",
    "    #--------\n",
    "    # Create train and predict dataframes\n",
    "    #--------\n",
    "    df_train, df_predict = features_target(df, \n",
    "                                           earliest_year, set_year-1, \n",
    "                                           pos['RB']['med_features'], \n",
    "                                           pos['RB']['sum_features'],\n",
    "                                           pos['RB']['max_features'], \n",
    "                                           pos['RB']['age_features'],\n",
    "                                           target_feature=metric)\n",
    "\n",
    "    df_train = df_train.dropna(subset=['y_act']).reset_index(drop=True)\n",
    "\n",
    "    df_train = df_train.fillna(df_train.mean())\n",
    "    df_predict = df_predict.dropna().reset_index(drop=True)\n",
    "\n",
    "    #--------\n",
    "    # Remove low correlation features and high VIF features\n",
    "    #--------\n",
    "\n",
    "    # remove low correlation features\n",
    "    df_train, df_predict = corr_removal(df_train, df_predict, corr_cutoff=0.05)\n",
    "\n",
    "    # select only features with low vif for modeling\n",
    "    transformer = ReduceVIF(thresh=vif_thresh, scale=True, print_progress=False)\n",
    "    df_train_ = transformer.fit_transform(df_train.drop(['y_act', 'player'], axis=1), df_train.y_act)\n",
    "\n",
    "    # extract best columns and filter down df_predict\n",
    "    best_cols = list(df_train_.columns)\n",
    "    best_cols.extend(['player', 'avg_pick'])\n",
    "    df_predict = df_predict[best_cols]\n",
    "    df_predict = df_predict.loc[:,~df_predict.columns.duplicated()]\n",
    "\n",
    "    # add target and filter down df_train\n",
    "    best_cols.extend(['y_act', 'year', 'avg_pick'])\n",
    "    df_train = df_train[best_cols]\n",
    "    df_train = df_train.loc[:,~df_train.columns.duplicated()]\n",
    "\n",
    "    #--------\n",
    "    # Run ensemble model with parameter optimization\n",
    "    #--------\n",
    "\n",
    "    # generate a master dictionary of parameters (must match the)\n",
    "    param_list = [lgbm_params, xgb_params, lasso_params, ridge_params]\n",
    "    est_names = ['lgbm', 'xgb', 'lasso', 'ridge']\n",
    "\n",
    "    params = {}\n",
    "    for i, param in enumerate(param_list):\n",
    "        params[est_names[i]] = param\n",
    "    \n",
    "    print('Training Ensemble Model')\n",
    "    param_results, summary, df_train_results_, errors = validation(est_names, params, df_train, iterations=iter_rounds, random_state=1234)\n",
    "    \n",
    "    #--------\n",
    "    # Print best results\n",
    "    #--------\n",
    "    \n",
    "    # print a summary of error metrics, weightings of various models, and a comparison to \n",
    "    # using straight adp as as a prediction for next year's stats\n",
    "    print(summary.head(10))\n",
    "    \n",
    "    # pull out the best result for the random hyperparameter search of models\n",
    "    best_result = summary.index[0]\n",
    "    \n",
    "    # pass the best hyperparameters into the generation_prediction function, which\n",
    "    # will return the test results for the current year and the trained best models\n",
    "    df_test_results_, models = generate_predictions(best_result, param_results, summary, df_train, df_predict)\n",
    "    \n",
    "    #--------\n",
    "    # Aggregate all results through merging\n",
    "    #--------\n",
    "    \n",
    "    # add models to output dictionary\n",
    "    output[metric] = {}\n",
    "    output[metric]['models'] = models\n",
    "    \n",
    "    # add params to output dictionary\n",
    "    output[metric]['params'] = param_results\n",
    "    \n",
    "    # add columns to output dictionary\n",
    "    cols = list(df_train.columns)\n",
    "    cols.remove('y_act')\n",
    "    cols.remove('player')\n",
    "    output[metric]['cols'] = cols\n",
    "    \n",
    "    # merge the train results for the given metric with all other metric outputs\n",
    "    df_train_results_ = df_train_results_.rename(columns={'pred': 'pred_' + metric})\n",
    "    df_train_results = pd.merge(df_train_results, df_train_results_[['player', 'year','pred_' + metric]], \n",
    "                                how='inner', left_on=['player', 'year'], right_on=['player', 'year'])\n",
    "    \n",
    "    # merge the test results for the given metric with all other metric outputs\n",
    "    df_test_results_ = df_test_results_.rename(columns={'pred': 'pred_' + metric})\n",
    "    df_test_results = pd.merge(df_test_results, df_test_results_[['player', 'pred_' + metric]], \n",
    "                               how='inner', left_on='player', right_on='player')\n",
    "    \n",
    "# after loop, set the df_train to have the y_act as fp_per_game\n",
    "df_train, df_predict = features_target(df, earliest_year, set_year-1, \n",
    "                                           pos['RB']['med_features'], \n",
    "                                           pos['RB']['sum_features'],\n",
    "                                           pos['RB']['max_features'], \n",
    "                                           pos['RB']['age_features'],\n",
    "                                           target_feature='fp_per_game')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# If desired, plot feature importances for a given metric / model\n",
    "#==========\n",
    "\n",
    "metric = 'td_per_game'\n",
    "i = 2\n",
    "try:\n",
    "    plot_results(output[metric]['models'][i].feature_importances_, col_names=output[metric]['cols']);\n",
    "except:\n",
    "    plot_results(output[metric]['models'][i].coef_, col_names=output[metric]['cols']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# Calculate fantasy points based on predictions and point values\n",
    "#==========\n",
    "\n",
    "# create list of fantasy point metrics for each stat category\n",
    "pts_list = [pts['yd_pts'], pts['yd_pts'], pts['rec_pts'], pts['td_pts']]\n",
    "\n",
    "# calculate fantasy points for the train set\n",
    "df_train_results.iloc[:, 2:] = df_train_results.iloc[:, 2:] * pts_list\n",
    "df_train_results.loc[:, 'pred'] = df_train_results.iloc[:, 2:].sum(axis=1)\n",
    "\n",
    "# calculate fantasy points for the test set\n",
    "df_test_results.iloc[:, 1:] = df_test_results.iloc[:, 1:] * pts_list\n",
    "df_test_results.loc[:, 'pred'] = df_test_results.iloc[:, 1:].sum(axis=1)\n",
    "\n",
    "# calculate projected FP per game based on individual statistcal predictions\n",
    "df = calculate_fp(df, pts, pos='RB')\n",
    "\n",
    "# add actual results and adp to the train df\n",
    "df_train_results = pd.merge(df_train_results, df_train[['player', 'year', 'avg_pick', 'y_act']],\n",
    "                           how='inner', left_on=['player', 'year'], right_on=['player', 'year'])\n",
    "\n",
    "# add adp to the test df\n",
    "df_test_results = pd.merge(df_test_results, df_predict[['player', 'avg_pick']],\n",
    "                           how='inner', left_on='player', right_on='player')\n",
    "\n",
    "# calculate the residual between the predictions and results\n",
    "df_train_results['error'] = df_train_results.pred - df_train_results.y_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the predictions in descending order\n",
    "df_test_results.sort_values('pred').plot.barh(x='player', y='pred', figsize=(5,15));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Players into Tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class clustering():\n",
    "\n",
    "    def __init__(self, df_train, df_test):\n",
    "    \n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        import pandas as pd\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        # create self versions of train and test\n",
    "        self.df_train = df_train\n",
    "        self.df_test = df_test\n",
    "    \n",
    "        # create df for clustering by selecting numeric values and dropping y_act\n",
    "        self.X_train = df_train.select_dtypes(include=['float', 'int', 'uint8']).drop(['y_act', 'avg_pick', 'error'], axis=1)\n",
    "        self.X_test = df_test.select_dtypes(include=['float', 'int', 'uint8']).drop(['avg_pick'], axis=1)\n",
    "        \n",
    "    def explore_k(self, k=15):\n",
    "        \n",
    "        from scipy.spatial.distance import cdist\n",
    "        from sklearn.cluster import KMeans\n",
    "        from sklearn import metrics\n",
    "\n",
    "        # k means determine k\n",
    "        X_train = self.X_train\n",
    "        distortions = []\n",
    "        silhouettes = []\n",
    "        K = range(2,k)\n",
    "        for k in K:\n",
    "            kmeanModel = KMeans(n_clusters=k, random_state=1).fit(X_train)\n",
    "            kmeanModel.fit(X_train);\n",
    "            distortions.append(sum(np.min(cdist(X_train, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / X_train.shape[0]);\n",
    "            \n",
    "            silhouettes.append(metrics.silhouette_score(X_train, kmeanModel.labels_))\n",
    "                               \n",
    "        # create elbow plot\n",
    "        fig = plt.figure()\n",
    "        ax1 = fig.add_subplot(121)\n",
    "        ax1.plot(K, distortions, 'bx-')\n",
    "        ax1.set_title(\"Distortion\");\n",
    "        \n",
    "        ax2 = fig.add_subplot(122)\n",
    "        ax2.plot(K, silhouettes, 'x-')\n",
    "        ax2.set_title(\"Silhouette Score\");\n",
    "        \n",
    "        \n",
    "    def fit_and_predict(self, k=10):\n",
    "        \n",
    "        from sklearn.cluster import KMeans\n",
    "\n",
    "        # retrain with optimal cluster \n",
    "        self.k = k\n",
    "        self.kmeans = KMeans(n_clusters=k, random_state=1).fit(self.X_train)\n",
    "        self.train_results = self.kmeans.predict(self.X_train)\n",
    "        self.test_results = self.kmeans.predict(self.X_test) \n",
    "    \n",
    "    \n",
    "    def add_clusters(self):\n",
    "        \n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        \n",
    "        # add cluster results to the df_train and df_test\n",
    "        self.df_train['cluster'] = self.train_results\n",
    "        self.df_test['cluster'] = self.test_results\n",
    "        \n",
    "        final_train = pd.DataFrame()\n",
    "        final_test = pd.DataFrame()\n",
    "        \n",
    "        for j in range(0, self.k):\n",
    "        \n",
    "            test = self.df_test[self.df_test.cluster == j]\n",
    "            train = self.df_train[self.df_train.cluster==j]\n",
    "        \n",
    "            # create a linear regression instance\n",
    "            lr = LinearRegression()\n",
    "            X=train.pred.values.reshape(-1,1)\n",
    "            y=train.y_act\n",
    "        \n",
    "            # calculate rmse of predicted values vs. actual score\n",
    "            scores = cross_val_score(lr, X, y, scoring='neg_mean_absolute_error', cv=X.shape[0])\n",
    "            mae = np.mean(abs(scores))\n",
    "        \n",
    "            # update predictions based on actual score\n",
    "            lr.fit(X, y)\n",
    "            X_test = test.pred.values.reshape(-1,1)\n",
    "            predictions = lr.predict(X_test)\n",
    "            predictions_train = lr.predict(X)\n",
    "\n",
    "            # output accuracy metrics and predictions\n",
    "            rsq = round(lr.score(X,y), 3)\n",
    "            test['cluster_pred'] = predictions\n",
    "            test['rsq'] = rsq\n",
    "            test['mae'] = mae\n",
    "            \n",
    "            rsq = round(lr.score(X,y), 3)\n",
    "            train['cluster_pred'] = predictions_train\n",
    "            train['rsq'] = rsq\n",
    "            train['mae'] = mae\n",
    "            \n",
    "            final_test = pd.concat([final_test, test], axis=0)\n",
    "            final_train = pd.concat([final_train, train], axis=0)\n",
    "            \n",
    "        self.df_test = final_test\n",
    "        self.df_train = final_train\n",
    "        \n",
    "        return self.df_train, self.df_test\n",
    "            \n",
    "    \n",
    "    def show_results(self, j):\n",
    "        from scipy.stats import pearsonr\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        \n",
    "        test = self.df_test[self.df_test.cluster == j]\n",
    "        train = self.df_train[self.df_train.cluster==j]\n",
    "        \n",
    "        # calculate and print all percentiles for players in group\n",
    "        percentile = np.percentile(self.df_train[self.df_train.cluster == j].y_act, q=[5, 25, 50, 75, 95])\n",
    "        print('Fantasy PPG for Various Percentiles')\n",
    "        print('-----------------------------------')\n",
    "        print('5th percentile: ', round(percentile[0], 2))\n",
    "        print('25th percentile:', round(percentile[1], 2))\n",
    "        print('50th percentile:', round(percentile[2], 2))\n",
    "        print('75th percentile:', round(percentile[3], 2))\n",
    "        print('95th percentile:', round(percentile[4], 2))\n",
    "    \n",
    "        # show plot of historical actual results for cluster\n",
    "        ax = train.y_act.plot.hist()\n",
    "        ax.set_xlabel('Fantasy PPG Actual')\n",
    "    \n",
    "        # show plot of predicted vs actual points for cluster\n",
    "        ax = train.plot.scatter('pred', 'y_act')\n",
    "        ax.set_xlabel('Predicted Fantasy PPG')\n",
    "        ax.set_ylabel('Actual Fantasy PPG')\n",
    "        \n",
    "        # show correlation coefficient between actual and predicted points for cluster\n",
    "        print('')\n",
    "        print('Pred to Actual Correlation')\n",
    "        print(train.rsq.mean())\n",
    "        \n",
    "        # show examples of past players in cluster\n",
    "        current = test.sort_values(by='pred', ascending=False)[['player', 'pred', 'cluster_pred']]\n",
    "        \n",
    "        return current\n",
    "    \n",
    "    \n",
    "    def create_distributions(self, wt=2.5):\n",
    "        from scipy.stats import skewnorm\n",
    "        from scipy.stats import pearsonr\n",
    "        import numpy as np\n",
    "        \n",
    "        #==========\n",
    "        # Calculate Global Mean and Stand Deviation for Actual Results\n",
    "        #==========\n",
    "        \n",
    "        # historical standard deviation and mean for actual results\n",
    "        hist_std = df_train_results.groupby('player').agg('std').dropna()\n",
    "        hist_mean = df_train_results.groupby('player').agg('mean').dropna()\n",
    "        \n",
    "        # merge historicaly mean and standard deviations\n",
    "        hist_mean_std = pd.merge(hist_std, hist_mean, how='inner', left_index=True, right_index=True)\n",
    "        \n",
    "        # calculate global coefficient of variance for players that don't have enough historical results\n",
    "        global_cv = (hist_mean_std.y_act_x / hist_mean_std.y_act_y).mean()\n",
    "        \n",
    "        #==========\n",
    "        # Calculate Global Mean and Stand Deviation for Actual Results\n",
    "        #==========\n",
    "        \n",
    "        return rb_sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = clustering(df_train_results, df_test_results)\n",
    "cluster.explore_k(k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cluster.fit_and_predict(k=8)\n",
    "c_train, c_test = cluster.add_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tier 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.show_results(j=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical standard deviation and mean for actual results\n",
    "hist_std = df_train_results.groupby('player').agg('std').dropna()\n",
    "hist_mean = df_train_results.groupby('player').agg('mean').dropna()\n",
    "        \n",
    "# merge historicaly mean and standard deviations\n",
    "hist_mean_std = pd.merge(hist_std, hist_mean, how='inner', left_index=True, right_index=True)\n",
    "        \n",
    "# calculate global coefficient of variance for players that don't have enough historical results\n",
    "global_cv = (hist_mean_std.y_act_x / hist_mean_std.y_act_y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#==========\n",
    "# Loop to Create Prior and Posterior Distributions\n",
    "#==========\n",
    "\n",
    "prior_repeats = 5\n",
    "\n",
    "for player in df_test_results.player[0:]:\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(1234)\n",
    "    \n",
    "    #==========\n",
    "    # Pull Out Predictions and Actual Results for Given Player to Create Prior\n",
    "    #==========\n",
    "    \n",
    "    #--------\n",
    "    # Extract this year's results and multiply by prior_repeats\n",
    "    #--------\n",
    "    \n",
    "    # extract predictions from ensemble and updated predictions based on cluster fit\n",
    "    ty = c_test.loc[c_test.player == player, ['player', 'pred']]\n",
    "    ty_c = c_test.loc[c_test.player == player, ['player', 'cluster_pred']]\n",
    "    \n",
    "    # replicate the predictions to increase n_0 for the prior\n",
    "    ty = pd.concat([ty]*prior_repeats, ignore_index=True)\n",
    "    ty_c = pd.concat([ty_c]*prior_repeats, ignore_index=True)\n",
    "    \n",
    "    # rename the prediction columns to 'points'\n",
    "    ty = ty.rename(columns={'pred': 'points'})\n",
    "    ty_c = ty_c.rename(columns={'cluster_pred': 'points'})\n",
    "    \n",
    "    #--------\n",
    "    # Extract previous year's results, if available\n",
    "    #--------\n",
    "    \n",
    "    py = c_train.loc[c_train.player == player, ['player', 'y_act']].reset_index(drop=True)[0:5]\n",
    "    py = py.rename(columns={'y_act': 'points'})\n",
    "    priors = pd.concat([ty, ty_c, py], axis=0)\n",
    "    \n",
    "    m_0 = priors.points.mean()\n",
    "    if py.shape[0] >= 3:\n",
    "        s2_0 = ((py.shape[0]*py.points.std()**2) + (2*prior_repeats*(m_0 * global_cv)**2)) / (py.shape[0] + 2*prior_repeats)\n",
    "    else:\n",
    "        s2_0 = (m_0 * global_cv)**2\n",
    "    n_0 = priors.shape[0]\n",
    "    v_0 = n_0 - 1\n",
    "    \n",
    "    \n",
    "    ty_cluster = df_test_results[df_test_results.player ==player].cluster.values[0]\n",
    "    update_data = df_train_results[df_train_results.cluster == ty_cluster].y_act\n",
    "    ybar = update_data.mean()\n",
    "    s2 = ((np.percentile(update_data, q=95)-np.percentile(update_data, q=5)) / 4.0)**2\n",
    "    n = len(update_data)\n",
    "    \n",
    "    # posterior hyperparamters \n",
    "    n_n = n_0 + n \n",
    "    m_n = (n*ybar + n_0*m_0) / n_n \n",
    "    v_n = v_0 + n \n",
    "   \n",
    "    s2_n = ((n-1)*s2 + v_0*s2_0 + (n_0*n*(m_0 - ybar)**2)/n_n)/v_n\n",
    "    \n",
    "    phi = np.random.gamma(shape=v_n/2, scale=2/(s2_n*v_n), size=10000)\n",
    "    sigma = 1/np.sqrt(phi)\n",
    "    post_mu = np.random.normal(loc=m_n, scale=sigma/(np.sqrt(n_n)), size=10000)\n",
    "    \n",
    "    prior_y = np.random.normal(loc=m_0, scale=np.sqrt(s2_0), size=10000)\n",
    "    pred_y =  np.random.normal(loc=post_mu, scale=sigma, size=10000)\n",
    "    \n",
    "    print(player)\n",
    "    print(s2_0)\n",
    "    print(s2_n)\n",
    "    pd.Series(prior_y, name='Prior').plot.hist(alpha=0.5, color='grey', bins=20, legend=True, xlim=[0, 30])\n",
    "    plt.axvline(x=prior_y.mean(), alpha=0.7, linestyle='--', color='grey')\n",
    "    pd.Series(pred_y, name='Posterior').plot.hist(alpha=0.4, color='teal', bins=20, legend=True)\n",
    "    plt.axvline(x=pred_y.mean(), alpha=0.5, linestyle='--', color='teal')\n",
    "\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_sampling.to_csv('/Users/Mark/Desktop/Jupyter Projects/Fantasy Football/Projections/rb_sampling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
