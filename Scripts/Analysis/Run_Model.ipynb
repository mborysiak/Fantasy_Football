{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# General Setting\n",
    "#==========\n",
    "\n",
    "# set core path\n",
    "path = '/Users/Mark/Documents/Github/Fantasy_Football/'\n",
    "\n",
    "db_name = 'Model_Inputs.sqlite3'\n",
    "\n",
    "# set to position to analyze: 'RB', 'WR', 'QB', or 'TE'\n",
    "set_pos = 'TE'\n",
    "\n",
    "\n",
    "#==========\n",
    "# Data Filtering\n",
    "#==========\n",
    "\n",
    "# set year to analyze\n",
    "set_year = 2018\n",
    "earliest_year = 2001\n",
    "\n",
    "# set required touches (or pass thrown) and games for consideration\n",
    "req_games = 8\n",
    "req_touch = 40\n",
    "\n",
    "\n",
    "#==========\n",
    "# Fantasy Point Values\n",
    "#==========\n",
    "\n",
    "# settings for fantasy points\n",
    "pts = {}\n",
    "pts['yd_pts'] = 0.1\n",
    "pts['pass_yd_pts'] = 0.04\n",
    "pts['td_pts'] = 7\n",
    "pts['pass_td_pts'] = 5\n",
    "pts['rec_pts'] = 0.5\n",
    "pts['fmb_pts'] = -2.0\n",
    "pts['int_pts'] = -2\n",
    "pts['sack_pts'] = -1\n",
    "\n",
    "\n",
    "#==========\n",
    "# Model Settings\n",
    "#==========\n",
    "\n",
    "# correlation with target for initial feature reduction\n",
    "corr_cutoff = 0.2\n",
    "\n",
    "# VIF threshold to include remaining features\n",
    "vif_thresh = 2500\n",
    "\n",
    "# number of hypersearch rounds for training ensemble\n",
    "iter_rounds = 25\n",
    "\n",
    "# number of time to repeat predictions and cluster predictions when generating prior distributions\n",
    "prior_repeats = 5\n",
    "\n",
    "# whether or not to plot feature importances following modeling\n",
    "plot_importance = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "# jupyter specifications\n",
    "pd.options.mode.chained_assignment = None\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# plotting functions\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change directory temporarily to helper scripts\n",
    "os.chdir(path + 'Scripts/Analysis/Helper_Scripts')\n",
    "\n",
    "# load custom plot functions\n",
    "from my_plot import PrettyPlot\n",
    "PrettyPlot(plt)\n",
    "\n",
    "# load custom helper functions\n",
    "from helper_functions import *;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge and Clean Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# Pull and clean compiled data\n",
    "#==========\n",
    "\n",
    "# connect to database and pull in positional data\n",
    "conn = sqlite3.connect(path + 'Data/' + db_name)\n",
    "df = pd.read_sql_query('SELECT * FROM ' + set_pos + '_2018', con=conn)\n",
    "\n",
    "# split old and new to filter past years based on touches.\n",
    "# leave all new players in to ensure everyone gets a prediction\n",
    "old = df[(df[pos[set_pos]['touch_filter']] > req_touch) & (df.games > req_games) & (df.year < set_year-1)].reset_index(drop=True)\n",
    "this_year = df[df.year==set_year-1]\n",
    "\n",
    "# merge old and new back together after filtering\n",
    "df = pd.concat([old, this_year], axis=0)\n",
    "\n",
    "# create dataframes to store results\n",
    "df_train_results = pd.DataFrame([old.player, old.year]).T\n",
    "df_test_results = pd.DataFrame([this_year.player]).T\n",
    "\n",
    "# calculate FP and generate list of relevant metrics\n",
    "df, pts_list = calculate_fp(df, pts, pos=set_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#==========\n",
    "# Loop to create statistical predictions\n",
    "#==========\n",
    "\n",
    "output = {}\n",
    "\n",
    "for metric in pos[set_pos]['metrics']:\n",
    "    \n",
    "    # create dataframes to store chunk data\n",
    "    df_train_chunks = pd.DataFrame()\n",
    "    df_test_chunks = pd.DataFrame()\n",
    "\n",
    "    # print which metric is being calculated\n",
    "    print('Running Models for ' + metric)\n",
    "    print('----------------------------------')\n",
    "\n",
    "    #--------\n",
    "    # Create train and predict dataframes\n",
    "    #--------\n",
    "    \n",
    "    # create training and prediction dataframes\n",
    "    df_train_full, df_predict_full = features_target(df,\n",
    "                                                     earliest_year, set_year-1,\n",
    "                                                     pos[set_pos]['med_features'],\n",
    "                                                     pos[set_pos]['sum_features'],\n",
    "                                                     pos[set_pos]['max_features'],\n",
    "                                                     pos[set_pos]['age_features'],\n",
    "                                                     target_feature=metric)\n",
    "    \n",
    "    # drop any rows that have a null target value (likely due to injuries or other missed season)\n",
    "    df_train_full = df_train_full.dropna(subset=['y_act']).reset_index(drop=True)\n",
    "    df_train_full = df_train_full.fillna(df_train_full.mean())\n",
    "    df_predict_full = df_predict_full.dropna().reset_index(drop=True)\n",
    "    \n",
    "    # loop through different k's specific to draft position cutoffs\n",
    "    for k in [1]:\n",
    "        \n",
    "        if k == 1:\n",
    "            \n",
    "            df_train = df_train_full\n",
    "            df_predict = df_predict_full\n",
    "            #df_train = df_train_full[df_train_full.avg_pick < 4.6].reset_index(drop=True)\n",
    "            #df_predict = df_predict_full[df_predict_full.avg_pick < 4.6].reset_index(drop=True)\n",
    "        \n",
    "        #if k == 2:\n",
    "        #    df_train = df_train_full[(df_train_full.avg_pick >= 3.6) & (df_train_full.avg_pick < 4.6)].reset_index(drop=True)\n",
    "        #    df_predict = df_predict_full[(df_predict_full.avg_pick >= 3.6) & (df_predict_full.avg_pick < 4.6)].reset_index(drop=True)\n",
    "        \n",
    "        #if k == 2:\n",
    "        #    df_train = df_train_full[df_train_full.avg_pick >= 4.6].reset_index(drop=True)\n",
    "        #    df_predict = df_predict_full[df_predict_full.avg_pick >= 4.6].reset_index(drop=True)\n",
    "            \n",
    "        #--------\n",
    "        # Remove low correlation features and high VIF features\n",
    "        #--------\n",
    "\n",
    "        # remove low correlation features\n",
    "        df_train, df_predict = corr_removal(df_train, df_predict, corr_cutoff=corr_cutoff)\n",
    "\n",
    "        # select only features with low vif for modeling\n",
    "        transformer = ReduceVIF(thresh=vif_thresh, scale=True, print_progress=False)\n",
    "        df_train_ = transformer.fit_transform(df_train.drop(['y_act', 'player'], axis=1), df_train.y_act)\n",
    "\n",
    "        # extract best columns and filter down df_predict\n",
    "        best_cols = list(df_train_.columns)\n",
    "        best_cols.extend(['player', 'year', 'avg_pick'])\n",
    "        df_predict = df_predict[best_cols]\n",
    "        df_predict = df_predict.loc[:,~df_predict.columns.duplicated()]\n",
    "\n",
    "        # add target and filter down df_train\n",
    "        best_cols.extend(['y_act', 'year', 'avg_pick'])\n",
    "        df_train = df_train[best_cols]\n",
    "        df_train = df_train.loc[:,~df_train.columns.duplicated()]\n",
    "\n",
    "        #--------\n",
    "        # Run ensemble model with parameter optimization\n",
    "        #--------\n",
    "\n",
    "        # generate a master dictionary of parameters (must match the)\n",
    "        param_list = [lgbm_params, xgb_params, lasso_params, ridge_params]\n",
    "        est_names = ['lgbm', 'xgb', 'lasso', 'ridge']\n",
    "\n",
    "        params = {}\n",
    "        for i, param in enumerate(param_list):\n",
    "            params[est_names[i]] = param\n",
    "\n",
    "        print('Training Ensemble Model')\n",
    "        param_results, summary, df_train_results_, errors = validation(est_names, params, df_train, iterations=iter_rounds, random_state=1234)\n",
    "\n",
    "        #--------\n",
    "        # Print best results\n",
    "        #--------\n",
    "\n",
    "        # print a summary of error metrics, weightings of various models, and a comparison to \n",
    "        # using straight adp as as a prediction for next year's stats\n",
    "        print(summary.head(10))\n",
    "\n",
    "        # pull out the best result for the random hyperparameter search of models\n",
    "        best_result = summary.index[0]\n",
    "\n",
    "        # pass the best hyperparameters into the generation_prediction function, which\n",
    "        # will return the test results for the current year and the trained best models\n",
    "        df_test_results_, models = generate_predictions(best_result, param_results, summary, df_train, df_predict)\n",
    "\n",
    "        #--------\n",
    "        # Aggregate all results through merging\n",
    "        #--------\n",
    "\n",
    "        # add models to output dictionary\n",
    "        output[metric] = {}\n",
    "        output[metric][k] = {}\n",
    "        output[metric][k]['models'] = models\n",
    "\n",
    "        # add params to output dictionary\n",
    "        output[metric][k]['params'] = param_results\n",
    "\n",
    "        # add columns to output dictionary\n",
    "        cols = list(df_train.columns)\n",
    "        cols.remove('y_act')\n",
    "        cols.remove('player')\n",
    "        output[metric]['cols'] = cols\n",
    "        \n",
    "        # concat the chunk for each metric together into one dataframe\n",
    "        df_train_results_ = df_train_results_.rename(columns={'pred': 'pred_' + metric})\n",
    "        df_train_results_ = df_train_results_[['player', 'year', 'pred_' + metric]]\n",
    "        df_train_chunks = pd.concat([df_train_chunks, df_train_results_], axis=0).reset_index(drop=True)\n",
    "        \n",
    "        # concat the chunk for each metric together into one dataframe\n",
    "        df_test_results_ = df_test_results_.rename(columns={'pred': 'pred_' + metric})\n",
    "        df_test_results_ = df_test_results_[['player', 'pred_' + metric]]\n",
    "        df_test_chunks = pd.concat([df_test_chunks, df_test_results_], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    # merge the train results for the given metric with all other metric outputs\n",
    "    df_train_results = pd.merge(df_train_results, df_train_chunks, \n",
    "                                how='inner', left_on=['player', 'year'], right_on=['player', 'year'])\n",
    "    # merge the test results for the given metric with all other metric outputs\n",
    "    df_test_results = pd.merge(df_test_results, df_test_chunks, \n",
    "                               how='inner', left_on='player', right_on='player')\n",
    "\n",
    "# after loop, set the df_train to have the y_act as fp_per_game\n",
    "df_train, df_predict = features_target(df, earliest_year, set_year-1, \n",
    "                                           pos[set_pos]['med_features'], \n",
    "                                           pos[set_pos]['sum_features'],\n",
    "                                           pos[set_pos]['max_features'], \n",
    "                                           pos[set_pos]['age_features'],\n",
    "                                           target_feature='fp_per_game')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# If desired, plot feature importances for a given metric / model\n",
    "#==========\n",
    "\n",
    "if plot_importance == True:\n",
    "    \n",
    "    metric = 'td_per_game'\n",
    "    k = 1\n",
    "    j = 3\n",
    "    try:\n",
    "        plot_results(output[metric][k]['models'][j].feature_importances_, col_names=output[metric]['cols']);\n",
    "    except:\n",
    "        plot_results(output[metric][k]['models'][j].coef_, col_names=output[metric]['cols']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# Calculate fantasy points based on predictions and point values\n",
    "#==========\n",
    "\n",
    "# format the prediction results, calculate FP/game, and add other relevant metrics to results\n",
    "df_train_results, df_test_results = format_results(df_train_results, df_test_results, \n",
    "                                                   df_train, df_predict, pts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# Plot Predictions for Each Player\n",
    "#==========\n",
    "\n",
    "# set length of plot based on number of results\n",
    "plot_length = int(df_test_results.shape[0] / 3.5)\n",
    "\n",
    "# plot results from highest predicted FP to lowest predicted FP\n",
    "df_test_results.sort_values('pred').plot.barh(x='player', y='pred', figsize=(5, plot_length));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Players into Tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# Group Players into Clusters Using Decision Tree\n",
    "#==========\n",
    "\n",
    "# initialize cluster with train and test results\n",
    "cluster = clustering(df_train_results, df_test_results)\n",
    "\n",
    "# fit decision tree and apply nodes to players\n",
    "cluster.fit_and_predict_tree()\n",
    "\n",
    "# add linear regression of predicted vs actual for cluster predictions\n",
    "c_train, c_test = cluster.add_fit_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# Create Graph of Decision Tree Logic\n",
    "#==========\n",
    "\n",
    "cluster.tree_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# Show the Results for Each Cluster\n",
    "#==========\n",
    "\n",
    "cluster.show_results(j=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#==========\n",
    "# Create the Distributions and Plot Prior / Posterior Results\n",
    "#==========\n",
    "\n",
    "distributions = cluster.create_distributions(prior_repeats=prior_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = pd.melt(distributions, id_vars=0)\n",
    "distributions = distributions.drop('variable', axis=1)\n",
    "distributions = distributions.rename(columns={0: 'player', 'value': 'pred'})\n",
    "distributions = distributions.sort_values(by='player').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_to_db(distributions, db_name='Simulation_Inputs.sqlite3', \n",
    "             table_name= set_pos + '_Sim_' + str(set_year), if_exist='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
