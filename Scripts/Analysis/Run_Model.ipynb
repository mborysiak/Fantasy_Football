{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# General Setting\n",
    "#==========\n",
    "\n",
    "# set core path\n",
    "path = '/Users/Mark/Documents/Github/Fantasy_Football/'\n",
    "\n",
    "db_name = 'Model_Inputs.sqlite3'\n",
    "\n",
    "# set to position to analyze: 'RB', 'WR', 'QB', or 'TE'\n",
    "set_pos = 'WR'\n",
    "\n",
    "\n",
    "#==========\n",
    "# Postgres Database\n",
    "#==========\n",
    "\n",
    "# postgres login information\n",
    "pg_log = {\n",
    "    'USER': 'postgres',\n",
    "    'PASSWORD': 'Ctdim#1bf!!!!!',\n",
    "    'HOST': 'localhost',\n",
    "    'PORT': '5432', \n",
    "    'DATABASE_NAME': 'fantasyfootball'\n",
    "}\n",
    "\n",
    "# create engine for connecting to database\n",
    "engine = create_engine('postgres+psycopg2://{}:{}@{}:{}/{}'.format(pg_log['USER'], pg_log['PASSWORD'], pg_log['HOST'],\n",
    "                                                                   pg_log['PORT'], pg_log['DATABASE_NAME']))\n",
    "\n",
    "# specify schema and table to write out intermediate results\n",
    "table_info = {\n",
    "    'engine': engine,\n",
    "    'schema': 'websitedev',\n",
    "}\n",
    "\n",
    "#==========\n",
    "# Data Filtering\n",
    "#==========\n",
    "\n",
    "# set year to analyze\n",
    "set_year = 2019\n",
    "earliest_year = 2001\n",
    "\n",
    "# set required touches (or pass thrown) and games for consideration\n",
    "req_games = 8\n",
    "req_touch = 50\n",
    "\n",
    "\n",
    "#==========\n",
    "# Fantasy Point Values\n",
    "#==========\n",
    "\n",
    "# define point values for all statistical categories\n",
    "pass_yd_per_pt = 0.04 \n",
    "pass_td_pt = 5\n",
    "int_pts = -2\n",
    "sacks = -1\n",
    "rush_yd_per_pt = 0.1 \n",
    "rec_yd_per_pt = 0.1\n",
    "rush_rec_td = 7\n",
    "ppr = 0.5\n",
    "fumble = -2\n",
    "\n",
    "# creating dictionary containing point values for each position\n",
    "pts_dict = {}\n",
    "pts_dict['QB'] = [pass_yd_per_pt, pass_td_pt, rush_yd_per_pt, rush_rec_td, int_pts, sacks, fumble]\n",
    "pts_dict['RB'] = [rush_yd_per_pt, rec_yd_per_pt, ppr, rush_rec_td, fumble]\n",
    "pts_dict['WR'] = [rec_yd_per_pt, ppr, rush_rec_td, fumble]\n",
    "pts_dict['TE'] = [rec_yd_per_pt, ppr, rush_rec_td, fumble]\n",
    "\n",
    "\n",
    "#==========\n",
    "# Model Settings\n",
    "#==========\n",
    "\n",
    "# correlation with target for initial feature reduction\n",
    "corr_cutoff = 0.2\n",
    "\n",
    "# VIF threshold to include remaining features\n",
    "vif_thresh = 10\n",
    "\n",
    "# number of hypersearch rounds for training ensemble\n",
    "iter_rounds = 100\n",
    "\n",
    "# whether or not to plot feature importances following modeling\n",
    "plot_importance = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "# jupyter specifications\n",
    "pd.options.mode.chained_assignment = None\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# plotting functions\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change directory temporarily to helper scripts\n",
    "os.chdir(path + 'Scripts/Analysis/Helper_Scripts')\n",
    "\n",
    "# load custom plot functions\n",
    "from my_plot import PrettyPlot\n",
    "PrettyPlot(plt)\n",
    "\n",
    "# load custom helper functions and ensure lightgbm runs\n",
    "from helper_functions import *\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge and Clean Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# Pull and clean compiled data\n",
    "#==========\n",
    "\n",
    "# connect to database and pull in positional data\n",
    "conn = sqlite3.connect(path + 'Data/' + db_name)\n",
    "df = pd.read_sql_query('SELECT * FROM ' + set_pos + '_' + str(set_year), con=conn)\n",
    "\n",
    "# ay = pd.read_sql_query('SELECT * FROM AirYards', con=sqlite3.connect(path + 'Data/Season_Stats.sqlite3'))\n",
    "# df = pd.merge(df, ay, how='inner', left_on=['player', 'year'], right_on=['player', 'year'])\n",
    "\n",
    "# split old and new to filter past years based on touches.\n",
    "# leave all new players in to ensure everyone gets a prediction\n",
    "old = df[(df[pos[set_pos]['touch_filter']] > req_touch) & (df.games > req_games) & (df.year < set_year-1)].reset_index(drop=True)\n",
    "this_year = df[df.year==set_year-1]\n",
    "\n",
    "# merge old and new back together after filtering\n",
    "df = pd.concat([old, this_year], axis=0)\n",
    "\n",
    "# create dataframes to store results\n",
    "df_train_results = pd.DataFrame([old.player, old.year]).T\n",
    "df_test_results = pd.DataFrame([this_year.player]).T\n",
    "\n",
    "# calculate FP and generate list of relevant metrics\n",
    "df = calculate_fp(df, pts_dict, pos=set_pos).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------\n",
    "# QB Dictionary\n",
    "#---------\n",
    "\n",
    "# initilize RB dictionary\n",
    "pos['QB'] = {}\n",
    "\n",
    "# total touch filter name\n",
    "pos['QB']['touch_filter'] = 'qb_att'\n",
    "\n",
    "# metrics to calculate stats for\n",
    "pos['QB']['metrics'] = ['qb_yd_per_game', 'pass_td_per_game','rush_yd_per_game', \n",
    "                        'rush_td_per_game' ,'int_per_game', 'sacks_per_game' ]\n",
    "\n",
    "pos['QB']['med_features'] = ['fp', 'qb_tds','qb_rating', 'qb_yds', 'pass_off', 'qb_complete_pct', 'qb_td_pct', \n",
    "                             'sack_pct', 'avg_pick', 'sacks_allowed', 'qbr', 'adj_yd_per_att', 'adj_net_yd_per_att',\n",
    "                             'int', 'int_pct', 'rush_att', 'rush_yds', 'rush_td', 'rush_yd_per_att',\n",
    "                             'rz_20_pass_complete', 'rz_20_pass_att',\n",
    "                               'rz_20_complete_pct', 'rz_20_pass_yds', 'rz_20_pass_td', 'rz_20_int',\n",
    "                               'rz_10_pass_complete', 'rz_10_pass_att', 'rz_10_complete_pct',\n",
    "                               'rz_10_pass_yds', 'rz_10_pass_td', 'rz_10_int', 'rz_20_rush_att',\n",
    "                               'rz_20_rush_yds', 'rz_20_rush_td', 'rz_20_rush_pct', 'rz_10_rush_att',\n",
    "                               'rz_10_rush_yds', 'rz_10_rush_td', 'rz_10_rush_pct', 'rz_5_rush_att',\n",
    "                               'rz_5_rush_yds', 'rz_5_rush_td', 'rz_5_rush_pct']\n",
    "pos['QB']['max_features'] = ['fp', 'qb_rating', 'qb_yds', 'qb_tds', 'int', 'int_pct', 'sack_pct', 'rush_yd_per_att']\n",
    "pos['QB']['age_features'] = ['fp', 'qb_rating', 'qb_yds', 'qb_complete_pct', 'qb_td_pct', 'sack_pct', \n",
    "                             'avg_pick', 'qbr', 'int', 'int_pct', 'rush_att', 'rush_yds', 'rush_td', 'rush_yd_per_att']\n",
    "pos['QB']['sum_features'] = ['qb_tds', 'qb_yds', 'fourth_qt_comeback', 'game_winning_drives', 'fp']\n",
    "\n",
    "\n",
    "\n",
    "# initilize RB dictionary\n",
    "pos['RB'] = {}\n",
    "\n",
    "# total touch filter name\n",
    "pos['RB']['touch_filter'] = 'total_touches'\n",
    "\n",
    "# metrics to be predicted for fantasy point generation\n",
    "pos['RB']['metrics'] = ['rush_yd_per_game', 'rec_yd_per_game', 'rec_per_game', 'td_per_game']\n",
    "\n",
    "# median feature categories\n",
    "pos['RB']['med_features'] = ['fp', 'tgt', 'receptions', 'total_touches', 'rush_yds', 'rec_yds', \n",
    "                           'rush_yd_per_game', 'rec_yd_per_game', 'rush_td', 'games_started', \n",
    "                           'qb_rating', 'qb_yds', 'pass_off', 'tm_rush_td', 'tm_rush_yds', \n",
    "                           'tm_rush_att', 'adjust_line_yds', 'ms_rush_yd', 'ms_rec_yd', 'ms_rush_td',\n",
    "                           'avg_pick', 'fp_per_touch', 'team_rush_avg_att',\n",
    "                            'rz_20_rush_att', 'rz_20_rush_yds', 'rz_20_rush_td', 'rz_20_tgt', 'rz_20_receptions', \n",
    "                            'rz_20_catch_pct', 'rz_20_rec_yds', 'rz_20_rec_tds',\n",
    "                            'rz_10_rush_att', 'rz_10_rush_yds', 'rz_10_rush_td', 'rz_10_tgt', 'rz_10_receptions', \n",
    "                            'rz_10_catch_pct', 'rz_10_rec_yds', 'rz_10_rec_tds',\n",
    "                            'rz_5_rush_att', 'rz_5_rush_yds', 'rz_5_rush_td']\n",
    "\n",
    "# sum feature categories\n",
    "pos['RB']['sum_features'] = ['total_touches', 'att', 'total_yds', 'rush_td', 'fp', 'rec_yds', \n",
    "                             'rush_yds', 'qb_yds']\n",
    "\n",
    "# max feature categories\n",
    "pos['RB']['max_features'] = ['fp', 'rush_td', 'tgt', 'rush_yds', 'rec_yds', 'total_yds', \n",
    "                             'rush_yd_per_game', 'rec_yd_per_game', 'ms_rush_yd']\n",
    "\n",
    "# age feature categories\n",
    "pos['RB']['age_features'] = ['fp', 'rush_yd_per_game', 'rec_yd_per_game', 'total_touches', 'receptions', 'tgt',\n",
    "                             'ms_rush_yd', 'ms_rec_yd', 'available_rush_att', 'available_tgt', 'total_touches_sum',\n",
    "                             'total_yds_sum', 'avg_pick', 'fp_per_touch', 'ms_rush_yd_per_att', 'ms_tgts',\n",
    "                            'rz_20_rush_att', 'rz_20_rush_yds', 'rz_20_rush_td', 'rz_20_tgt', 'rz_20_receptions', \n",
    "                            'rz_20_catch_pct', 'rz_20_rec_yds', 'rz_20_rec_tds',\n",
    "                            'rz_10_rush_att', 'rz_10_rush_yds', 'rz_10_rush_td', 'rz_10_tgt', 'rz_10_receptions', \n",
    "                            'rz_10_catch_pct', 'rz_10_rec_yds', 'rz_10_rec_tds',\n",
    "                            'rz_5_rush_att', 'rz_5_rush_yds', 'rz_5_rush_td']\n",
    "\n",
    "# initilize RB dictionary\n",
    "pos['WR'] = {}\n",
    "\n",
    "# total touch filter name\n",
    "pos['WR']['touch_filter'] = 'tgt'\n",
    "\n",
    "# metrics to calculate stats for\n",
    "pos['WR']['metrics'] = ['rec_yd_per_game', 'rec_per_game', 'td_per_game']\n",
    "\n",
    "# median feature categories\n",
    "pos['WR']['med_features'] = ['fp', 'tgt', 'receptions', 'rec_yds', 'rec_yd_per_game', 'rec_td', 'games_started', \n",
    "                             'qb_rating', 'qb_yds', 'pass_off', 'ms_tgts', 'ms_rec_yd', \n",
    "                             'tm_net_pass_yds', 'avg_pick',  'rz_20_tgt', 'rz_20_receptions', \n",
    "                            'rz_20_catch_pct', 'rz_20_rec_yds', 'rz_20_rec_tds',\n",
    "                             'rz_10_tgt', 'rz_10_receptions', \n",
    "                            'rz_10_catch_pct', 'rz_10_rec_yds', 'rz_10_rec_tds',]\n",
    "# sum feature categories\n",
    "pos['WR']['sum_features'] = ['receptions', 'rec_yds', 'tgt']\n",
    "\n",
    "# max feature categories\n",
    "pos['WR']['max_features'] = ['fp', 'rec_td', 'tgt', 'ms_tgts', 'ms_rec_yd', 'rec_yd_per_game',\n",
    "                             'rz_20_tgt', 'rz_20_receptions', \n",
    "                             'rz_20_catch_pct', 'rz_20_rec_yds', 'rz_20_rec_tds',]\n",
    "\n",
    "# age feature categories\n",
    "pos['WR']['age_features'] = ['fp', 'rec_yd_per_game', 'receptions', 'tgt', 'ms_tgts', 'ms_rec_yd', \n",
    "                             'avg_pick', 'ms_yds_per_tgts', 'rz_20_tgt', 'rz_20_receptions', \n",
    "                            'rz_20_catch_pct', 'rz_20_rec_yds', 'rz_20_rec_tds',\n",
    "                             'rz_10_tgt', 'rz_10_receptions', \n",
    "                            'rz_10_catch_pct', 'rz_10_rec_yds', 'rz_10_rec_tds',]\n",
    "\n",
    "# initilize RB dictionary\n",
    "pos['TE'] = {}\n",
    "\n",
    "# total touch filter name\n",
    "pos['TE']['touch_filter'] = 'tgt'\n",
    "\n",
    "# metrics to calculate stats for\n",
    "pos['TE']['metrics'] = ['rec_yd_per_game', 'rec_per_game', 'td_per_game']\n",
    "\n",
    "# median feature categories\n",
    "pos['TE']['med_features'] = ['fp', 'tgt', 'receptions', 'rec_yds', 'rec_yd_per_game', 'rec_td', 'games_started', \n",
    "                             'qb_rating', 'qb_yds', 'pass_off', 'ms_tgts', 'ms_rec_yd', \n",
    "                             'tm_net_pass_yds', 'avg_pick','rz_20_tgt', 'rz_20_receptions', \n",
    "                            'rz_20_catch_pct', 'rz_20_rec_yds', 'rz_20_rec_tds',\n",
    "                             'rz_10_tgt', 'rz_10_receptions', \n",
    "                            'rz_10_catch_pct', 'rz_10_rec_yds', 'rz_10_rec_tds',]\n",
    "# sum feature categories\n",
    "pos['TE']['sum_features'] = ['receptions', 'rec_yds', 'tgt', 'rec_td', 'qb_yds']\n",
    "\n",
    "# max feature categories\n",
    "pos['TE']['max_features'] = ['fp', 'rec_td', 'tgt', 'ms_tgts', 'rec_yds', 'ms_rec_yd', 'rec_yd_per_game',\n",
    "                             'rz_20_tgt', 'rz_20_receptions', \n",
    "                            'rz_20_catch_pct', 'rz_20_rec_yds', 'rz_20_rec_tds',\n",
    "                             'rz_10_tgt', 'rz_10_receptions', \n",
    "                            'rz_10_catch_pct', 'rz_10_rec_yds', 'rz_10_rec_tds',]\n",
    "\n",
    "# age feature categories\n",
    "pos['TE']['age_features'] = ['fp', 'rec_yd_per_game', 'receptions', 'tgt', 'ms_tgts', 'ms_rec_yd', \n",
    "                             'avg_pick', 'ms_yds_per_tgts','rz_20_tgt', 'rz_20_receptions', \n",
    "                            'rz_20_catch_pct', 'rz_20_rec_yds', 'rz_20_rec_tds',\n",
    "                             'rz_10_tgt', 'rz_10_receptions', \n",
    "                            'rz_10_catch_pct', 'rz_10_rec_yds', 'rz_10_rec_tds',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#==========\n",
    "# Loop to create statistical predictions\n",
    "#==========\n",
    "\n",
    "output = {}\n",
    "\n",
    "for metric in pos[set_pos]['metrics']:\n",
    "    \n",
    "    # create dataframes to store chunk data\n",
    "    df_train_chunks = pd.DataFrame()\n",
    "    df_test_chunks = pd.DataFrame()\n",
    "\n",
    "    # print which metric is being calculated\n",
    "    print('Running Models for ' + metric)\n",
    "    print('----------------------------------')\n",
    "\n",
    "    #--------\n",
    "    # Create train and predict dataframes\n",
    "    #--------\n",
    "    \n",
    "    # create training and prediction dataframes\n",
    "    df_train_full, df_predict_full = features_target(df,\n",
    "                                                     earliest_year, set_year-1,\n",
    "                                                     pos[set_pos]['med_features'],\n",
    "                                                     pos[set_pos]['sum_features'],\n",
    "                                                     pos[set_pos]['max_features'],\n",
    "                                                     pos[set_pos]['age_features'],\n",
    "                                                     target_feature=metric)\n",
    "    \n",
    "    # drop any rows that have a null target value (likely due to injuries or other missed season)\n",
    "    df_train_full = df_train_full.dropna(subset=['y_act']).reset_index(drop=True)\n",
    "    df_train_full = df_train_full.fillna(df_train_full.mean())\n",
    "    df_predict_full = df_predict_full.dropna().reset_index(drop=True)\n",
    "    \n",
    "    print('Number of Training Samples:', df_train_full.shape[0])\n",
    "    \n",
    "    # loop through different k's specific to draft position cutoffs\n",
    "    for k in [1]:\n",
    "        \n",
    "        if k == 1:\n",
    "            \n",
    "            df_train = df_train_full\n",
    "            df_predict = df_predict_full\n",
    "            #df_train = df_train_full[df_train_full.avg_pick < 4.6].reset_index(drop=True)\n",
    "            #df_predict = df_predict_full[df_predict_full.avg_pick < 4.6].reset_index(drop=True)\n",
    "        \n",
    "        #if k == 2:\n",
    "        #    df_train = df_train_full[(df_train_full.avg_pick >= 3.6) & (df_train_full.avg_pick < 4.6)].reset_index(drop=True)\n",
    "        #    df_predict = df_predict_full[(df_predict_full.avg_pick >= 3.6) & (df_predict_full.avg_pick < 4.6)].reset_index(drop=True)\n",
    "        \n",
    "        #if k == 2:\n",
    "        #    df_train = df_train_full[df_train_full.avg_pick >= 4.6].reset_index(drop=True)\n",
    "        #    df_predict = df_predict_full[df_predict_full.avg_pick >= 4.6].reset_index(drop=True)\n",
    "            \n",
    "        #--------\n",
    "        # Remove low correlation features and high VIF features\n",
    "        #--------\n",
    "\n",
    "        # remove low correlation features\n",
    "        df_train, df_predict = corr_removal(df_train, df_predict, corr_cutoff=corr_cutoff)\n",
    "\n",
    "        # select only features with low vif for modeling\n",
    "        transformer = ReduceVIF(thresh=vif_thresh, scale=True, print_progress=False)\n",
    "        df_train_ = transformer.fit_transform(df_train.drop(['y_act', 'player'], axis=1), df_train.y_act)\n",
    "\n",
    "        # extract best columns and filter down df_predict\n",
    "        best_cols = list(df_train_.columns)\n",
    "        best_cols.extend(['player', 'year', 'avg_pick'])\n",
    "        df_predict = df_predict[best_cols]\n",
    "        df_predict = df_predict.loc[:,~df_predict.columns.duplicated()]\n",
    "\n",
    "        # add target and filter down df_train\n",
    "        best_cols.extend(['y_act', 'year', 'avg_pick'])\n",
    "        df_train = df_train[best_cols]\n",
    "        df_train = df_train.loc[:,~df_train.columns.duplicated()]\n",
    "\n",
    "        #--------\n",
    "        # Run ensemble model with parameter optimization\n",
    "        #--------\n",
    "\n",
    "        # generate a master dictionary of parameters (must match the)\n",
    "        param_list = [lgbm_params, xgb_params, lasso_params, ridge_params]\n",
    "        est_names = ['lgbm', 'xgb', 'lasso', 'ridge']\n",
    "\n",
    "        params = {}\n",
    "        for i, param in enumerate(param_list):\n",
    "            params[est_names[i]] = param\n",
    "\n",
    "        print('Training Ensemble Model')\n",
    "        param_results, summary, df_train_results_, errors = validation(est_names, params, df_train, \n",
    "                                                                       iterations=iter_rounds, random_state=1234, skip_years=1)\n",
    "\n",
    "        #--------\n",
    "        # Print best results\n",
    "        #--------\n",
    "\n",
    "        # print a summary of error metrics, weightings of various models, and a comparison to \n",
    "        # using straight adp as as a prediction for next year's stats\n",
    "        print(summary.head(10))\n",
    "        path = '/Users/Mark/Documents/Github/Fantasy_Football/Scripts/Analysis/ParamSearch/'\n",
    "        label = '{}{}_G{}_Touch{}_Corr{}_VIF{}.csv'.format(path, set_pos, req_games, req_touch, corr_cutoff, vif_thresh)\n",
    "        summary.to_csv(label, index=False, mode='a')\n",
    "\n",
    "        # pull out the best result for the random hyperparameter search of models\n",
    "        best_result = summary.index[0]\n",
    "\n",
    "        # pass the best hyperparameters into the generation_prediction function, which\n",
    "        # will return the test results for the current year and the trained best models\n",
    "        df_test_results_, models = generate_predictions(best_result, param_results, summary, df_train, df_predict)\n",
    "\n",
    "        #--------\n",
    "        # Aggregate all results through merging\n",
    "        #--------\n",
    "\n",
    "        # add models to output dictionary\n",
    "        output[metric] = {}\n",
    "        output[metric][k] = {}\n",
    "        output[metric][k]['models'] = models\n",
    "\n",
    "        # add params to output dictionary\n",
    "        output[metric][k]['params'] = param_results\n",
    "\n",
    "        # add columns to output dictionary\n",
    "        cols = list(df_train.columns)\n",
    "        cols.remove('y_act')\n",
    "        cols.remove('player')\n",
    "        output[metric]['cols'] = cols\n",
    "        \n",
    "        # concat the chunk for each metric together into one dataframe\n",
    "        df_train_results_ = df_train_results_.rename(columns={'pred': 'pred_' + metric})\n",
    "        df_train_results_ = df_train_results_[['player', 'year', 'pred_' + metric]]\n",
    "        df_train_chunks = pd.concat([df_train_chunks, df_train_results_], axis=0).reset_index(drop=True)\n",
    "        \n",
    "        # concat the chunk for each metric together into one dataframe\n",
    "        df_test_results_ = df_test_results_.rename(columns={'pred': 'pred_' + metric})\n",
    "        df_test_results_ = df_test_results_[['player', 'pred_' + metric]]\n",
    "        df_test_chunks = pd.concat([df_test_chunks, df_test_results_], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    # merge the train results for the given metric with all other metric outputs\n",
    "    df_train_results = pd.merge(df_train_results, df_train_chunks, \n",
    "                                how='inner', left_on=['player', 'year'], right_on=['player', 'year'])\n",
    "    # merge the test results for the given metric with all other metric outputs\n",
    "    df_test_results = pd.merge(df_test_results, df_test_chunks, \n",
    "                               how='inner', left_on='player', right_on='player')\n",
    "\n",
    "# after loop, set the df_train to have the y_act as fp_per_game\n",
    "df_train, df_predict = features_target(df, earliest_year, set_year-1, \n",
    "                                           pos[set_pos]['med_features'], \n",
    "                                           pos[set_pos]['sum_features'],\n",
    "                                           pos[set_pos]['max_features'], \n",
    "                                           pos[set_pos]['age_features'],\n",
    "                                           target_feature='fp_per_game')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out results to Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------\n",
    "# Append additional stat categories to the results\n",
    "#--------\n",
    "\n",
    "# add actual results and adp to the train df\n",
    "train_results = pd.merge(df_train_results, df_train[['player', 'year', 'age', 'year_exp', 'avg_pick', 'y_act']],\n",
    "                           how='inner', left_on=['player', 'year'], right_on=['player', 'year']).drop('year', axis=1)\n",
    "\n",
    "# add adp to the test df\n",
    "test_results = pd.merge(df_test_results, df_predict[['player', 'age', 'year_exp', 'avg_pick']],\n",
    "                           how='inner', left_on='player', right_on='player')\n",
    "\n",
    "#--------\n",
    "# Set up proper database connections to save out single dataset\n",
    "#--------\n",
    "\n",
    "train_results.to_sql(set_pos + '_Train_' + str(set_year), engine, schema='websitedev', index=False, if_exists='replace')\n",
    "test_results.to_sql(set_pos + '_Test_' + str(set_year), engine, schema='websitedev', index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------\n",
    "# Calculate Fantasy Points for Given Scoring System\n",
    "#-------- \n",
    "\n",
    "# extract points list and get the idx of point attributes based on length of list\n",
    "pts_list = pts_dict[set_pos][:-1]\n",
    "print(pts_list)\n",
    "c_idx = len(pts_list) + 1\n",
    "\n",
    "\n",
    "train_plot = df_train_results.copy()\n",
    "test_plot = df_test_results.copy()\n",
    "\n",
    "# multiply stat categories by corresponding point values\n",
    "train_plot.iloc[:, 1:c_idx] = train_plot.iloc[:, 1:c_idx] * pts_list\n",
    "test_plot.iloc[:, 1:c_idx] = test_plot.iloc[:, 1:c_idx] * pts_list\n",
    "\n",
    "# add a total predicted points stat category\n",
    "train_plot.loc[:, 'pred'] = train_plot.iloc[:, 1:c_idx].sum(axis=1)\n",
    "test_plot.loc[:, 'pred'] = test_plot.iloc[:, 1:c_idx].sum(axis=1)\n",
    "\n",
    "#==========\n",
    "# Plot Predictions for Each Player\n",
    "#==========\n",
    "\n",
    "# set length of plot based on number of results\n",
    "plot_length = int(test_plot.shape[0] / 3.5)\n",
    "\n",
    "# plot results from highest predicted FP to lowest predicted FP\n",
    "test_plot.sort_values('pred').plot.barh(x='player', y='pred', figsize=(5, plot_length));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# If desired, plot feature importances for a given metric / model\n",
    "#==========\n",
    "plot_importance=True\n",
    "if plot_importance == True:\n",
    "    \n",
    "    metric = 'int_per_game'\n",
    "    k = 1\n",
    "    j = 3\n",
    "    try:\n",
    "        plot_results(output[metric][k]['models'][j].feature_importances_, col_names=output[metric]['cols']);\n",
    "    except:\n",
    "        plot_results(output[metric][k]['models'][j].coef_, col_names=output[metric]['cols']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Salary, Injury Tables and SQLite Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push Salary to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal = pd.read_csv('/Users/Mark/Documents/GitHub/Fantasy_Football/Data/OtherData/Salaries/salaries_2019.csv')\n",
    "sal.to_sql('salaries_' + str(set_year), engine, schema='websitedev', index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push Injuries to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "inj = pd.read_csv('/Users/Mark/Documents/GitHub/Fantasy_Football/Data/OtherData/InjuryPredictor/injury_predictor_2019_v2.csv',  \n",
    "                  encoding='latin-1', header=None)\n",
    "inj.columns = ['player', 'pct_miss_one', 'proj_games_missed', 'inj_pct_per_game', 'inj_risk', 'points']\n",
    "inj.player = inj.player.apply(lambda x: x.split(',')[0])\n",
    "inj.pct_miss_one = inj.pct_miss_one.apply(lambda x: float(x.strip('%')))\n",
    "inj.inj_pct_per_game = inj.inj_pct_per_game.apply(lambda x: float(x.strip('%')))\n",
    "inj = inj.drop(['points', 'inj_risk'], axis=1)\n",
    "\n",
    "X = StandardScaler().fit_transform(inj.iloc[:, 1:])\n",
    "inj = pd.concat([pd.DataFrame(inj.player), \n",
    "                 pd.DataFrame(X, columns=['pct_miss_one', 'proj_games_missed', 'pct_per_game'])], \n",
    "                axis=1)\n",
    "for col in ['pct_miss_one', 'proj_games_missed', 'pct_per_game']:\n",
    "    inj[col] = inj[col] + abs(inj[col].min())\n",
    "\n",
    "inj['mean_risk'] = inj.iloc[:, 1:].mean(axis=1)\n",
    "inj = inj[['player', 'mean_risk']].sort_values(by='mean_risk').reset_index(drop=True)\n",
    "inj.loc[inj.player=='Kareem Hunt', 'mean_risk'] = 8\n",
    "inj.loc[inj.player=='Melvin Gordon', 'mean_risk'] = inj.loc[inj.player=='Melvin Gordon', 'mean_risk'] + 2\n",
    "inj.loc[inj.player=='Todd Gurley', 'mean_risk'] = inj.loc[inj.player=='Todd Gurley', 'mean_risk'] + 1\n",
    "inj.loc[inj.player=='Antonio Brown', 'mean_risk'] = inj.loc[inj.player=='Antonio Brown', 'mean_risk'] + 1\n",
    "inj.loc[inj.player=='Kenyan Drake', 'mean_risk'] = inj.loc[inj.player=='Kenyan Drake', 'mean_risk'] + 2\n",
    "inj.loc[inj.player=='Derrius Guice', 'mean_risk'] = inj.loc[inj.player=='Derrius Guice', 'mean_risk'] + 2\n",
    "\n",
    "inj = inj[['player', 'mean_risk']]\n",
    "inj.to_sql('injuries_' + str(set_year), engine, schema='websitedev', index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop All Data into SQLite Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('/Users/Mark/Desktop/FF_Sim/SimInput_v2.sqlite3')\n",
    "\n",
    "for set_pos in ['QB', 'RB', 'WR', 'TE']:\n",
    "    \n",
    "    train = pd.read_sql_query('SELECT * FROM {}.\"{}_Train_{}\"' \\\n",
    "                                     .format(table_info['schema'], set_pos, str(set_year)), table_info['engine'])\n",
    "    test = pd.read_sql_query('SELECT * FROM {}.\"{}_Test_{}\"' \\\n",
    "                                    .format(table_info['schema'], set_pos, str(set_year)), table_info['engine'])\n",
    "    \n",
    "    train.to_sql(name='{}_Train_{}'.format(set_pos, str(set_year)), con=db, if_exists='replace', index=False)\n",
    "    test.to_sql(name='{}_Test_{}'.format(set_pos, str(set_year)), con=db, if_exists='replace', index=False)\n",
    "    \n",
    "\n",
    "sal = pd.read_sql_query('SELECT * FROM {}.\"salaries_2019\"' \\\n",
    "                                    .format(table_info['schema'], set_pos, str(set_year)), table_info['engine'])\n",
    "sal.to_sql(name='salaries_2019', con=db, if_exists='replace', index=False)\n",
    "\n",
    "inj = pd.read_sql_query('SELECT * FROM {}.\"injuries_2019\"' \\\n",
    "                                    .format(table_info['schema'], set_pos, str(set_year)), table_info['engine'])\n",
    "inj.to_sql(name='injuries_2019', con=db, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Fantasy Pros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and prediction dataframes\n",
    "fantasy_points = []\n",
    "\n",
    "if set_pos == 'RB':\n",
    "    cat_list = ['rush_yd_per_game', 'rec_yd_per_game', 'rec_per_game', 'td_per_game']\n",
    "    \n",
    "elif set_pos == 'WR' or set_pos == 'TE':\n",
    "    cat_list = ['rec_yd_per_game', 'rec_per_game', 'td_per_game']\n",
    "    \n",
    "elif set_pos == 'QB':\n",
    "    cat_list = ['qb_yd_per_game', 'pass_td_per_game','rush_yd_per_game', \n",
    "                        'rush_td_per_game' ,'int_per_game', 'sacks_per_game' ]\n",
    "\n",
    "for m in cat_list:\n",
    "    df_train_full, df_predict_full = features_target(df,\n",
    "                                                     earliest_year, set_year-1,\n",
    "                                                     pos[set_pos]['med_features'],\n",
    "                                                     pos[set_pos]['sum_features'],\n",
    "                                                     pos[set_pos]['max_features'],\n",
    "                                                     pos[set_pos]['age_features'],\n",
    "                                                     target_feature=m)\n",
    "    fantasy_points.append(list(df_train_full.y_act.values))\n",
    "    \n",
    "fantasy_pts = pd.DataFrame(fantasy_points).T.reset_index(drop=True)\n",
    "\n",
    "if set_pos == 'RB':\n",
    "    fantasy_pts = (fantasy_pts * [0.1, 0.1, 0.5, 7]).sum(axis=1)\n",
    "elif set_pos == 'WR' or set_pos == 'TE':\n",
    "    fantasy_pts = (fantasy_pts * [0.1, 0.5, 7]).sum(axis=1)\n",
    "elif set_pos == 'QB':\n",
    "    fantasy_pts = (fantasy_pts * [0.04, 5, 0.1, 7, -2, -1]).sum(axis=1)\n",
    "    \n",
    "fantasy_pts.name = 'fantasy_pts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_fp = []\n",
    "stats_all = []\n",
    "    \n",
    "for metric in cat_list:\n",
    "\n",
    "    df_train_full, df_predict_full = features_target(df,\n",
    "                                                         earliest_year, set_year-1,\n",
    "                                                         pos[set_pos]['med_features'],\n",
    "                                                         pos[set_pos]['sum_features'],\n",
    "                                                         pos[set_pos]['max_features'],\n",
    "                                                         pos[set_pos]['age_features'],\n",
    "                                                         target_feature=metric)\n",
    "\n",
    "    df_train_full = pd.concat([df_train_full, fantasy_pts], axis=1)\n",
    "\n",
    "    fp = pd.read_sql_query('SELECT * FROM FantasyPros', con=sqlite3.connect('/Users/Mark/Documents/Github/Fantasy_Football/Data/Season_Stats.sqlite3'))\n",
    "    fp.year = fp.year-1\n",
    "    df_train_full = pd.merge(df_train_full, fp, how='inner', left_on=['player', 'year'], right_on=['player', 'year'])\n",
    "    df_train_full = df_train_full[df_train_full.fp > 5]\n",
    "\n",
    "\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "    df_train_full = df_train_full.dropna()\n",
    "    lass = Lasso(alpha=250)\n",
    "#     y = 'fantasy_pts'\n",
    "#     y_other = 'y_act'\n",
    "    \n",
    "    y_other = 'fantasy_pts'\n",
    "    y = 'y_act'\n",
    "\n",
    "\n",
    "    stat_all = []\n",
    "    stat_fp = []\n",
    "    results_all = []\n",
    "    results_fp = []\n",
    "    for i in [2012, 2013, 2014, 2015, 2016, 2017]:\n",
    "\n",
    "        print(i)\n",
    "        X_train = df_train_full.loc[df_train_full.year < i].drop([y_other, y], axis=1)\n",
    "        y_train = df_train_full.loc[df_train_full.year < i, y]\n",
    "\n",
    "        X_fp = X_train[['year', 'rank', 'adp', 'best', 'worst', 'avg', 'std_dev']]\n",
    "        X_all = X_train.drop(['player', 'team', 'pos','rank', 'adp', 'best', 'worst', 'avg', 'std_dev' ], axis=1)\n",
    "\n",
    "        X_predict = df_train_full.loc[df_train_full.year== i].drop([y_other, y], axis=1)\n",
    "        X_pred_fp = X_predict[['year', 'rank', 'adp', 'best', 'worst', 'avg', 'std_dev']]\n",
    "        X_pred_all = X_predict.drop(['player', 'team', 'pos', 'rank', 'adp', 'best', 'worst', 'avg', 'std_dev'], axis=1)\n",
    "\n",
    "        y_pred = df_train_full.loc[df_train_full.year == i, y]\n",
    "\n",
    "        lass.fit(X_fp, y_train)\n",
    "        fp_pred = lass.predict(X_pred_fp)\n",
    "        stat_fp.extend(list(fp_pred))\n",
    "        print('FP error:', round(np.mean(np.sqrt(abs(mean_squared_error(fp_pred, y_pred)))), 3))\n",
    "        results_fp.append(round(np.mean(np.sqrt(abs(mean_squared_error(fp_pred, y_pred)))), 3))\n",
    "\n",
    "        lass.fit(X_all.replace([np.inf, -np.inf], np.nan).fillna(0), y_train)\n",
    "        all_pred = lass.predict(X_pred_all.replace([np.inf, -np.inf], np.nan).fillna(0))\n",
    "        stat_all.extend(list(all_pred))\n",
    "        print('All error:', round(np.mean(np.sqrt(abs(mean_squared_error(all_pred, y_pred)))), 3))\n",
    "        results_all.append(round(np.mean(np.sqrt(abs(mean_squared_error(all_pred, y_pred)))), 3))\n",
    "    \n",
    "    stats_fp.append(stat_fp)\n",
    "    stats_all.append(stat_all)\n",
    "    \n",
    "    if y == 'fantasy_pts':\n",
    "        print('--------------')\n",
    "        print('Fantasy Pros straight FP Error:', round(np.mean(results_fp), 3))\n",
    "        print('All straight FP Error:', round(np.mean(results_all), 3))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------\n",
    "# Convert Fantasy Pros and Lasso Stat Results to Points\n",
    "#----------------\n",
    "\n",
    "df_all = pd.DataFrame(stats_all).T\n",
    "df_fp = pd.DataFrame(stats_fp).T\n",
    "\n",
    "if set_pos == 'RB':\n",
    "    \n",
    "    df_all = (df_all * [0.1, 0.1, 0.5, 7]).sum(axis=1)\n",
    "    df_fp = (df_fp * [0.1, 0.1, 0.5, 7]).sum(axis=1)\n",
    "\n",
    "elif set_pos == 'WR' or set_pos == 'TE':\n",
    "    df_all = (df_all * [0.1, 0.5, 7]).sum(axis=1)\n",
    "    df_fp = (df_fp * [0.1, 0.5, 7]).sum(axis=1)\n",
    "    \n",
    "elif set_pos == 'QB':\n",
    "    df_all = (df_all * [0.04, 5, 0.1, 7, -2, -1]).sum(axis=1)\n",
    "    df_fp = (df_fp * [0.04, 5, 0.1, 7, -2, -1]).sum(axis=1)\n",
    "\n",
    "\n",
    "y_test = df_train_full.loc[(df_train_full.year <= i) & (df_train_full.year > 2011), y_other]\n",
    "\n",
    "print('Lasso error:', round(np.mean(np.sqrt(abs(mean_squared_error(df_all, y_test)))), 2))\n",
    "print('FantasyPros error:', round(np.mean(np.sqrt(abs(mean_squared_error(df_fp, y_test)))), 2))\n",
    "\n",
    "#----------------\n",
    "# Merge Fantasy Pros Data with Full Model Results to get Matching Player Sets\n",
    "#----------------\n",
    "\n",
    "full_models = pd.merge(\n",
    "              df_train_full.loc[(df_train_full.year <= i) & (df_train_full.year > 2011), ['player', 'year']],\n",
    "              df_train_results, \n",
    "              how='inner', left_on=['player', 'year'], right_on=['player', 'year'])\n",
    "\n",
    "y_test = df_train_full.loc[(df_train_full.year <= i) & (df_train_full.year > 2011), y_other]\n",
    "\n",
    "if set_pos == 'RB':\n",
    "    full_models['fantasy_pts'] = (full_models.iloc[:,2:]* [0.1, 0.1, 0.5, 7]).sum(axis=1)\n",
    "\n",
    "elif set_pos == 'WR' or set_pos =='TE':\n",
    "    full_models['fantasy_pts'] = (full_models.iloc[:,2:]* [0.1, 0.5, 7]).sum(axis=1)\n",
    "    \n",
    "elif set_pos == 'QB':\n",
    "    full_models['fantasy_pts'] = (full_models.iloc[:,2:]* [0.04, 5, 0.1, 7, -2, -1]).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All Models:', round(np.mean(np.sqrt(abs(mean_squared_error(full_models.fantasy_pts, y_test)))), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Air Yards (Large Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(4.34-3.8) / (np.mean([4.34, 3.8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Air Yards (Small Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(4.34-4) / (np.mean([4.34, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Air Yards (Large Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3.18 - 2.83) / (np.mean([3.18, 2.83]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Air Yards (Small Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3.18 - 2.9) / (np.mean([3.18, 2.9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TE (all years, no air yards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(2.66-2.42) / (np.mean([2.66, 2.42]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3.13 - 3.01) / (np.mean([3.13, 3.01]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
