{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# General Setting\n",
    "#==========\n",
    "\n",
    "# set core path\n",
    "path = '/Users/Mark/Documents/Github/Fantasy_Football/'\n",
    "\n",
    "db_name = 'Model_Inputs.sqlite3'\n",
    "\n",
    "# set to position to analyze: 'RB', 'WR', 'QB', or 'TE'\n",
    "set_pos = 'WR'\n",
    "\n",
    "\n",
    "#==========\n",
    "# Postgres Database\n",
    "#==========\n",
    "\n",
    "# postgres login information\n",
    "pg_log = {\n",
    "    'USER': 'postgres',\n",
    "    'PASSWORD': 'Ctdim#1bf!!!!!',\n",
    "    'HOST': 'localhost',\n",
    "    'PORT': '5432', \n",
    "    'DATABASE_NAME': 'fantasyfootball'\n",
    "}\n",
    "\n",
    "# create engine for connecting to database\n",
    "engine = create_engine('postgres+psycopg2://{}:{}@{}:{}/{}'.format(pg_log['USER'], pg_log['PASSWORD'], pg_log['HOST'],\n",
    "                                                                   pg_log['PORT'], pg_log['DATABASE_NAME']))\n",
    "\n",
    "# specify schema and table to write out intermediate results\n",
    "table_info = {\n",
    "    'engine': engine,\n",
    "    'schema': 'websitedev',\n",
    "}\n",
    "\n",
    "#==========\n",
    "# Data Filtering\n",
    "#==========\n",
    "\n",
    "# set year to analyze\n",
    "set_year = 2019\n",
    "earliest_year = 2001\n",
    "\n",
    "# set required touches (or pass thrown) and games for consideration\n",
    "req_games = 8\n",
    "req_touch = 60\n",
    "\n",
    "\n",
    "#==========\n",
    "# Fantasy Point Values\n",
    "#==========\n",
    "\n",
    "# define point values for all statistical categories\n",
    "pass_yd_per_pt = 0.04 \n",
    "pass_td_pt = 5\n",
    "int_pts = -2\n",
    "sacks = -1\n",
    "rush_yd_per_pt = 0.1 \n",
    "rec_yd_per_pt = 0.1\n",
    "rush_rec_td = 7\n",
    "ppr = 0.5\n",
    "fumble = -2\n",
    "\n",
    "# creating dictionary containing point values for each position\n",
    "pts_dict = {}\n",
    "pts_dict['QB'] = [pass_yd_per_pt, pass_td_pt, rush_yd_per_pt, rush_rec_td, int_pts, sacks, fumble]\n",
    "pts_dict['RB'] = [rush_yd_per_pt, rec_yd_per_pt, ppr, rush_rec_td, fumble]\n",
    "pts_dict['WR'] = [rec_yd_per_pt, ppr, rush_rec_td, fumble]\n",
    "pts_dict['TE'] = [rec_yd_per_pt, ppr, rush_rec_td, fumble]\n",
    "\n",
    "\n",
    "#==========\n",
    "# Model Settings\n",
    "#==========\n",
    "\n",
    "# correlation with target for initial feature reduction\n",
    "corr_cutoff = 0.25\n",
    "\n",
    "# VIF threshold to include remaining features\n",
    "vif_thresh = 5\n",
    "\n",
    "# number of hypersearch rounds for training ensemble\n",
    "iter_rounds = 50\n",
    "\n",
    "# whether or not to plot feature importances following modeling\n",
    "plot_importance = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# core packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "# jupyter specifications\n",
    "pd.options.mode.chained_assignment = None\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# plotting functions\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change directory temporarily to helper scripts\n",
    "os.chdir(path + 'Scripts/Analysis/Helper_Scripts')\n",
    "\n",
    "# load custom plot functions\n",
    "from my_plot import PrettyPlot\n",
    "PrettyPlot(plt)\n",
    "\n",
    "# load custom helper functions and ensure lightgbm runs\n",
    "from helper_functions import *\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge and Clean Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# Pull and clean compiled data\n",
    "#==========\n",
    "\n",
    "# connect to database and pull in positional data\n",
    "conn = sqlite3.connect(path + 'Data/' + db_name)\n",
    "df = pd.read_sql_query('SELECT * FROM ' + set_pos + '_' + str(set_year), con=conn)\n",
    "\n",
    "#pff = pd.read_sql_query('SELECT * FROM PFF_Receiving', con=sqlite3.connect(path + 'Data/Season_Stats.sqlite3'))\n",
    "#df = pd.merge(df, pff, how='inner', left_on=['player', 'year'], right_on=['player', 'year'])\n",
    "\n",
    "# split old and new to filter past years based on touches.\n",
    "# leave all new players in to ensure everyone gets a prediction\n",
    "old = df[(df[pos[set_pos]['touch_filter']] > req_touch) & (df.games > req_games) & (df.year < set_year-1)].reset_index(drop=True)\n",
    "this_year = df[df.year==set_year-1]\n",
    "\n",
    "# merge old and new back together after filtering\n",
    "df = pd.concat([old, this_year], axis=0)\n",
    "\n",
    "# create dataframes to store results\n",
    "df_train_results = pd.DataFrame([old.player, old.year]).T\n",
    "df_test_results = pd.DataFrame([this_year.player]).T\n",
    "\n",
    "# calculate FP and generate list of relevant metrics\n",
    "df = calculate_fp(df, pts_dict, pos=set_pos).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#==========\n",
    "# Loop to create statistical predictions\n",
    "#==========\n",
    "\n",
    "output = {}\n",
    "\n",
    "for metric in pos[set_pos]['metrics']:\n",
    "    \n",
    "    # create dataframes to store chunk data\n",
    "    df_train_chunks = pd.DataFrame()\n",
    "    df_test_chunks = pd.DataFrame()\n",
    "\n",
    "    # print which metric is being calculated\n",
    "    print('Running Models for ' + metric)\n",
    "    print('----------------------------------')\n",
    "\n",
    "    #--------\n",
    "    # Create train and predict dataframes\n",
    "    #--------\n",
    "    \n",
    "    # create training and prediction dataframes\n",
    "    df_train_full, df_predict_full = features_target(df,\n",
    "                                                     earliest_year, set_year-1,\n",
    "                                                     pos[set_pos]['med_features'],\n",
    "                                                     pos[set_pos]['sum_features'],\n",
    "                                                     pos[set_pos]['max_features'],\n",
    "                                                     pos[set_pos]['age_features'],\n",
    "                                                     target_feature=metric)\n",
    "    \n",
    "    # drop any rows that have a null target value (likely due to injuries or other missed season)\n",
    "    df_train_full = df_train_full.dropna(subset=['y_act']).reset_index(drop=True)\n",
    "    df_train_full = df_train_full.fillna(df_train_full.mean())\n",
    "    df_predict_full = df_predict_full.dropna().reset_index(drop=True)\n",
    "    \n",
    "    # loop through different k's specific to draft position cutoffs\n",
    "    for k in [1]:\n",
    "        \n",
    "        if k == 1:\n",
    "            \n",
    "            df_train = df_train_full\n",
    "            df_predict = df_predict_full\n",
    "            #df_train = df_train_full[df_train_full.avg_pick < 4.6].reset_index(drop=True)\n",
    "            #df_predict = df_predict_full[df_predict_full.avg_pick < 4.6].reset_index(drop=True)\n",
    "        \n",
    "        #if k == 2:\n",
    "        #    df_train = df_train_full[(df_train_full.avg_pick >= 3.6) & (df_train_full.avg_pick < 4.6)].reset_index(drop=True)\n",
    "        #    df_predict = df_predict_full[(df_predict_full.avg_pick >= 3.6) & (df_predict_full.avg_pick < 4.6)].reset_index(drop=True)\n",
    "        \n",
    "        #if k == 2:\n",
    "        #    df_train = df_train_full[df_train_full.avg_pick >= 4.6].reset_index(drop=True)\n",
    "        #    df_predict = df_predict_full[df_predict_full.avg_pick >= 4.6].reset_index(drop=True)\n",
    "            \n",
    "        #--------\n",
    "        # Remove low correlation features and high VIF features\n",
    "        #--------\n",
    "\n",
    "        # remove low correlation features\n",
    "        df_train, df_predict = corr_removal(df_train, df_predict, corr_cutoff=corr_cutoff)\n",
    "\n",
    "        # select only features with low vif for modeling\n",
    "        transformer = ReduceVIF(thresh=vif_thresh, scale=True, print_progress=False)\n",
    "        df_train_ = transformer.fit_transform(df_train.drop(['y_act', 'player'], axis=1), df_train.y_act)\n",
    "\n",
    "        # extract best columns and filter down df_predict\n",
    "        best_cols = list(df_train_.columns)\n",
    "        best_cols.extend(['player', 'year', 'avg_pick'])\n",
    "        df_predict = df_predict[best_cols]\n",
    "        df_predict = df_predict.loc[:,~df_predict.columns.duplicated()]\n",
    "\n",
    "        # add target and filter down df_train\n",
    "        best_cols.extend(['y_act', 'year', 'avg_pick'])\n",
    "        df_train = df_train[best_cols]\n",
    "        df_train = df_train.loc[:,~df_train.columns.duplicated()]\n",
    "\n",
    "        #--------\n",
    "        # Run ensemble model with parameter optimization\n",
    "        #--------\n",
    "\n",
    "        # generate a master dictionary of parameters (must match the)\n",
    "        param_list = [lgbm_params, xgb_params, lasso_params, ridge_params]\n",
    "        est_names = ['lgbm', 'xgb', 'lasso', 'ridge']\n",
    "\n",
    "        params = {}\n",
    "        for i, param in enumerate(param_list):\n",
    "            params[est_names[i]] = param\n",
    "\n",
    "        print('Training Ensemble Model')\n",
    "        param_results, summary, df_train_results_, errors = validation(est_names, params, df_train, iterations=iter_rounds, random_state=1234)\n",
    "\n",
    "        #--------\n",
    "        # Print best results\n",
    "        #--------\n",
    "\n",
    "        # print a summary of error metrics, weightings of various models, and a comparison to \n",
    "        # using straight adp as as a prediction for next year's stats\n",
    "        print(summary.head(10))\n",
    "        path = '/Users/Mark/Documents/Github/Fantasy_Football/Scripts/Analysis/ParamSearch/'\n",
    "        label = '{}{}_G{}_Touch{}_Corr{}_VIF{}.csv'.format(path, set_pos, req_games, req_touch, corr_cutoff, vif_thresh)\n",
    "        summary.to_csv(label, index=False, mode='a')\n",
    "\n",
    "        # pull out the best result for the random hyperparameter search of models\n",
    "        best_result = summary.index[0]\n",
    "\n",
    "        # pass the best hyperparameters into the generation_prediction function, which\n",
    "        # will return the test results for the current year and the trained best models\n",
    "        df_test_results_, models = generate_predictions(best_result, param_results, summary, df_train, df_predict)\n",
    "\n",
    "        #--------\n",
    "        # Aggregate all results through merging\n",
    "        #--------\n",
    "\n",
    "        # add models to output dictionary\n",
    "        output[metric] = {}\n",
    "        output[metric][k] = {}\n",
    "        output[metric][k]['models'] = models\n",
    "\n",
    "        # add params to output dictionary\n",
    "        output[metric][k]['params'] = param_results\n",
    "\n",
    "        # add columns to output dictionary\n",
    "        cols = list(df_train.columns)\n",
    "        cols.remove('y_act')\n",
    "        cols.remove('player')\n",
    "        output[metric]['cols'] = cols\n",
    "        \n",
    "        # concat the chunk for each metric together into one dataframe\n",
    "        df_train_results_ = df_train_results_.rename(columns={'pred': 'pred_' + metric})\n",
    "        df_train_results_ = df_train_results_[['player', 'year', 'pred_' + metric]]\n",
    "        df_train_chunks = pd.concat([df_train_chunks, df_train_results_], axis=0).reset_index(drop=True)\n",
    "        \n",
    "        # concat the chunk for each metric together into one dataframe\n",
    "        df_test_results_ = df_test_results_.rename(columns={'pred': 'pred_' + metric})\n",
    "        df_test_results_ = df_test_results_[['player', 'pred_' + metric]]\n",
    "        df_test_chunks = pd.concat([df_test_chunks, df_test_results_], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    # merge the train results for the given metric with all other metric outputs\n",
    "    df_train_results = pd.merge(df_train_results, df_train_chunks, \n",
    "                                how='inner', left_on=['player', 'year'], right_on=['player', 'year'])\n",
    "    # merge the test results for the given metric with all other metric outputs\n",
    "    df_test_results = pd.merge(df_test_results, df_test_chunks, \n",
    "                               how='inner', left_on='player', right_on='player')\n",
    "\n",
    "# after loop, set the df_train to have the y_act as fp_per_game\n",
    "df_train, df_predict = features_target(df, earliest_year, set_year-1, \n",
    "                                           pos[set_pos]['med_features'], \n",
    "                                           pos[set_pos]['sum_features'],\n",
    "                                           pos[set_pos]['max_features'], \n",
    "                                           pos[set_pos]['age_features'],\n",
    "                                           target_feature='fp_per_game')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out results to Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------\n",
    "# Append additional stat categories to the results\n",
    "#--------\n",
    "\n",
    "# add actual results and adp to the train df\n",
    "train_results = pd.merge(df_train_results, df_train[['player', 'year', 'age', 'year_exp', 'avg_pick', 'y_act']],\n",
    "                           how='inner', left_on=['player', 'year'], right_on=['player', 'year']).drop('year', axis=1)\n",
    "\n",
    "# add adp to the test df\n",
    "test_results = pd.merge(df_test_results, df_predict[['player', 'age', 'year_exp', 'avg_pick']],\n",
    "                           how='inner', left_on='player', right_on='player')\n",
    "\n",
    "#--------\n",
    "# Set up proper database connections to save out single dataset\n",
    "#--------\n",
    "\n",
    "train_results.to_sql(set_pos + '_Train_' + str(set_year), engine, schema='websitedev', index=False, if_exists='replace')\n",
    "test_results.to_sql(set_pos + '_Test_' + str(set_year), engine, schema='websitedev', index=False, if_exists='replace')\n",
    "\n",
    "# #--------\n",
    "# # Calculate Fantasy Points for Given Scoring System\n",
    "# #-------- \n",
    "\n",
    "# # extract points list and get the idx of point attributes based on length of list\n",
    "# pts_list = pts_dict[set_pos][:-1]\n",
    "# print(pts_list)\n",
    "# c_idx = len(pts_list) + 1\n",
    "\n",
    "# # multiply stat categories by corresponding point values\n",
    "# train_results.iloc[:, 1:c_idx] = train_results.iloc[:, 1:c_idx] * pts_list\n",
    "# test_results.iloc[:, 1:c_idx] = test_results.iloc[:, 1:c_idx] * pts_list\n",
    "\n",
    "# # add a total predicted points stat category\n",
    "# train_results.loc[:, 'pred'] = train_results.iloc[:, 1:c_idx].sum(axis=1)\n",
    "# test_results.loc[:, 'pred'] = test_results.iloc[:, 1:c_idx].sum(axis=1)\n",
    "\n",
    "# #==========\n",
    "# # Plot Predictions for Each Player\n",
    "# #==========\n",
    "\n",
    "# # set length of plot based on number of results\n",
    "# plot_length = int(test_results.shape[0] / 3.5)\n",
    "\n",
    "# # plot results from highest predicted FP to lowest predicted FP\n",
    "# test_results.sort_values('pred').plot.barh(x='player', y='pred', figsize=(5, plot_length));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========\n",
    "# If desired, plot feature importances for a given metric / model\n",
    "#==========\n",
    "plot_importance=True\n",
    "if plot_importance == True:\n",
    "    \n",
    "    metric = 'rush_yd_per_game'\n",
    "    k = 1\n",
    "    j = 3\n",
    "    try:\n",
    "        plot_results(output[metric][k]['models'][j].feature_importances_, col_names=output[metric]['cols']);\n",
    "    except:\n",
    "        plot_results(output[metric][k]['models'][j].coef_, col_names=output[metric]['cols']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Salary, Injury Tables and SQLite Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal = pd.read_csv('/Users/Mark/Desktop/salaries.csv')\n",
    "sal.to_sql('salaries_' + str(set_year), engine, schema='websitedev', index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "inj = pd.read_csv('/Users/Mark/Desktop/injury_predictor_2019.csv',  encoding='latin-1', header=None)\n",
    "inj.columns = ['player', 'pct_miss_one', 'proj_games_missed', 'inj_pct_per_game', 'inj_risk', 'points']\n",
    "inj.player = inj.player.apply(lambda x: x.split(',')[0])\n",
    "inj.pct_miss_one = inj.pct_miss_one.apply(lambda x: float(x.strip('%')))\n",
    "inj.inj_pct_per_game = inj.inj_pct_per_game.apply(lambda x: float(x.strip('%')))\n",
    "inj = inj.drop(['points', 'inj_risk'], axis=1)\n",
    "\n",
    "X = StandardScaler().fit_transform(inj.iloc[:, 1:])\n",
    "inj = pd.concat([pd.DataFrame(inj.player), \n",
    "                 pd.DataFrame(X, columns=['pct_miss_one', 'proj_games_missed', 'pct_per_game'])], \n",
    "                axis=1)\n",
    "for col in ['pct_miss_one', 'proj_games_missed', 'pct_per_game']:\n",
    "    inj[col] = inj[col] + abs(inj[col].min())\n",
    "\n",
    "inj['mean_risk'] = inj.iloc[:, 1:].mean(axis=1)\n",
    "inj = inj[['player', 'mean_risk']].sort_values(by='mean_risk').reset_index(drop=True)\n",
    "inj.loc[inj.player=='Kareem Hunt', 'mean_risk'] = 8\n",
    "inj.loc[inj.player=='Melvin Gordon', 'mean_risk'] = inj.loc[inj.player=='Melvin Gordon', 'mean_risk'] + 1\n",
    "\n",
    "inj = inj[['player', 'mean_risk']]\n",
    "inj.to_sql('injuries_' + str(set_year), engine, schema='websitedev', index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('/Users/Mark/Desktop/FF_Sim/SimInput_v1.sqlite3')\n",
    "\n",
    "for set_pos in ['QB', 'RB', 'WR', 'TE']:\n",
    "    \n",
    "    train = pd.read_sql_query('SELECT * FROM {}.\"{}_Train_{}\"' \\\n",
    "                                     .format(table_info['schema'], set_pos, str(set_year)), table_info['engine'])\n",
    "    test = pd.read_sql_query('SELECT * FROM {}.\"{}_Test_{}\"' \\\n",
    "                                    .format(table_info['schema'], set_pos, str(set_year)), table_info['engine'])\n",
    "    \n",
    "    train.to_sql(name='{}_Train_{}'.format(set_pos, str(set_year)), con=db, if_exists='replace', index=False)\n",
    "    test.to_sql(name='{}_Test_{}'.format(set_pos, str(set_year)), con=db, if_exists='replace', index=False)\n",
    "    \n",
    "\n",
    "sal = pd.read_sql_query('SELECT * FROM {}.\"salaries_2019\"' \\\n",
    "                                    .format(table_info['schema'], set_pos, str(set_year)), table_info['engine'])\n",
    "sal.to_sql(name='salaries_2019', con=db, if_exists='replace', index=False)\n",
    "\n",
    "inj = pd.read_sql_query('SELECT * FROM {}.\"injuries_2019\"' \\\n",
    "                                    .format(table_info['schema'], set_pos, str(set_year)), table_info['engine'])\n",
    "inj.to_sql(name='injuries_2019', con=db, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Fantasy Pros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and prediction dataframes\n",
    "fantasy_points = []\n",
    "#for m in ['rush_yd_per_game', 'rec_yd_per_game', 'rec_per_game', 'td_per_game']:\n",
    "for m in ['rec_yd_per_game', 'rec_per_game', 'td_per_game']:\n",
    "    df_train_full, df_predict_full = features_target(df,\n",
    "                                                     earliest_year, set_year-1,\n",
    "                                                     pos[set_pos]['med_features'],\n",
    "                                                     pos[set_pos]['sum_features'],\n",
    "                                                     pos[set_pos]['max_features'],\n",
    "                                                     pos[set_pos]['age_features'],\n",
    "                                                     target_feature=m)\n",
    "    fantasy_points.append(list(df_train_full.y_act.values))\n",
    "    \n",
    "fantasy_pts = pd.DataFrame(fantasy_points).T.reset_index(drop=True)\n",
    "#fantasy_pts = (fantasy_pts * [0.1, 0.1, 0.5, 7]).sum(axis=1)\n",
    "fantasy_pts = (fantasy_pts * [0.1, 0.5, 7]).sum(axis=1)\n",
    "fantasy_pts.name = 'fantasy_pts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_fp = []\n",
    "stats_all = []\n",
    "#for metric in ['rush_yd_per_game', 'rec_yd_per_game', 'rec_per_game', 'td_per_game']:\n",
    "for metric in ['rec_yd_per_game', 'rec_per_game', 'td_per_game']:\n",
    "\n",
    "    df_train_full, df_predict_full = features_target(df,\n",
    "                                                         earliest_year, set_year-1,\n",
    "                                                         pos[set_pos]['med_features'],\n",
    "                                                         pos[set_pos]['sum_features'],\n",
    "                                                         pos[set_pos]['max_features'],\n",
    "                                                         pos[set_pos]['age_features'],\n",
    "                                                         target_feature=metric)\n",
    "\n",
    "    df_train_full = pd.concat([df_train_full, fantasy_pts], axis=1)\n",
    "\n",
    "    fp = pd.read_sql_query('SELECT * FROM FantasyPros', con=sqlite3.connect('/Users/Mark/Documents/Github/Fantasy_Football/Data/Season_Stats.sqlite3'))\n",
    "    fp.year = fp.year-1\n",
    "    df_train_full = pd.merge(df_train_full, fp, how='inner', left_on=['player', 'year'], right_on=['player', 'year'])\n",
    "    df_train_full = df_train_full[df_train_full.fp > 5]\n",
    "\n",
    "\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "    df_train_full = df_train_full.dropna()\n",
    "    lass = Lasso(alpha=250)\n",
    "#     y = 'fantasy_pts'\n",
    "#     y_other = 'y_act'\n",
    "    \n",
    "    y_other = 'fantasy_pts'\n",
    "    y = 'y_act'\n",
    "\n",
    "\n",
    "    stat_all = []\n",
    "    stat_fp = []\n",
    "    results_all = []\n",
    "    results_fp = []\n",
    "    for i in [2012, 2013, 2014, 2015, 2016, 2017]:\n",
    "\n",
    "        print(i)\n",
    "        X_train = df_train_full.loc[df_train_full.year < i].drop([y_other, y], axis=1)\n",
    "        y_train = df_train_full.loc[df_train_full.year < i, y]\n",
    "\n",
    "        X_fp = X_train[['year', 'rank', 'adp', 'best', 'worst', 'avg', 'std_dev']]\n",
    "        X_all = X_train.drop(['player', 'team', 'pos','rank', 'adp', 'best', 'worst', 'avg', 'std_dev' ], axis=1)\n",
    "\n",
    "        X_predict = df_train_full.loc[df_train_full.year== i].drop([y_other, y], axis=1)\n",
    "        X_pred_fp = X_predict[['year', 'rank', 'adp', 'best', 'worst', 'avg', 'std_dev']]\n",
    "        X_pred_all = X_predict.drop(['player', 'team', 'pos', 'rank', 'adp', 'best', 'worst', 'avg', 'std_dev'], axis=1)\n",
    "\n",
    "        y_pred = df_train_full.loc[df_train_full.year == i, y]\n",
    "\n",
    "        lass.fit(X_fp, y_train)\n",
    "        fp_pred = lass.predict(X_pred_fp)\n",
    "        stat_fp.extend(list(fp_pred))\n",
    "        print('FP error:', round(np.mean(np.sqrt(abs(mean_squared_error(fp_pred, y_pred)))), 3))\n",
    "        results_fp.append(round(np.mean(np.sqrt(abs(mean_squared_error(fp_pred, y_pred)))), 3))\n",
    "\n",
    "\n",
    "\n",
    "        lass.fit(X_all, y_train)\n",
    "        all_pred = lass.predict(X_pred_all)\n",
    "        stat_all.extend(list(all_pred))\n",
    "        print('All error:', round(np.mean(np.sqrt(abs(mean_squared_error(all_pred, y_pred)))), 3))\n",
    "        results_all.append(round(np.mean(np.sqrt(abs(mean_squared_error(all_pred, y_pred)))), 3))\n",
    "    \n",
    "    stats_fp.append(stat_fp)\n",
    "    stats_all.append(stat_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Fantasy Pros straight FP Error:', round(np.mean(results_fp), 3))\n",
    "print('All straight FP Error:', round(np.mean(results_all), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame(stats_all).T\n",
    "df_fp = pd.DataFrame(stats_fp).T\n",
    "\n",
    "# df_all = (df_all * [0.1, 0.1, 0.5, 7]).sum(axis=1)\n",
    "# df_fp = (df_fp * [0.1, 0.1, 0.5, 7]).sum(axis=1)\n",
    "\n",
    "df_all = (df_all * [0.1, 0.5, 7]).sum(axis=1)\n",
    "df_fp = (df_fp * [0.1, 0.5, 7]).sum(axis=1)\n",
    "\n",
    "y_test = df_train_full.loc[(df_train_full.year <= i) & (df_train_full.year > 2011), y_other]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lasso error:', round(np.mean(np.sqrt(abs(mean_squared_error(df_all, y_test)))), 2))\n",
    "print('FantasyPros error:', round(np.mean(np.sqrt(abs(mean_squared_error(df_fp, y_test)))), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_models = pd.merge(\n",
    "              df_train_full.loc[(df_train_full.year <= i) & (df_train_full.year > 2011), ['player', 'year']],\n",
    "              df_train_results, \n",
    "              how='inner', left_on=['player', 'year'], right_on=['player', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_models['fantasy_pts'] = (full_models.iloc[:,2:]* [0.1, 0.1, 0.5, 7]).sum(axis=1)\n",
    "full_models['fantasy_pts'] = (full_models.iloc[:,2:]* [0.1, 0.5, 7]).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All Models:', round(np.mean(np.sqrt(abs(mean_squared_error(full_models.fantasy_pts, y_test)))), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(4.34-3.93) / (np.mean([4.34, 3.93]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3.2 - 2.88) / (np.mean([3.2, 2.88]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
